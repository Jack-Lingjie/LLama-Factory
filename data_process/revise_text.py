import json
from concurrent.futures import ThreadPoolExecutor, as_completed  
import os
import pandas as pd
from gpt4o import Openai, API_INFOS
from datasets import load_dataset, Dataset
from tqdm import tqdm

system_template= \
"""You are tasked with acting as a text rewriter to enhance the aesthetic quality of text generated by a Large Language Model (LLM). Your job is to evaluate the provided user instruction and the LLM-generated response from an aesthetic perspective, determine whether the text needs modification, and then provide the revised text if necessary.  
  
*Format*   
  
Textual Aesthetic Analysis:
[Your analysis]

Does it need modification:
[Y/N]

Revised Text:
[Your revised text, if applicable]   
  
*Textual Aesthetic Elements to Consider*:  
  
1. **Paragraph Structure**: Ensure paragraphs are of appropriate length and logically structured.  
2. **Indentation**: Apply consistent indentation where necessary.  
3. **Headings and Subheadings**: Use headings and subheadings to organize content and improve readability.  
4. **Lists and Bullet Points**: Utilize lists and bullet points to break down complex information.  
5. **Markdown Formatting**: Apply markdown for bold, italic, and code blocks to highlight important information or distinguish between different types of text.  
6. **Line Spacing**: Adjust line spacing to enhance readability.  
7. **Consistency**: Maintain a consistent style throughout the document.  
8. **Visual Breaks**: Use visual breaks to separate different sections and improve flow.  
"""
user_template = \
"""### User Instruction:  
{instruction}  
  
### Answer:  
{completion}  
  
Your task is to:  
  
1. Analyze the LLM-generated response from a textual aesthetic perspective.  
2. Determine whether the text needs modification.  
3. Provide a revised version of the text if necessary.  
  
*Format*   
  
Textual Aesthetic Analysis:
[Your analysis]

Does it need modification:
[Y/N]

Revised Text:
[Your revised text, if applicable]
  
*Textual Aesthetic Elements to Consider*:  
  
1. **Paragraph Structure**: Ensure paragraphs are of appropriate length and logically structured.  
2. **Indentation**: Apply consistent indentation where necessary.  
3. **Headings and Subheadings**: Use headings and subheadings to organize content and improve readability.  
4. **Lists and Bullet Points**: Utilize lists and bullet points to break down complex information.  
5. **Markdown Formatting**: Apply markdown for bold, italic, and code blocks to highlight important information or distinguish between different types of text.  
6. **Line Spacing**: Adjust line spacing to enhance readability.  
7. **Consistency**: Maintain a consistent style throughout the document.  
8. **Visual Breaks**: Use visual breaks to separate different sections and improve flow.  
"""

def get_data():
    ds = load_dataset("HuggingFaceH4/ultrafeedback_binarized", split="train_prefs")
    def get_instruct_response(item):
        # item["instruction"] = item['chosen'][0]["content"]
        item["response"] = item['chosen'][1]["content"]
        return item
    ds = ds.map(get_instruct_response, batch_size=1024, num_proc=8)
    export_data = ds.select_columns(["prompt", "response"])
    return export_data

def get_revised_text(client, instruction, completion, user_template, system_template, max_tokens=2048):  
    content = user_template.format(instruction=instruction, completion=completion)  
    # print(f"content: {content}")
    gpt_answer = client.get_response(content=content, system=system_template, max_tokens=max_tokens)  
    gpt_answer = gpt_answer.strip()  
    need_modification = "Y" if "Does it need modification: Y" in gpt_answer else "N"  
    revised_text_start = gpt_answer.find("Revised Text:") + len("Revised Text:")  
    revised_text = gpt_answer[revised_text_start:].strip()  
    return need_modification, revised_text, gpt_answer  
  
def process_row(index, client, row, user_template, system_template, max_tokens=2048, output_file="output.jsonl"):  
    prompt = row['prompt']  
    response = row['response']  
    need_modification, revised_text, gpt_answer = get_revised_text(client, prompt, response, user_template, system_template, max_tokens=max_tokens)  
    # print(f"index {index}")
    result = {  
        'index': index,  
        'prompt': prompt,  
        'response': response,  
        'does_it_need_modification': need_modification,  
        'revised_text': revised_text,  
        'gpt_answer': gpt_answer  
    }  
    # Write the result to a JSONL file  
    with open(output_file, 'a') as f:  
        f.write(json.dumps(result) + "\n")  
    return result  
def main():  
    # Initialize multiple clients  
    clients = [Openai(apis=[API_INFOS[i]]) for i in range(6)]  
    export_data = get_data()
    sample_data = export_data.select(range(100))
    # user_template = "User: {instruction}\nCompletion: {completion}"  
    # system_template = "You are a helpful assistant."  
    max_tokens = 2048  
    output_file = "data_process/revised_data/output.jsonl"  
  
    # Clear the output file before starting  
    if os.path.exists(output_file):  
        os.remove(output_file)  
  
    revised_data = []  
  
    with ThreadPoolExecutor(max_workers=6) as executor:  
        # Create a future for each row in the dataset  
        futures = [executor.submit(process_row, i, clients[i % len(clients)], row, user_template, system_template, max_tokens, output_file) for i, row in enumerate(sample_data)]  
  
        # Collect the results as they complete  
        for future in tqdm(as_completed(futures), total=len(futures)):  
            revised_data.append(future.result())  
        # with tqdm(total=len(futures)) as pbar:  
        #     # Collect the results as they complete  
        #     for future in as_completed(futures):  
        #         result = future.result()  
        #         revised_data.append(result)  
        #         pbar.update(1)  # Update the progress bar
  
    # Load results from JSONL file and ensure the order is preserved  
    with open(output_file, 'r') as f:  
        revised_data = [json.loads(line) for line in f]  
  
    # Sort by the original index  
    revised_dataset = revised_data.sort(key=lambda x: x['index'])  
  
    # Create a new Dataset  
    revised_dataset = Dataset.from_pandas(pd.DataFrame(revised_data))  
    revised_dataset.to_json("data_process/revised_data/output_sorted.jsonl") 
if __name__ == "__main__":
    main()