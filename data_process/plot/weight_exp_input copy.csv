Model,Loss,ta_text,ta_image,alpaca_eval_lcwin,arena-hard_gpt4o,mt-bench,mmlu,,,,,,,,,,,,
Llama-3.1-base 8B,-,0.00,0.36,0.20,0.77,2.57,61.94,,,,,,,,,,,,
Llama-3.1-base+SFT,-,1.17,8.60,5.24,4.10,5.60,64.07,,,,,,,,,,,,
Llama-3.1-base+SFT,1:0,23.09,56.25,20.50,7.72,5.48,60.56,,,,,,,,,,,,
Llama-3.2-base+SFT,1:1,27.47,56.1,27.84,9.48,6.02,64.3,,,,,,,,,,,,
Llama-3.3-base+SFT,1:2,23.8,54.13,26.73,9.55,6.13,64.7,,,,,,,,,,,,
Llama-3.4-base+SFT,1:5,24.35,51.56,25.05,11.99,6.17,64.8,,,,,,,,,,,,
Llama-3.5-base+SFT,1:10,31.39,55.81,24.74,12.09,6.19,65,,,,,,,,,,,,
Llama-3.6-base+SFT,1:15,33.94,60.78,25.99,11.37,6.13,64.96,,,,,,,,,,,,
Llama-3.7-base+SFT,2:1,27.56,57.99,25.49,8.57,6.02,64.06,,,,,,,,,,,,
Llama-3.8-base+SFT,1:1(L1=r1/(r1 + r2),24.61,53.78,25.90,9.33,5.96,64.5,,,,,,,,,,,,
Llama-3.8-base+SFT,1:1(L1=r1/(r1 + r3),26.82,50.56,24.67,5.93,6.26,64.77,,,,,,,,,,,,
Llama-3.1-8B-Instruct,1:1,52.45,71.11,48.43,34.15,7.83,68.79,,,,,,,,,,,,
Llama-3.1-9B-Instruct,1:2,49.39,69.84,48.17,35.90,7.68,68.79,,,,,,,,,,,,
Llama-3.1-10B-Instruct,1:5,42.71,63.61,48.08,34.09,7.65,68.91,,,,,,,,,,,,
Llama-3.1-11B-Instruct,1:10,39.68,58.12,45.98,37.85,7.10,68.86,,,,,,,,,,,,
Llama-3.1-12B-Instruct,1:15,36.07,54.53,46.05,36.64,6.94,68.87,,,,,,,,,,,,
Llama-3.1-13B-Instruct,2：1,52.98,73.91,48.58,34.66,6.88,68.71,,,,,,,,,,,,
Llama-3.1-14B-Instruct,1:1（(L1=r1/(r1 + r2)),51.73,73.08,48.94,34.23,6.96,68.84,,,,,,,,,,,,
Llama-3.1-15B-Instruct,1:1（L1=r1/(r1 + r3)),46.88,64.18,45.94,33.81,7.78,68.8,,,,,,,,,,,,