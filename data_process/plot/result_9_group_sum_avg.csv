Model,gpt4_text,gpt4_image,text_70B,image_70B,group_1_sum,group_1_avg,group_2_sum,group_2_avg
Meta-Llama-3.1-70B-Instruct,9:30:11,25:23:2,10:37:3,25:23:2,34/53/13,34.0/53.0/13.0,35/60/5,35.0/60.0/5.0
Meta-Llama-3.1-8B-Instruct,18:29:3,20:26:4,27:21:2,20:26:4,38/55/7,38.0/55.0/7.0,47/47/6,47.0/47.0/6.0
Qwen2-72B-Instruct,32:14:4,30:16:4,36:9:5,30:16:4,62/30/8,62.0/30.0/8.0,66/25/9,66.0/25.0/9.0
tulu-2-dpo-70b,44:4:2,38:9:3,44:4:2,38:9:3,82/13/5,82.0/13.0/5.0,82/13/5,82.0/13.0/5.0
