{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-Llama-3.1-8B-Instruct: 23:24:3\n",
      "Meta-Llama-3.1-70B-Instruct: 14:32:4\n",
      "Qwen2-72B-Instruct: 30:18:2\n",
      "tulu-2-dpo-70b: 43:5:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_610907/220148569.py:9: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "  \n",
    "# 读取Excel文件  \n",
    "file_path = 'Label_two.xlsx'  \n",
    "sheet_name = 'Lingjie'  \n",
    "df = pd.read_excel(file_path, sheet_name=sheet_name)  \n",
    "  \n",
    "# 将所有字符转换为大写  \n",
    "df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)  \n",
    "  \n",
    "# 初始化一个字典来存储每列的统计结果  \n",
    "result = {}  \n",
    "  \n",
    "# 遍历每一列并统计W:T:L的数量  \n",
    "for column in df.columns[1:]:  # 跳过第一列（假设第一列是索引或非统计列）  \n",
    "    counts = df[column].value_counts().to_dict()  \n",
    "    w_count = counts.get('W', 0)  \n",
    "    t_count = counts.get('T', 0)  \n",
    "    l_count = counts.get('L', 0)  \n",
    "    result[column] = f'{w_count}:{t_count}:{l_count}'  \n",
    "  \n",
    "# 打印结果  \n",
    "for column, count in result.items():  \n",
    "    print(f'{column}: {count}')  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我有一个数据标表格的前几列如下，代表着我们的模型和这些模型比较的结果，W代表我们的模型更好，T代表相同，L代表我们的模型不如对比的模型好，帮我统计每一列的W:T:L的数量，文件名如下Label_two.xlsx，表格前几列如下\n",
    "Index\tMeta-Llama-3.1-8B-Instruct\tMeta-Llama-3.1-70B-Instruct\tQwen2-72B-Instruct\ttulu-2-dpo-70b\n",
    "0\tT\tT\tW\tW\n",
    "1\tT\tT\tW\tW\n",
    "2\tW\tW\tW\tW\n",
    "3\tT\tT\tW\tW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results have been written to result.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_610907/922062794.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_610907/922062794.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_610907/922062794.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "  \n",
    "def process_sheet(file_path, sheet_name):  \n",
    "    # 读取指定工作表  \n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)  \n",
    "  \n",
    "    # 将所有字符转换为大写  \n",
    "    df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)  \n",
    "  \n",
    "    # 初始化一个字典来存储每列的统计结果  \n",
    "    result = {}  \n",
    "  \n",
    "    # 遍历每一列并统计W:T:L的数量  \n",
    "    for column in df.columns[1:]:  # 跳过第一列（假设第一列是索引或非统计列）  \n",
    "        counts = df[column].value_counts().to_dict()  \n",
    "        w_count = counts.get('W', 0)  \n",
    "        t_count = counts.get('T', 0)  \n",
    "        l_count = counts.get('L', 0)  \n",
    "        result[column] = f'{w_count}:{t_count}:{l_count}'  \n",
    "  \n",
    "    return result  \n",
    "  \n",
    "# 文件路径  \n",
    "file_path = 'Label_two.xlsx'  \n",
    "  \n",
    "# 需要处理的工作表名称  \n",
    "sheets = ['Lingjie', 'Shaohanh', 'Label3_8B']  # 假设另外两个工作表名为Sheet1和Sheet2，根据实际情况修改  \n",
    "  \n",
    "# 初始化一个DataFrame来存储所有结果  \n",
    "all_results = pd.DataFrame()  \n",
    "  \n",
    "# 处理每个工作表  \n",
    "for sheet in sheets:  \n",
    "    sheet_result = process_sheet(file_path, sheet)  \n",
    "    sheet_df = pd.DataFrame(list(sheet_result.items()), columns=['Model', sheet])  \n",
    "    if all_results.empty:  \n",
    "        all_results = sheet_df  \n",
    "    else:  \n",
    "        all_results = all_results.merge(sheet_df, on='Model', how='outer')  \n",
    "  \n",
    "# 将结果写入CSV文件  \n",
    "output_file = 'result.csv'  \n",
    "all_results.to_csv(output_file, index=False)  \n",
    "  \n",
    "print(f'Results have been written to {output_file}')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results have been written to agreement_result.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_610907/3209199104.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_610907/3209199104.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_610907/3209199104.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "  \n",
    "def process_sheet(file_path, sheet_name):  \n",
    "    # 读取指定工作表  \n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)  \n",
    "  \n",
    "    # 将所有字符转换为大写  \n",
    "    df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)  \n",
    "      \n",
    "    return df  \n",
    "  \n",
    "def calculate_agreement(df1, df2):  \n",
    "    # 确保两个DataFrame的索引和列对齐  \n",
    "    df1 = df1.set_index(df1.columns[0])  \n",
    "    df2 = df2.set_index(df2.columns[0])  \n",
    "      \n",
    "    agreements = {}  \n",
    "    for col in df1.columns:  \n",
    "        comparison = df1[col] == df2[col]  \n",
    "        agreements[col] = comparison.mean()  \n",
    "          \n",
    "    return agreements  \n",
    "  \n",
    "# 文件路径  \n",
    "file_path = 'Label_two.xlsx'  \n",
    "  \n",
    "# 需要处理的工作表名称  \n",
    "sheets = ['Lingjie', 'Shaohanh', 'Label3_8B']  # 假设另外两个工作表名为Sheet1和Sheet2，根据实际情况修改  \n",
    "  \n",
    "# 读取所有的表  \n",
    "dfs = {sheet: process_sheet(file_path, sheet) for sheet in sheets}  \n",
    "  \n",
    "# 计算每对工作表的一致性  \n",
    "results = {}  \n",
    "for i, sheet1 in enumerate(sheets):  \n",
    "    for j, sheet2 in enumerate(sheets):  \n",
    "        if i < j:  \n",
    "            agreement = calculate_agreement(dfs[sheet1], dfs[sheet2])  \n",
    "            results[f'{sheet1} vs {sheet2}'] = agreement  \n",
    "  \n",
    "# 将结果转换为DataFrame  \n",
    "agreement_df = pd.DataFrame(results).T  \n",
    "  \n",
    "# 计算每列的平均一致性  \n",
    "agreement_df['Average'] = agreement_df.mean(axis=1)  \n",
    "  \n",
    "# 将结果写入CSV文件  \n",
    "output_file = 'agreement_result.csv'  \n",
    "agreement_df.to_csv(output_file)  \n",
    "  \n",
    "print(f'Results have been written to {output_file}')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results have been written to agreement_result_2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_610907/454848843.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_610907/454848843.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_610907/454848843.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "  \n",
    "def process_sheet(file_path, sheet_name):  \n",
    "    # 读取指定工作表  \n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)  \n",
    "  \n",
    "    # 将所有字符转换为大写  \n",
    "    df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)  \n",
    "      \n",
    "    return df  \n",
    "  \n",
    "def calculate_agreement(df1, df2):  \n",
    "    # 确保两个DataFrame的索引和列对齐  \n",
    "    df1 = df1.set_index(df1.columns[0])  \n",
    "    df2 = df2.set_index(df2.columns[0])  \n",
    "      \n",
    "    agreements = {}  \n",
    "    for col in df1.columns:  \n",
    "        comparison = df1[col] == df2[col]  \n",
    "        agreements[col] = comparison.mean()  \n",
    "          \n",
    "    return agreements  \n",
    "  \n",
    "# 文件路径  \n",
    "file_path = 'Label_two.xlsx'  \n",
    "  \n",
    "# 需要处理的工作表名称  \n",
    "sheets = ['Lingjie-70B', 'shaohanh-70B', 'Label3-70B']  # 假设另外两个工作表名为Sheet1和Sheet2，根据实际情况修改  \n",
    "  \n",
    "# 读取所有的表  \n",
    "dfs = {sheet: process_sheet(file_path, sheet) for sheet in sheets}  \n",
    "  \n",
    "# 计算每对工作表的一致性  \n",
    "results = {}  \n",
    "for i, sheet1 in enumerate(sheets):  \n",
    "    for j, sheet2 in enumerate(sheets):  \n",
    "        if i < j:  \n",
    "            agreement = calculate_agreement(dfs[sheet1], dfs[sheet2])  \n",
    "            results[f'{sheet1} vs {sheet2}'] = agreement  \n",
    "  \n",
    "# 将结果转换为DataFrame  \n",
    "agreement_df = pd.DataFrame(results).T  \n",
    "  \n",
    "# 计算每列的平均一致性  \n",
    "agreement_df['Average'] = agreement_df.mean(axis=1)  \n",
    "  \n",
    "# 将结果写入CSV文件  \n",
    "output_file = 'agreement_result_2.csv'  \n",
    "agreement_df.to_csv(output_file)  \n",
    "  \n",
    "print(f'Results have been written to {output_file}')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "  \n",
    "def process_sheet(file_path, sheet_name):  \n",
    "    # 读取指定工作表  \n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)  \n",
    "  \n",
    "    # 将所有字符转换为大写  \n",
    "    df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)  \n",
    "  \n",
    "    # 初始化一个字典来存储每列的统计结果  \n",
    "    result = {}  \n",
    "  \n",
    "    # 遍历每一列并统计W:T:L的数量  \n",
    "    for column in df.columns[1:]:  # 跳过第一列（假设第一列是索引或非统计列）  \n",
    "        counts = df[column].value_counts().to_dict()  \n",
    "        w_count = counts.get('W', 0)  \n",
    "        t_count = counts.get('T', 0)  \n",
    "        l_count = counts.get('L', 0)  \n",
    "        result[column] = f'{w_count}:{t_count}:{l_count}'  \n",
    "  \n",
    "    return result  \n",
    "  \n",
    "# 文件路径  \n",
    "file_path = 'Label_two.xlsx'  \n",
    "  \n",
    "# 需要处理的工作表名称  \n",
    "sheets = ['Lingjie', 'Shaohanh', 'Label3_8B']  # 假设另外两个工作表名为Sheet1和Sheet2，根据实际情况修改  \n",
    "  \n",
    "# 初始化一个DataFrame来存储所有结果  \n",
    "all_results = pd.DataFrame()  \n",
    "  \n",
    "# 处理每个工作表  \n",
    "for sheet in sheets:  \n",
    "    sheet_result = process_sheet(file_path, sheet)  \n",
    "    sheet_df = pd.DataFrame(list(sheet_result.items()), columns=['Model', sheet])  \n",
    "    if all_results.empty:  \n",
    "        all_results = sheet_df  \n",
    "    else:  \n",
    "        all_results = all_results.merge(sheet_df, on='Model', how='outer')  \n",
    "  \n",
    "# 将结果写入CSV文件  \n",
    "output_file = 'result.csv'  \n",
    "all_results.to_csv(output_file, index=False)  \n",
    "  \n",
    "print(f'Results have been written to {output_file}')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results have been written to result_70B.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_610907/3872925005.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_610907/3872925005.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_610907/3872925005.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "  \n",
    "def process_sheet(file_path, sheet_name):  \n",
    "    # 读取指定工作表  \n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)  \n",
    "  \n",
    "    # 将所有字符转换为大写  \n",
    "    df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)  \n",
    "  \n",
    "    # 初始化一个字典来存储每列的统计结果  \n",
    "    result = {}  \n",
    "  \n",
    "    # 遍历每一列并统计W:T:L的数量  \n",
    "    for column in df.columns[1:]:  # 跳过第一列（假设第一列是索引或非统计列）  \n",
    "        counts = df[column].value_counts().to_dict()  \n",
    "        w_count = counts.get('W', 0)  \n",
    "        t_count = counts.get('T', 0)  \n",
    "        l_count = counts.get('L', 0)  \n",
    "        result[column] = f'{w_count}:{t_count}:{l_count}'  \n",
    "  \n",
    "    return result  \n",
    "  \n",
    "# 文件路径  \n",
    "file_path = 'Label_two.xlsx'  \n",
    "  \n",
    "# 需要处理的工作表名称  \n",
    "sheets = ['Lingjie-70B', 'shaohanh-70B', 'Label3-70B']  # 假设另外两个工作表名为Sheet1和Sheet2，根据实际情况修改   \n",
    "  \n",
    "# 初始化一个DataFrame来存储所有结果  \n",
    "all_results = pd.DataFrame()  \n",
    "  \n",
    "# 处理每个工作表  \n",
    "for sheet in sheets:  \n",
    "    sheet_result = process_sheet(file_path, sheet)  \n",
    "    sheet_df = pd.DataFrame(list(sheet_result.items()), columns=['Model', sheet])  \n",
    "    if all_results.empty:  \n",
    "        all_results = sheet_df  \n",
    "    else:  \n",
    "        all_results = all_results.merge(sheet_df, on='Model', how='outer')  \n",
    "  \n",
    "# 将结果写入CSV文件  \n",
    "output_file = 'result_70B.csv'  \n",
    "all_results.to_csv(output_file, index=False)  \n",
    "  \n",
    "print(f'Results have been written to {output_file}')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged results have been written to merged_result.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "  \n",
    "# 读取第一个CSV文件  \n",
    "result_8B = pd.read_csv('result.csv')  \n",
    "  \n",
    "# 读取第二个CSV文件  \n",
    "result_70B = pd.read_csv('result_70B.csv')  \n",
    "  \n",
    "# 合并两个DataFrame  \n",
    "merged_results = pd.merge(result_8B, result_70B, on='Model', how='outer')  \n",
    "  \n",
    "# 将合并后的结果写入新的CSV文件  \n",
    "output_file = 'merged_result.csv'  \n",
    "merged_results.to_csv(output_file, index=False)  \n",
    "  \n",
    "print(f'Merged results have been written to {output_file}')  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "  \n",
    "def process_sheet(file_path, sheet_name):  \n",
    "    # 读取指定工作表  \n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)  \n",
    "  \n",
    "    # 将所有字符转换为大写  \n",
    "    df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)  \n",
    "  \n",
    "    # 初始化一个字典来存储每列的统计结果  \n",
    "    result = {}  \n",
    "  \n",
    "    # 遍历每一列并统计W:T:L的数量  \n",
    "    for column in df.columns[1:]:  # 跳过第一列（假设第一列是索引或非统计列）  \n",
    "        counts = df[column].value_counts().to_dict()  \n",
    "        w_count = counts.get('W', 0)  \n",
    "        t_count = counts.get('T', 0)  \n",
    "        l_count = counts.get('L', 0)  \n",
    "        result[column] = f'{w_count}:{t_count}:{l_count}'  \n",
    "  \n",
    "    return result  \n",
    "  \n",
    "# 文件路径  \n",
    "file_path = 'Label_two.xlsx'  \n",
    "  \n",
    "# 需要处理的工作表名称  \n",
    "sheets = ['Lingjie', 'Shaohanh', 'Label3_8B']  # 假设另外两个工作表名为Sheet1和Sheet2，根据实际情况修改  \n",
    "  \n",
    "# 初始化一个DataFrame来存储所有结果  \n",
    "all_results = pd.DataFrame()  \n",
    "  \n",
    "# 处理每个工作表  \n",
    "for sheet in sheets:  \n",
    "    sheet_result = process_sheet(file_path, sheet)  \n",
    "    sheet_df = pd.DataFrame(list(sheet_result.items()), columns=['Model', sheet])  \n",
    "    if all_results.empty:  \n",
    "        all_results = sheet_df  \n",
    "    else:  \n",
    "        all_results = all_results.merge(sheet_df, on='Model', how='outer')  \n",
    "  \n",
    "# 将结果写入CSV文件  \n",
    "output_file = 'result.csv'  \n",
    "all_results.to_csv(output_file, index=False)  \n",
    "  \n",
    "print(f'Results have been written to {output_file}')  \n",
    "\n",
    "import pandas as pd  \n",
    "  \n",
    "def process_sheet(file_path, sheet_name):  \n",
    "    # 读取指定工作表  \n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)  \n",
    "  \n",
    "    # 将所有字符转换为大写  \n",
    "    df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)  \n",
    "      \n",
    "    return df  \n",
    "  \n",
    "def calculate_agreement(df1, df2):  \n",
    "    # 确保两个DataFrame的索引和列对齐  \n",
    "    df1 = df1.set_index(df1.columns[0])  \n",
    "    df2 = df2.set_index(df2.columns[0])  \n",
    "      \n",
    "    agreements = {}  \n",
    "    for col in df1.columns:  \n",
    "        comparison = df1[col] == df2[col]  \n",
    "        agreements[col] = comparison.mean()  \n",
    "          \n",
    "    return agreements  \n",
    "  \n",
    "# 文件路径  \n",
    "file_path = 'Label_two.xlsx'  \n",
    "  \n",
    "# 需要处理的工作表名称  \n",
    "sheets = ['Lingjie-70B', 'shaohanh-70B', 'Label3-70B']  # 假设另外两个工作表名为Sheet1和Sheet2，根据实际情况修改  \n",
    "  \n",
    "# 读取所有的表  \n",
    "dfs = {sheet: process_sheet(file_path, sheet) for sheet in sheets}  \n",
    "  \n",
    "# 计算每对工作表的一致性  \n",
    "results = {}  \n",
    "for i, sheet1 in enumerate(sheets):  \n",
    "    for j, sheet2 in enumerate(sheets):  \n",
    "        if i < j:  \n",
    "            agreement = calculate_agreement(dfs[sheet1], dfs[sheet2])  \n",
    "            results[f'{sheet1} vs {sheet2}'] = agreement  \n",
    "  \n",
    "# 将结果转换为DataFrame  \n",
    "agreement_df = pd.DataFrame(results).T  \n",
    "  \n",
    "# 计算每列的平均一致性  \n",
    "agreement_df['Average'] = agreement_df.mean(axis=1)  \n",
    "  \n",
    "# 将结果写入CSV文件  \n",
    "output_file = 'agreement_result_2.csv'  \n",
    "agreement_df.to_csv(output_file)  \n",
    "  \n",
    "print(f'Results have been written to {output_file}')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "  \n",
    "def process_sheet(file_path, sheet_name):  \n",
    "    # 读取指定工作表  \n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)  \n",
    "  \n",
    "    # 将所有字符转换为大写  \n",
    "    df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)  \n",
    "  \n",
    "    # 初始化一个字典来存储每列的统计结果  \n",
    "    result = {}  \n",
    "  \n",
    "    # 遍历每一列并统计W:T:L的数量  \n",
    "    for column in df.columns[1:]:  # 跳过第一列（假设第一列是索引或非统计列）  \n",
    "        counts = df[column].value_counts().to_dict()  \n",
    "        w_count = counts.get('W', 0)  \n",
    "        t_count = counts.get('T', 0)  \n",
    "        l_count = counts.get('L', 0)  \n",
    "        result[column] = f'{w_count}:{t_count}:{l_count}'  \n",
    "  \n",
    "    return result  \n",
    "  \n",
    "# 文件路径  \n",
    "file_path = 'Label_two.xlsx'  \n",
    "  \n",
    "# 需要处理的工作表名称  \n",
    "sheets = ['Lingjie', 'Shaohanh', 'Label3_8B']  # 假设另外两个工作表名为Sheet1和Sheet2，根据实际情况修改  \n",
    "  \n",
    "# 初始化一个DataFrame来存储所有结果  \n",
    "all_results = pd.DataFrame()  \n",
    "  \n",
    "# 处理每个工作表  \n",
    "for sheet in sheets:  \n",
    "    sheet_result = process_sheet(file_path, sheet)  \n",
    "    sheet_df = pd.DataFrame(list(sheet_result.items()), columns=['Model', sheet])  \n",
    "    if all_results.empty:  \n",
    "        all_results = sheet_df  \n",
    "    else:  \n",
    "        all_results = all_results.merge(sheet_df, on='Model', how='outer')  \n",
    "  \n",
    "# 将结果写入CSV文件  \n",
    "output_file = 'result.csv'  \n",
    "all_results.to_csv(output_file, index=False)  \n",
    "  \n",
    "print(f'Results have been written to {output_file}')  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "  \n",
    "def process_sheet(file_path, sheet_name):  \n",
    "    # 读取指定工作表  \n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)  \n",
    "  \n",
    "    # 将所有字符转换为大写  \n",
    "    df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)  \n",
    "  \n",
    "    # 初始化一个字典来存储每列的统计结果  \n",
    "    result = {}  \n",
    "  \n",
    "    # 遍历每一列并统计W:T:L的数量  \n",
    "    for column in df.columns[1:]:  # 跳过第一列（假设第一列是索引或非统计列）  \n",
    "        counts = df[column].value_counts().to_dict()  \n",
    "        w_count = counts.get('W', 0)  \n",
    "        t_count = counts.get('T', 0)  \n",
    "        l_count = counts.get('L', 0)  \n",
    "        result[column] = f'{w_count}:{t_count}:{l_count}'  \n",
    "  \n",
    "    return result  \n",
    "  \n",
    "# 文件路径  \n",
    "file_path = 'Label_two.xlsx'  \n",
    "  \n",
    "# 需要处理的工作表名称  \n",
    "sheets = ['Lingjie', 'Shaohanh', 'Label3_8B']  # 假设另外两个工作表名为Sheet1和Sheet2，根据实际情况修改  \n",
    "  \n",
    "# 初始化一个DataFrame来存储所有结果  \n",
    "all_results = pd.DataFrame()  \n",
    "  \n",
    "# 处理每个工作表  \n",
    "for sheet in sheets:  \n",
    "    sheet_result = process_sheet(file_path, sheet)  \n",
    "    sheet_df = pd.DataFrame(list(sheet_result.items()), columns=['Model', sheet])  \n",
    "    if all_results.empty:  \n",
    "        all_results = sheet_df  \n",
    "    else:  \n",
    "        all_results = all_results.merge(sheet_df, on='Model', how='outer')  \n",
    "  \n",
    "# 将结果写入CSV文件  \n",
    "output_file = 'result.csv'  \n",
    "all_results.to_csv(output_file, index=False)  \n",
    "  \n",
    "print(f'Results have been written to {output_file}')  \n",
    "\n",
    "\n",
    "import pandas as pd  \n",
    "  \n",
    "def process_sheet(file_path, sheet_name):  \n",
    "    # 读取指定工作表  \n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)  \n",
    "  \n",
    "    # 将所有字符转换为大写  \n",
    "    df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)  \n",
    "  \n",
    "    # 初始化一个字典来存储每列的统计结果  \n",
    "    result = {}  \n",
    "  \n",
    "    # 遍历每一列并统计W:T:L的数量  \n",
    "    for column in df.columns[1:]:  # 跳过第一列（假设第一列是索引或非统计列）  \n",
    "        counts = df[column].value_counts().to_dict()  \n",
    "        w_count = counts.get('W', 0)  \n",
    "        t_count = counts.get('T', 0)  \n",
    "        l_count = counts.get('L', 0)  \n",
    "        result[column] = f'{w_count}:{t_count}:{l_count}'  \n",
    "  \n",
    "    return result  \n",
    "  \n",
    "# 文件路径  \n",
    "file_path = 'Label_two.xlsx'  \n",
    "  \n",
    "# 需要处理的工作表名称  \n",
    "sheets = ['Lingjie-70B', 'shaohanh-70B', 'Label3-70B']  # 假设另外两个工作表名为Sheet1和Sheet2，根据实际情况修改   \n",
    "  \n",
    "# 初始化一个DataFrame来存储所有结果  \n",
    "all_results = pd.DataFrame()  \n",
    "  \n",
    "# 处理每个工作表  \n",
    "for sheet in sheets:  \n",
    "    sheet_result = process_sheet(file_path, sheet)  \n",
    "    sheet_df = pd.DataFrame(list(sheet_result.items()), columns=['Model', sheet])  \n",
    "    if all_results.empty:  \n",
    "        all_results = sheet_df  \n",
    "    else:  \n",
    "        all_results = all_results.merge(sheet_df, on='Model', how='outer')  \n",
    "  \n",
    "# 将结果写入CSV文件  \n",
    "output_file = 'result_70B.csv'  \n",
    "all_results.to_csv(output_file, index=False)  \n",
    "  \n",
    "print(f'Results have been written to {output_file}')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results have been written to result.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_717019/4245012563.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/4245012563.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/4245012563.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/4245012563.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/4245012563.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/4245012563.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd    \n",
    "  \n",
    "def process_sheet(file_path, sheet_name):    \n",
    "    # 读取指定工作表    \n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)    \n",
    "  \n",
    "    # 将所有字符转换为大写    \n",
    "    df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)    \n",
    "  \n",
    "    # 初始化一个字典来存储每列的统计结果    \n",
    "    result = {}    \n",
    "  \n",
    "    # 遍历每一列并统计W:T:L的数量    \n",
    "    for column in df.columns[1:]:  # 跳过第一列（假设第一列是索引或非统计列）    \n",
    "        counts = df[column].value_counts().to_dict()    \n",
    "        w_count = counts.get('W', 0)    \n",
    "        t_count = counts.get('T', 0)    \n",
    "        l_count = counts.get('L', 0)    \n",
    "        result[column] = f'{w_count}:{t_count}:{l_count}'    \n",
    "  \n",
    "    return result    \n",
    "  \n",
    "def process_all_sheets(file_path, sheets):    \n",
    "    # 初始化一个DataFrame来存储所有结果    \n",
    "    all_results = pd.DataFrame()    \n",
    "  \n",
    "    # 处理每个工作表    \n",
    "    for sheet in sheets:    \n",
    "        sheet_result = process_sheet(file_path, sheet)    \n",
    "        sheet_df = pd.DataFrame(list(sheet_result.items()), columns=['Model', sheet])    \n",
    "        if all_results.empty:    \n",
    "            all_results = sheet_df    \n",
    "        else:    \n",
    "            all_results = pd.merge(all_results, sheet_df, on='Model', how='outer')    \n",
    "  \n",
    "    return all_results  \n",
    "  \n",
    "# 文件路径    \n",
    "file_path = 'Label_two.xlsx'    \n",
    "  \n",
    "# 需要处理的工作表名称    \n",
    "sheets1 = ['Lingjie', 'Shaohanh', 'Label3_8B']    \n",
    "sheets2 = ['Lingjie-70B', 'shaohanh-70B', 'Label3-70B']    \n",
    "  \n",
    "results1 = process_all_sheets(file_path, sheets1)  \n",
    "results2 = process_all_sheets(file_path, sheets2)  \n",
    "  \n",
    "# 合并结果  \n",
    "all_results = pd.merge(results1, results2, on='Model', how='outer')  \n",
    "  \n",
    "# 将结果写入CSV文件    \n",
    "output_file = 'result.csv'    \n",
    "all_results.to_csv(output_file, index=False)    \n",
    "  \n",
    "print(f'Results have been written to {output_file}')    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results have been written to result_2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_717019/1442869200.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/1442869200.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/1442869200.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/1442869200.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/1442869200.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/1442869200.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd    \n",
    "  \n",
    "def process_sheet(file_path, sheet_name):    \n",
    "    # 读取指定工作表    \n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)    \n",
    "  \n",
    "    # 将所有字符转换为大写    \n",
    "    df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)    \n",
    "  \n",
    "    # 初始化一个字典来存储每列的统计结果    \n",
    "    result = {}    \n",
    "  \n",
    "    # 遍历每一列并统计W:T:L的数量    \n",
    "    for column in df.columns[1:]:  # 跳过第一列（假设第一列是索引或非统计列）    \n",
    "        counts = df[column].value_counts().to_dict()    \n",
    "        w_count = counts.get('W', 0)    \n",
    "        t_count = counts.get('T', 0)    \n",
    "        l_count = counts.get('L', 0)    \n",
    "        result[column] = f'{w_count}:{t_count}:{l_count}'    \n",
    "  \n",
    "    return result    \n",
    "  \n",
    "def process_all_sheets(file_path, sheets):    \n",
    "    # 初始化一个DataFrame来存储所有结果    \n",
    "    all_results = pd.DataFrame()    \n",
    "  \n",
    "    # 处理每个工作表    \n",
    "    for sheet in sheets:    \n",
    "        sheet_result = process_sheet(file_path, sheet)    \n",
    "        sheet_df = pd.DataFrame(list(sheet_result.items()), columns=['Model', sheet])    \n",
    "        if all_results.empty:    \n",
    "            all_results = sheet_df    \n",
    "        else:    \n",
    "            all_results = pd.merge(all_results, sheet_df, on='Model', how='outer')    \n",
    "  \n",
    "    return all_results  \n",
    "  \n",
    "# 文件路径    \n",
    "file_path = 'Label_2.xlsx'    \n",
    "  \n",
    "# 需要处理的工作表名称    \n",
    "sheets1 = ['Lingjie', 'Shaohanh', 'Label3_8B']    \n",
    "sheets2 = ['Lingjie-70B', 'shaohanh-70B', 'Label3-70B']    \n",
    "  \n",
    "results1 = process_all_sheets(file_path, sheets1)  \n",
    "results2 = process_all_sheets(file_path, sheets2)  \n",
    "  \n",
    "# 合并结果  \n",
    "all_results = pd.merge(results1, results2, on='Model', how='outer')  \n",
    "  \n",
    "# 将结果写入CSV文件    \n",
    "output_file = 'result_2.csv'    \n",
    "all_results.to_csv(output_file, index=False)    \n",
    "  \n",
    "print(f'Results have been written to {output_file}')    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results have been written to result3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_717019/79655812.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/79655812.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/79655812.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/79655812.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/79655812.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/79655812.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd    \n",
    "  \n",
    "def process_sheet(file_path, sheet_name):    \n",
    "    # 读取指定工作表    \n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)    \n",
    "  \n",
    "    # 将所有字符转换为大写    \n",
    "    df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)    \n",
    "  \n",
    "    # 初始化一个字典来存储每列的统计结果    \n",
    "    result = {}    \n",
    "  \n",
    "    # 遍历每一列并统计W:T:L的数量    \n",
    "    for column in df.columns[1:]:  # 跳过第一列（假设第一列是索引或非统计列）    \n",
    "        counts = df[column].value_counts().to_dict()    \n",
    "        w_count = counts.get('W', 0)    \n",
    "        t_count = counts.get('T', 0)    \n",
    "        l_count = counts.get('L', 0)    \n",
    "        result[column] = f'{w_count}:{t_count}:{l_count}'    \n",
    "  \n",
    "    return result    \n",
    "  \n",
    "def process_all_sheets(file_path, sheets):    \n",
    "    # 初始化一个DataFrame来存储所有结果    \n",
    "    all_results = pd.DataFrame()    \n",
    "  \n",
    "    # 处理每个工作表    \n",
    "    for sheet in sheets:    \n",
    "        sheet_result = process_sheet(file_path, sheet)    \n",
    "        sheet_df = pd.DataFrame(list(sheet_result.items()), columns=['Model', sheet])    \n",
    "        if all_results.empty:    \n",
    "            all_results = sheet_df    \n",
    "        else:    \n",
    "            all_results = pd.merge(all_results, sheet_df, on='Model', how='outer')    \n",
    "  \n",
    "    return all_results  \n",
    "  \n",
    "# 文件路径    \n",
    "file_path = 'Label_two.xlsx'    \n",
    "  \n",
    "# 需要处理的工作表名称    \n",
    "sheets1 = ['Lingjie', 'Shaohanh', 'Label3_8B']    \n",
    "sheets2 = ['Lingjie-70B', 'shaohanh-70B', 'Label3-70B']    \n",
    "  \n",
    "results1 = process_all_sheets(file_path, sheets1)  \n",
    "results2 = process_all_sheets(file_path, sheets2)  \n",
    "  \n",
    "# 合并结果  \n",
    "all_results = pd.merge(results1, results2, on='Model', how='outer')  \n",
    "  \n",
    "# 计算每个表格W:T:L的总和和平均值  \n",
    "for sheet in all_results.columns[1:]:  \n",
    "    all_results[sheet+\"_sum\"] = all_results[sheet].apply(lambda x: sum(map(int, str(x).split(\":\"))))  \n",
    "    all_results[sheet+\"_average\"] = all_results[sheet].apply(lambda x: round(sum(map(int, str(x).split(\":\")))/3, 2))  \n",
    "  \n",
    "# 将结果写入CSV文件    \n",
    "output_file = 'result3.csv'    \n",
    "all_results.to_csv(output_file, index=False)    \n",
    "  \n",
    "print(f'Results have been written to {output_file}')    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results have been written to result1.csv and result2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_717019/2704018744.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/2704018744.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/2704018744.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/2704018744.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/2704018744.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/2704018744.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "  \n",
    "def process_sheet(file_path, sheet_name):  \n",
    "    # 读取指定工作表  \n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)  \n",
    "  \n",
    "    # 将所有字符转换为大写  \n",
    "    df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)  \n",
    "  \n",
    "    # 遍历每一列并统计W:T:L的数量  \n",
    "    for column in df.columns[1:]:  # 跳过第一列（假设第一列是索引或非统计列）  \n",
    "        counts = df[column].value_counts().to_dict()  \n",
    "        w_count = counts.get('W', 0)  \n",
    "        t_count = counts.get('T', 0)  \n",
    "        l_count = counts.get('L', 0)  \n",
    "        df[column] = f'{w_count}:{t_count}:{l_count}'  \n",
    "  \n",
    "    return df  \n",
    "  \n",
    "def process_all_sheets(file_path, sheets):  \n",
    "    # 初始化一个DataFrame来存储所有结果  \n",
    "    all_results = pd.DataFrame()  \n",
    "  \n",
    "    # 处理每个工作表  \n",
    "    for sheet in sheets:  \n",
    "        sheet_df = process_sheet(file_path, sheet)  \n",
    "        if all_results.empty:  \n",
    "            all_results = sheet_df  \n",
    "        else:  \n",
    "            all_results = pd.concat([all_results, sheet_df], ignore_index=True)  \n",
    "  \n",
    "    # 计算每一列的W:T:L的总和和平均值  \n",
    "    for column in all_results.columns[1:]:  \n",
    "        all_results[column+\"_sum\"] = all_results[column].apply(lambda x: sum(map(int, str(x).split(\":\"))))  \n",
    "        all_results[column+\"_average\"] = all_results[column].apply(lambda x: round(sum(map(int, str(x).split(\":\")))/3, 2))  \n",
    "  \n",
    "    return all_results  \n",
    "  \n",
    "# 文件路径  \n",
    "file_path = 'Label_two.xlsx'  \n",
    "  \n",
    "# 需要处理的工作表名称  \n",
    "sheets1 = ['Lingjie', 'Shaohanh', 'Label3_8B']  \n",
    "sheets2 = ['Lingjie-70B', 'shaohanh-70B', 'Label3-70B']  \n",
    "  \n",
    "results1 = process_all_sheets(file_path, sheets1)  \n",
    "results2 = process_all_sheets(file_path, sheets2)  \n",
    "  \n",
    "# 将结果写入CSV文件  \n",
    "output_file1 = 'result1.csv'  \n",
    "results1.to_csv(output_file1, index=False)  \n",
    "  \n",
    "output_file2 = 'result2.csv'  \n",
    "results2.to_csv(output_file2, index=False)  \n",
    "  \n",
    "print(f'Results have been written to {output_file1} and {output_file2}')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_717019/448725002.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/448725002.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/448725002.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/448725002.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/448725002.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/448725002.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "  \n",
    "def process_sheet(file_path, sheet_name):      \n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)      \n",
    "    df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)      \n",
    "    result = {}      \n",
    "    \n",
    "    for column in df.columns[1:]:  \n",
    "        counts = df[column].value_counts().to_dict()      \n",
    "        w_count = counts.get('W', 0)      \n",
    "        t_count = counts.get('T', 0)      \n",
    "        l_count = counts.get('L', 0)      \n",
    "        result[column] = f'{w_count}:{t_count}:{l_count}'      \n",
    "    \n",
    "    return result      \n",
    "  \n",
    "def process_all_sheets(file_path, sheets):      \n",
    "    all_results = pd.DataFrame()      \n",
    "  \n",
    "    for sheet in sheets:      \n",
    "        sheet_result = process_sheet(file_path, sheet)      \n",
    "        sheet_df = pd.DataFrame(list(sheet_result.items()), columns=['Model', sheet])      \n",
    "        if all_results.empty:      \n",
    "            all_results = sheet_df      \n",
    "        else:      \n",
    "            all_results = pd.merge(all_results, sheet_df, on='Model', how='outer')      \n",
    "    \n",
    "    return all_results    \n",
    "  \n",
    "def process_wtl(wtl_str):  \n",
    "    w, t, l = map(int, wtl_str.split(':'))  \n",
    "    return w, t, l  \n",
    "  \n",
    "file_path = 'Label_2.xlsx'      \n",
    "sheets1 = ['Lingjie', 'Shaohanh', 'Label3_8B']      \n",
    "sheets2 = ['Lingjie-70B', 'shaohanh-70B', 'Label3-70B']      \n",
    "  \n",
    "results1 = process_all_sheets(file_path, sheets1)    \n",
    "results2 = process_all_sheets(file_path, sheets2)    \n",
    "  \n",
    "all_results = pd.merge(results1, results2, on='Model', how='outer')    \n",
    "  \n",
    "groups = [sheets1, sheets2]  \n",
    "for group in groups:  \n",
    "    for column in group:  \n",
    "        all_results[[f'{column}_W', f'{column}_T', f'{column}_L']] = all_results[column].apply(process_wtl).apply(pd.Series)  \n",
    "  \n",
    "    group_columns = [f'{column}_W' for column in group] + [f'{column}_T' for column in group] + [f'{column}_L' for column in group]  \n",
    "    all_results[f'{group[0]}_group_sum'] = all_results[group_columns].sum(axis=1)  \n",
    "    all_results[f'{group[0]}_group_avg'] = all_results[group_columns].mean(axis=1)  \n",
    "  \n",
    "all_results.to_csv('result_2_group_sum_avg.csv', index=False)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_717019/4063661493.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/4063661493.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/4063661493.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/4063661493.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/4063661493.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/4063661493.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "  \n",
    "def process_sheet(file_path, sheet_name):      \n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)      \n",
    "    df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)      \n",
    "    result = {}      \n",
    "    \n",
    "    for column in df.columns[1:]:  \n",
    "        counts = df[column].value_counts().to_dict()      \n",
    "        w_count = counts.get('W', 0)      \n",
    "        t_count = counts.get('T', 0)      \n",
    "        l_count = counts.get('L', 0)      \n",
    "        result[column] = f'{w_count}:{t_count}:{l_count}'      \n",
    "    \n",
    "    return result      \n",
    "  \n",
    "def process_all_sheets(file_path, sheets):      \n",
    "    all_results = pd.DataFrame()      \n",
    "  \n",
    "    for sheet in sheets:      \n",
    "        sheet_result = process_sheet(file_path, sheet)      \n",
    "        sheet_df = pd.DataFrame(list(sheet_result.items()), columns=['Model', sheet])      \n",
    "        if all_results.empty:      \n",
    "            all_results = sheet_df      \n",
    "        else:      \n",
    "            all_results = pd.merge(all_results, sheet_df, on='Model', how='outer')      \n",
    "    \n",
    "    return all_results    \n",
    "  \n",
    "def process_wtl(wtl_str):  \n",
    "    w, t, l = map(int, wtl_str.split(':'))  \n",
    "    return w, t, l  \n",
    "  \n",
    "file_path = 'Label_2.xlsx'      \n",
    "sheets1 = ['Lingjie', 'Shaohanh', 'Label3_8B']      \n",
    "sheets2 = ['Lingjie-70B', 'shaohanh-70B', 'Label3-70B']      \n",
    "  \n",
    "results1 = process_all_sheets(file_path, sheets1)    \n",
    "results2 = process_all_sheets(file_path, sheets2)    \n",
    "  \n",
    "all_results = pd.merge(results1, results2, on='Model', how='outer')    \n",
    "  \n",
    "groups = [sheets1, sheets2]  \n",
    "for group in groups:  \n",
    "    group_results = pd.DataFrame()  \n",
    "    for column in group:  \n",
    "        group_results[[f'{column}_W', f'{column}_T', f'{column}_L']] = all_results[column].apply(process_wtl).apply(pd.Series)  \n",
    "  \n",
    "    all_results[f'{group[0]}_group_sum'] = group_results.sum(axis=1)  \n",
    "    all_results[f'{group[0]}_group_avg'] = group_results.mean(axis=1)  \n",
    "  \n",
    "all_results.to_csv('result_2_group_sum_avg.csv', index=False)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_717019/3729521858.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/3729521858.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/3729521858.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/3729521858.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/3729521858.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/3729521858.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "  \n",
    "def process_sheet(file_path, sheet_name):      \n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)      \n",
    "    df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)      \n",
    "    result = {}      \n",
    "    \n",
    "    for column in df.columns[1:]:  \n",
    "        counts = df[column].value_counts().to_dict()      \n",
    "        w_count = counts.get('W', 0)      \n",
    "        t_count = counts.get('T', 0)      \n",
    "        l_count = counts.get('L', 0)      \n",
    "        result[column] = f'{w_count}:{t_count}:{l_count}'      \n",
    "    \n",
    "    return result      \n",
    "  \n",
    "def process_all_sheets(file_path, sheets):      \n",
    "    all_results = pd.DataFrame()      \n",
    "  \n",
    "    for sheet in sheets:      \n",
    "        sheet_result = process_sheet(file_path, sheet)      \n",
    "        sheet_df = pd.DataFrame(list(sheet_result.items()), columns=['Model', sheet])      \n",
    "        if all_results.empty:      \n",
    "            all_results = sheet_df      \n",
    "        else:      \n",
    "            all_results = pd.merge(all_results, sheet_df, on='Model', how='outer')      \n",
    "    \n",
    "    return all_results    \n",
    "  \n",
    "def process_wtl(wtl_str):  \n",
    "    w, t, l = map(int, wtl_str.split(':'))  \n",
    "    return w, t, l  \n",
    "  \n",
    "file_path = 'Label_2.xlsx'      \n",
    "sheets1 = ['Lingjie', 'Shaohanh', 'Label3_8B']   \n",
    "sheets2 = ['Lingjie-70B', 'shaohanh-70B', 'Label3-70B']     \n",
    "  \n",
    "results1 = process_all_sheets(file_path, sheets1)    \n",
    "results2 = process_all_sheets(file_path, sheets2)    \n",
    "  \n",
    "all_results = pd.merge(results1, results2, on='Model', how='outer')    \n",
    "  \n",
    "for index, row in all_results.iterrows():  \n",
    "    w_sum = t_sum = l_sum = 0  \n",
    "    for column in sheets1:  \n",
    "        w, t, l = process_wtl(row[column])  \n",
    "        w_sum += w  \n",
    "        t_sum += t  \n",
    "        l_sum += l  \n",
    "    all_results.loc[index, 'group_1_sum'] = f'{w_sum}:{t_sum}:{l_sum}'  \n",
    "    all_results.loc[index, 'group_1_avg'] = f'{w_sum//len(sheets1)}:{t_sum//len(sheets1)}:{l_sum//len(sheets1)}'  \n",
    "  \n",
    "    w_sum = t_sum = l_sum = 0  \n",
    "    for column in sheets2:  \n",
    "        w, t, l = process_wtl(row[column])  \n",
    "        w_sum += w  \n",
    "        t_sum += t  \n",
    "        l_sum += l  \n",
    "    all_results.loc[index, 'group_2_sum'] = f'{w_sum}:{t_sum}:{l_sum}'  \n",
    "    all_results.loc[index, 'group_2_avg'] = f'{w_sum//len(sheets2)}:{t_sum//len(sheets2)}:{l_sum//len(sheets2)}'  \n",
    "  \n",
    "all_results.to_csv('result_2_group_sum_avg.csv', index=False)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_717019/1244520072.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/1244520072.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/1244520072.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/1244520072.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/1244520072.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/1244520072.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "  \n",
    "def process_sheet(file_path, sheet_name):  \n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)  \n",
    "    df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)  \n",
    "    result = {}  \n",
    "  \n",
    "    for column in df.columns[1:]:  \n",
    "        counts = df[column].value_counts().to_dict()  \n",
    "        w_count = counts.get('W', 0)  \n",
    "        t_count = counts.get('T', 0)  \n",
    "        l_count = counts.get('L', 0)  \n",
    "        result[column] = f'{w_count}:{t_count}:{l_count}'  \n",
    "  \n",
    "    return result  \n",
    "  \n",
    "def process_all_sheets(file_path, sheets):  \n",
    "    all_results = pd.DataFrame()  \n",
    "  \n",
    "    for sheet in sheets:  \n",
    "        sheet_result = process_sheet(file_path, sheet)  \n",
    "        sheet_df = pd.DataFrame(list(sheet_result.items()), columns=['Model', sheet])  \n",
    "        if all_results.empty:  \n",
    "            all_results = sheet_df  \n",
    "        else:  \n",
    "            all_results = pd.merge(all_results, sheet_df, on='Model', how='outer')  \n",
    "  \n",
    "    return all_results  \n",
    "  \n",
    "def process_wtl(wtl_str):  \n",
    "    w, t, l = map(int, wtl_str.split(':'))  \n",
    "    return w, t, l  \n",
    "  \n",
    "file_path = 'Label_2.xlsx'  \n",
    "sheets1 = ['Lingjie', 'Shaohanh', 'Label3_8B']  \n",
    "sheets2 = ['Lingjie-70B', 'shaohanh-70B', 'Label3-70B']  \n",
    "  \n",
    "results1 = process_all_sheets(file_path, sheets1)  \n",
    "results2 = process_all_sheets(file_path, sheets2)  \n",
    "  \n",
    "all_results = pd.merge(results1, results2, on='Model', how='outer')  \n",
    "  \n",
    "for index, row in all_results.iterrows():  \n",
    "    w_sum = t_sum = l_sum = 0  \n",
    "    for column in sheets1:  \n",
    "        w, t, l = process_wtl(row[column])  \n",
    "        w_sum += w  \n",
    "        t_sum += t  \n",
    "        l_sum += l  \n",
    "    all_results.loc[index, 'group_1_sum'] = f'{w_sum}:{t_sum}:{l_sum}'  \n",
    "    all_results.loc[index, 'group_1_avg'] = f'{w_sum/len(sheets1):.1f}:{t_sum/len(sheets1):.1f}:{l_sum/len(sheets1):.1f}'  \n",
    "  \n",
    "    w_sum = t_sum = l_sum = 0  \n",
    "    for column in sheets2:  \n",
    "        w, t, l = process_wtl(row[column])  \n",
    "        w_sum += w  \n",
    "        t_sum += t  \n",
    "        l_sum += l  \n",
    "    all_results.loc[index, 'group_2_sum'] = f'{w_sum}:{t_sum}:{l_sum}'  \n",
    "    all_results.loc[index, 'group_2_avg'] = f'{w_sum/len(sheets2):.1f}:{t_sum/len(sheets2):.1f}:{l_sum/len(sheets2):.1f}'  \n",
    "  \n",
    "all_results.to_csv('result_2_group_sum_avg.csv', index=False)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results have been written to agreement_result.csv\n",
      "Results have been written to agreement_result_2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_717019/2301225137.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/2301225137.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/2301225137.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/2301225137.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/2301225137.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/2301225137.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "  \n",
    "def process_sheet(file_path, sheet_name):    \n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)    \n",
    "    df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)  \n",
    "    return df    \n",
    "  \n",
    "def calculate_agreement(df1, df2):    \n",
    "    df1 = df1.set_index(df1.columns[0])    \n",
    "    df2 = df2.set_index(df2.columns[0])    \n",
    "        \n",
    "    agreements = {}    \n",
    "    for col in df1.columns:    \n",
    "        comparison = df1[col] == df2[col]    \n",
    "        agreements[col] = comparison.mean()  \n",
    "    return agreements    \n",
    "  \n",
    "# 文件路径    \n",
    "file_path = 'Label_2.xlsx'    \n",
    "  \n",
    "# 需要处理的工作表名称和输出文件名  \n",
    "sheets_and_output_files = [  \n",
    "    (['Lingjie', 'Shaohanh', 'Label3_8B'], 'agreement_result.csv'),  \n",
    "    (['Lingjie-70B', 'shaohanh-70B', 'Label3-70B'], 'agreement_result_2.csv')  \n",
    "]  \n",
    "  \n",
    "for sheets, output_file in sheets_and_output_files:  \n",
    "    # 读取所有的表    \n",
    "    dfs = {sheet: process_sheet(file_path, sheet) for sheet in sheets}    \n",
    "  \n",
    "    # 计算每对工作表的一致性    \n",
    "    results = {}    \n",
    "    for i, sheet1 in enumerate(sheets):    \n",
    "        for j, sheet2 in enumerate(sheets):    \n",
    "            if i < j:    \n",
    "                agreement = calculate_agreement(dfs[sheet1], dfs[sheet2])    \n",
    "                results[f'{sheet1} vs {sheet2}'] = agreement    \n",
    "  \n",
    "    # 将结果转换为DataFrame    \n",
    "    agreement_df = pd.DataFrame(results).T    \n",
    "  \n",
    "    # 计算每列的平均一致性    \n",
    "    agreement_df['Average'] = agreement_df.mean(axis=1)    \n",
    "  \n",
    "    # 将结果写入CSV文件    \n",
    "    agreement_df.to_csv(output_file)    \n",
    "  \n",
    "    print(f'Results have been written to {output_file}')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Unnamed: 0  Meta-Llama-3.1-8B-Instruct  \\\n",
      "0    Lingjie vs Shaohanh                        0.72   \n",
      "1   Lingjie vs Label3_8B                        0.70   \n",
      "2  Shaohanh vs Label3_8B                        0.74   \n",
      "\n",
      "   Meta-Llama-3.1-70B-Instruct  Qwen2-72B-Instruct  tulu-2-dpo-70b  Average  \n",
      "0                         0.66                0.76            0.88   0.7825  \n",
      "1                         0.74                0.84            0.92   0.8100  \n",
      "2                         0.68                0.76            0.92   0.7875  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "  \n",
    "# 读取CSV文件  \n",
    "file1 = 'agreement_result.csv'  \n",
    "file2 = 'agreement_result_2.csv'  \n",
    "  \n",
    "df1 = pd.read_csv(file1)  \n",
    "df2 = pd.read_csv(file2)  \n",
    "  \n",
    "# 提取最后一列  \n",
    "last_col1 = df1.iloc[:, -1]  \n",
    "last_col2 = df2.iloc[:, -1]  \n",
    "  \n",
    "# 计算对应行的平均值  \n",
    "average_col = (last_col1 + last_col2) / 2  \n",
    "  \n",
    "# 将结果放在第三列  \n",
    "df1['Average'] = average_col  \n",
    "  \n",
    "# 保存结果到新的CSV文件  \n",
    "df1.to_csv('agreement_result_with_average.csv', index=False)  \n",
    "  \n",
    "print(df1)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "将这个代码中的平均结果写入到另外一个csv中，列名w1，t1,l1,w2,t2,l2\n",
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "  \n",
    "def process_sheet(file_path, sheet_name):  \n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)  \n",
    "    df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)  \n",
    "    result = {}  \n",
    "  \n",
    "    for column in df.columns[1:]:  \n",
    "        counts = df[column].value_counts().to_dict()  \n",
    "        w_count = counts.get('W', 0)  \n",
    "        t_count = counts.get('T', 0)  \n",
    "        l_count = counts.get('L', 0)  \n",
    "        result[column] = f'{w_count}:{t_count}:{l_count}'  \n",
    "  \n",
    "    return result  \n",
    "  \n",
    "def process_all_sheets(file_path, sheets):  \n",
    "    all_results = pd.DataFrame()  \n",
    "  \n",
    "    for sheet in sheets:  \n",
    "        sheet_result = process_sheet(file_path, sheet)  \n",
    "        sheet_df = pd.DataFrame(list(sheet_result.items()), columns=['Model', sheet])  \n",
    "        if all_results.empty:  \n",
    "            all_results = sheet_df  \n",
    "        else:  \n",
    "            all_results = pd.merge(all_results, sheet_df, on='Model', how='outer')  \n",
    "  \n",
    "    return all_results  \n",
    "  \n",
    "def process_wtl(wtl_str):  \n",
    "    w, t, l = map(int, wtl_str.split(':'))  \n",
    "    return w, t, l  \n",
    "  \n",
    "file_path = 'Label_2.xlsx'  \n",
    "sheets1 = ['Lingjie', 'Shaohanh', 'Label3_8B']  \n",
    "sheets2 = ['Lingjie-70B', 'shaohanh-70B', 'Label3-70B']  \n",
    "  \n",
    "results1 = process_all_sheets(file_path, sheets1)  \n",
    "results2 = process_all_sheets(file_path, sheets2)  \n",
    "  \n",
    "all_results = pd.merge(results1, results2, on='Model', how='outer')  \n",
    "  \n",
    "for index, row in all_results.iterrows():  \n",
    "    w_sum = t_sum = l_sum = 0  \n",
    "    for column in sheets1:  \n",
    "        w, t, l = process_wtl(row[column])  \n",
    "        w_sum += w  \n",
    "        t_sum += t  \n",
    "        l_sum += l  \n",
    "    all_results.loc[index, 'group_1_sum'] = f'{w_sum}:{t_sum}:{l_sum}'  \n",
    "    all_results.loc[index, 'group_1_avg'] = f'{w_sum/len(sheets1):.1f}:{t_sum/len(sheets1):.1f}:{l_sum/len(sheets1):.1f}'  \n",
    "  \n",
    "    w_sum = t_sum = l_sum = 0  \n",
    "    for column in sheets2:  \n",
    "        w, t, l = process_wtl(row[column])  \n",
    "        w_sum += w  \n",
    "        t_sum += t  \n",
    "        l_sum += l  \n",
    "    all_results.loc[index, 'group_2_sum'] = f'{w_sum}:{t_sum}:{l_sum}'  \n",
    "    all_results.loc[index, 'group_2_avg'] = f'{w_sum/len(sheets2):.1f}:{t_sum/len(sheets2):.1f}:{l_sum/len(sheets2):.1f}'  \n",
    "  \n",
    "all_results.to_csv('result_2_group_sum_avg.csv', index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_717019/2766127693.py:7: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/2766127693.py:7: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/2766127693.py:7: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/2766127693.py:7: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/2766127693.py:7: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/2766127693.py:7: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "# 将这个代码中的平均结果写入到另外一个csv中，列名w1，t1,l1,w2,t2,l2\n",
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "  \n",
    "def process_sheet(file_path, sheet_name):  \n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)  \n",
    "    df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)  \n",
    "    result = {}  \n",
    "  \n",
    "    for column in df.columns[1:]:  \n",
    "        counts = df[column].value_counts().to_dict()  \n",
    "        w_count = counts.get('W', 0)  \n",
    "        t_count = counts.get('T', 0)  \n",
    "        l_count = counts.get('L', 0)  \n",
    "        result[column] = f'{w_count}:{t_count}:{l_count}'  \n",
    "  \n",
    "    return result  \n",
    "  \n",
    "def process_all_sheets(file_path, sheets):  \n",
    "    all_results = pd.DataFrame()  \n",
    "  \n",
    "    for sheet in sheets:  \n",
    "        sheet_result = process_sheet(file_path, sheet)  \n",
    "        sheet_df = pd.DataFrame(list(sheet_result.items()), columns=['Model', sheet])  \n",
    "        if all_results.empty:  \n",
    "            all_results = sheet_df  \n",
    "        else:  \n",
    "            all_results = pd.merge(all_results, sheet_df, on='Model', how='outer')  \n",
    "  \n",
    "    return all_results  \n",
    "  \n",
    "def process_wtl(wtl_str):  \n",
    "    w, t, l = map(int, wtl_str.split(':'))  \n",
    "    return w, t, l  \n",
    "  \n",
    "file_path = 'Label_2.xlsx'  \n",
    "sheets1 = ['Lingjie', 'Shaohanh', 'Label3_8B']  \n",
    "sheets2 = ['Lingjie-70B', 'shaohanh-70B', 'Label3-70B']  \n",
    "  \n",
    "results1 = process_all_sheets(file_path, sheets1)  \n",
    "results2 = process_all_sheets(file_path, sheets2)  \n",
    "  \n",
    "all_results = pd.merge(results1, results2, on='Model', how='outer')  \n",
    "  \n",
    "for index, row in all_results.iterrows():  \n",
    "    w_sum = t_sum = l_sum = 0  \n",
    "    for column in sheets1:  \n",
    "        w, t, l = process_wtl(row[column])  \n",
    "        w_sum += w  \n",
    "        t_sum += t  \n",
    "        l_sum += l  \n",
    "    all_results.loc[index, 'group_1_sum'] = f'{w_sum}/{t_sum}/{l_sum}'  \n",
    "    all_results.loc[index, 'group_1_avg'] = f'{w_sum/len(sheets1):.1f}/{t_sum/len(sheets1):.1f}/{l_sum/len(sheets1):.1f}'  \n",
    "  \n",
    "    w_sum = t_sum = l_sum = 0  \n",
    "    for column in sheets2:  \n",
    "        w, t, l = process_wtl(row[column])  \n",
    "        w_sum += w  \n",
    "        t_sum += t  \n",
    "        l_sum += l  \n",
    "    all_results.loc[index, 'group_2_sum'] = f'{w_sum}/{t_sum}/{l_sum}'  \n",
    "    all_results.loc[index, 'group_2_avg'] = f'{w_sum/len(sheets2):.1f}/{t_sum/len(sheets2):.1f}/{l_sum/len(sheets2):.1f}'  \n",
    "  \n",
    "all_results.to_csv('result_3_group_sum_avg.csv', index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_717019/3559737155.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/3559737155.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/3559737155.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/3559737155.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/3559737155.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/3559737155.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "  \n",
    "def process_sheet(file_path, sheet_name):  \n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)  \n",
    "    df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)  \n",
    "    result = {}  \n",
    "  \n",
    "    for column in df.columns[1:]:  \n",
    "        counts = df[column].value_counts().to_dict()  \n",
    "        w_count = counts.get('W', 0)  \n",
    "        t_count = counts.get('T', 0)  \n",
    "        l_count = counts.get('L', 0)  \n",
    "        result[column] = f'{w_count}:{t_count}:{l_count}'  \n",
    "  \n",
    "    return result  \n",
    "  \n",
    "def process_all_sheets(file_path, sheets):  \n",
    "    all_results = pd.DataFrame()  \n",
    "  \n",
    "    for sheet in sheets:  \n",
    "        sheet_result = process_sheet(file_path, sheet)  \n",
    "        sheet_df = pd.DataFrame(list(sheet_result.items()), columns=['Model', sheet])  \n",
    "        if all_results.empty:  \n",
    "            all_results = sheet_df  \n",
    "        else:  \n",
    "            all_results = pd.merge(all_results, sheet_df, on='Model', how='outer')  \n",
    "  \n",
    "    return all_results  \n",
    "  \n",
    "def process_wtl(wtl_str):  \n",
    "    w, t, l = map(int, wtl_str.split(':'))  \n",
    "    return w, t, l  \n",
    "  \n",
    "file_path = 'Label_2.xlsx'  \n",
    "sheets1 = ['Lingjie', 'Shaohanh', 'Label3_8B']  \n",
    "sheets2 = ['Lingjie-70B', 'shaohanh-70B', 'Label3-70B']  \n",
    "  \n",
    "results1 = process_all_sheets(file_path, sheets1)  \n",
    "results2 = process_all_sheets(file_path, sheets2)  \n",
    "  \n",
    "all_results = pd.merge(results1, results2, on='Model', how='outer')  \n",
    "  \n",
    "for index, row in all_results.iterrows():  \n",
    "    w_sum = t_sum = l_sum = 0  \n",
    "    for column in sheets1:  \n",
    "        w, t, l = process_wtl(row[column])  \n",
    "        w_sum += w  \n",
    "        t_sum += t  \n",
    "        l_sum += l  \n",
    "      \n",
    "    total_sum_1 = w_sum + t_sum + l_sum  \n",
    "    w1_avg = w_sum / total_sum_1 * 100 if total_sum_1 != 0 else 0  \n",
    "    t1_avg = t_sum / total_sum_1 * 100 if total_sum_1 != 0 else 0  \n",
    "    l1_avg = l_sum / total_sum_1 * 100 if total_sum_1 != 0 else 0  \n",
    "      \n",
    "    all_results.loc[index, 'group_1_sum'] = f'{w_sum}/{t_sum}/{l_sum}'  \n",
    "    all_results.loc[index, 'group_1_avg'] = f'{w1_avg:.1f}/{t1_avg:.1f}/{l1_avg:.1f}'  \n",
    "  \n",
    "    w_sum = t_sum = l_sum = 0  \n",
    "    for column in sheets2:  \n",
    "        w, t, l = process_wtl(row[column])  \n",
    "        w_sum += w  \n",
    "        t_sum += t  \n",
    "        l_sum += l  \n",
    "      \n",
    "    total_sum_2 = w_sum + t_sum + l_sum  \n",
    "    w2_avg = w_sum / total_sum_2 * 100 if total_sum_2 != 0 else 0  \n",
    "    t2_avg = t_sum / total_sum_2 * 100 if total_sum_2 != 0 else 0  \n",
    "    l2_avg = l_sum / total_sum_2 * 100 if total_sum_2 != 0 else 0  \n",
    "      \n",
    "    all_results.loc[index, 'group_2_sum'] = f'{w_sum}/{t_sum}/{l_sum}'  \n",
    "    all_results.loc[index, 'group_2_avg'] = f'{w2_avg:.1f}/{t2_avg:.1f}/{l2_avg:.1f}'  \n",
    "  \n",
    "all_results.to_csv('result_3_group_sum_avg.csv', index=False)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_717019/2014261800.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/2014261800.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/2014261800.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/2014261800.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/2014261800.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/2014261800.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "  \n",
    "def process_sheet(file_path, sheet_name):  \n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)  \n",
    "    df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)  \n",
    "    result = {}  \n",
    "  \n",
    "    for column in df.columns[1:]:  \n",
    "        counts = df[column].value_counts().to_dict()  \n",
    "        w_count = counts.get('W', 0)  \n",
    "        t_count = counts.get('T', 0)  \n",
    "        l_count = counts.get('L', 0)  \n",
    "        result[column] = f'{w_count}:{t_count}:{l_count}'  \n",
    "  \n",
    "    return result  \n",
    "  \n",
    "def process_all_sheets(file_path, sheets):  \n",
    "    all_results = pd.DataFrame()  \n",
    "  \n",
    "    for sheet in sheets:  \n",
    "        sheet_result = process_sheet(file_path, sheet)  \n",
    "        sheet_df = pd.DataFrame(list(sheet_result.items()), columns=['Model', sheet])  \n",
    "        if all_results.empty:  \n",
    "            all_results = sheet_df  \n",
    "        else:  \n",
    "            all_results = pd.merge(all_results, sheet_df, on='Model', how='outer')  \n",
    "  \n",
    "    return all_results  \n",
    "  \n",
    "def process_wtl(wtl_str):  \n",
    "    w, t, l = map(int, wtl_str.split(':'))  \n",
    "    return w, t, l  \n",
    "  \n",
    "file_path = 'Label_2.xlsx'  \n",
    "sheets1 = ['Lingjie', 'Shaohanh', 'Label3_8B']  \n",
    "sheets2 = ['Lingjie-70B', 'shaohanh-70B', 'Label3-70B']  \n",
    "  \n",
    "results1 = process_all_sheets(file_path, sheets1)  \n",
    "results2 = process_all_sheets(file_path, sheets2)  \n",
    "  \n",
    "all_results = pd.merge(results1, results2, on='Model', how='outer')  \n",
    "  \n",
    "average_results = []  \n",
    "  \n",
    "for index, row in all_results.iterrows():  \n",
    "    w_sum = t_sum = l_sum = 0  \n",
    "    for column in sheets1:  \n",
    "        w, t, l = process_wtl(row[column])  \n",
    "        w_sum += w  \n",
    "        t_sum += t  \n",
    "        l_sum += l  \n",
    "    w1_avg = w_sum / (w_sum + t_sum + l_sum) * 100\n",
    "    t1_avg = t_sum / (w_sum + t_sum + l_sum) * 100\n",
    "    l1_avg = l_sum / (w_sum + t_sum + l_sum) * 100\n",
    "    # w1_avg = w_sum / len(sheets1)  \n",
    "    # t1_avg = t_sum / len(sheets1)  \n",
    "    # l1_avg = l_sum / len(sheets1)  \n",
    "  \n",
    "    w_sum = t_sum = l_sum = 0  \n",
    "    for column in sheets2:  \n",
    "        w, t, l = process_wtl(row[column])  \n",
    "        w_sum += w  \n",
    "        t_sum += t  \n",
    "        l_sum += l  \n",
    "    w2_avg = w_sum / (w_sum + t_sum + l_sum) * 100\n",
    "    t2_avg = t_sum / (w_sum + t_sum + l_sum) * 100\n",
    "    l2_avg = l_sum / (w_sum + t_sum + l_sum) * 100\n",
    "    # w2_avg = w_sum / len(sheets2)  \n",
    "    # t2_avg = t_sum / len(sheets2)  \n",
    "    # l2_avg = l_sum / len(sheets2)  \n",
    "  \n",
    "    average_results.append({  \n",
    "        'Model': row['Model'],  \n",
    "        'w1': f'{w1_avg:.1f}',  \n",
    "        't1': f'{t1_avg:.1f}',  \n",
    "        'l1': f'{l1_avg:.1f}',  \n",
    "        'w2': f'{w2_avg:.1f}',  \n",
    "        't2': f'{t2_avg:.1f}',  \n",
    "        'l2': f'{l2_avg:.1f}'  \n",
    "    })  \n",
    "  \n",
    "average_results_df = pd.DataFrame(average_results)  \n",
    "average_results_df.to_csv('average_results4.csv', index=False)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_717019/3950137794.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/3950137794.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/3950137794.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/3950137794.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/3950137794.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/3950137794.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/3950137794.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/3950137794.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/3950137794.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/3950137794.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "  \n",
    "def process_sheet(file_path, sheet_name):  \n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)  \n",
    "    df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)  \n",
    "    result = {}  \n",
    "  \n",
    "    for column in df.columns[1:]:  \n",
    "        counts = df[column].value_counts().to_dict()  \n",
    "        w_count = counts.get('W', 0)  \n",
    "        t_count = counts.get('T', 0)  \n",
    "        l_count = counts.get('L', 0)  \n",
    "        result[column] = f'{w_count}:{t_count}:{l_count}'  \n",
    "  \n",
    "    return result  \n",
    "  \n",
    "def process_all_sheets(file_path, sheets):  \n",
    "    all_results = pd.DataFrame()  \n",
    "  \n",
    "    for sheet in sheets:  \n",
    "        sheet_result = process_sheet(file_path, sheet)  \n",
    "        sheet_df = pd.DataFrame(list(sheet_result.items()), columns=['Model', sheet])  \n",
    "        if all_results.empty:  \n",
    "            all_results = sheet_df  \n",
    "        else:  \n",
    "            all_results = pd.merge(all_results, sheet_df, on='Model', how='outer')  \n",
    "  \n",
    "    return all_results  \n",
    "  \n",
    "def process_wtl(wtl_str):  \n",
    "    w, t, l = map(int, wtl_str.split(':'))  \n",
    "    return w, t, l  \n",
    "  \n",
    "file_path = 'Label_4.xlsx'  \n",
    "sheets1 = ['Lingjie', 'Shaohanh', 'Label3_8B', \"gpt4_text\", \"gpt4_image\"]  \n",
    "sheets2 = ['Lingjie-70B', 'shaohanh-70B', 'Label3-70B',\"text_70B\", \"image_70B\"]  \n",
    "  \n",
    "results1 = process_all_sheets(file_path, sheets1)  \n",
    "results2 = process_all_sheets(file_path, sheets2)  \n",
    "  \n",
    "all_results = pd.merge(results1, results2, on='Model', how='outer')  \n",
    "  \n",
    "for index, row in all_results.iterrows():  \n",
    "    w_sum = t_sum = l_sum = 0  \n",
    "    for column in sheets1:  \n",
    "        w, t, l = process_wtl(row[column])  \n",
    "        w_sum += w  \n",
    "        t_sum += t  \n",
    "        l_sum += l  \n",
    "      \n",
    "    total_sum_1 = w_sum + t_sum + l_sum  \n",
    "    w1_avg = w_sum / total_sum_1 * 100 if total_sum_1 != 0 else 0  \n",
    "    t1_avg = t_sum / total_sum_1 * 100 if total_sum_1 != 0 else 0  \n",
    "    l1_avg = l_sum / total_sum_1 * 100 if total_sum_1 != 0 else 0  \n",
    "      \n",
    "    all_results.loc[index, 'group_1_sum'] = f'{w_sum}/{t_sum}/{l_sum}'  \n",
    "    all_results.loc[index, 'group_1_avg'] = f'{w1_avg:.1f}/{t1_avg:.1f}/{l1_avg:.1f}'  \n",
    "  \n",
    "    w_sum = t_sum = l_sum = 0  \n",
    "    for column in sheets2:  \n",
    "        w, t, l = process_wtl(row[column])  \n",
    "        w_sum += w  \n",
    "        t_sum += t  \n",
    "        l_sum += l  \n",
    "      \n",
    "    total_sum_2 = w_sum + t_sum + l_sum  \n",
    "    w2_avg = w_sum / total_sum_2 * 100 if total_sum_2 != 0 else 0  \n",
    "    t2_avg = t_sum / total_sum_2 * 100 if total_sum_2 != 0 else 0  \n",
    "    l2_avg = l_sum / total_sum_2 * 100 if total_sum_2 != 0 else 0  \n",
    "      \n",
    "    all_results.loc[index, 'group_2_sum'] = f'{w_sum}/{t_sum}/{l_sum}'  \n",
    "    all_results.loc[index, 'group_2_avg'] = f'{w2_avg:.1f}/{t2_avg:.1f}/{l2_avg:.1f}'  \n",
    "  \n",
    "all_results.to_csv('result_6_group_sum_avg.csv', index=False)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results have been written to agreement_result_5.csv\n",
      "Results have been written to agreement_result_6.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_717019/1212702476.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/1212702476.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/1212702476.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/1212702476.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/1212702476.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/1212702476.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/1212702476.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/1212702476.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/1212702476.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/1212702476.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "  \n",
    "def process_sheet(file_path, sheet_name):    \n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)    \n",
    "    df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)  \n",
    "    return df    \n",
    "  \n",
    "def calculate_agreement(df1, df2):    \n",
    "    df1 = df1.set_index(df1.columns[0])    \n",
    "    df2 = df2.set_index(df2.columns[0])    \n",
    "        \n",
    "    agreements = {}    \n",
    "    for col in df1.columns:    \n",
    "        comparison = df1[col] == df2[col]    \n",
    "        agreements[col] = comparison.mean()  \n",
    "    return agreements    \n",
    "  \n",
    "# 文件路径    \n",
    "file_path = 'Label_4.xlsx'    \n",
    "  \n",
    "# 需要处理的工作表名称和输出文件名  \n",
    "sheets_and_output_files = [  \n",
    "    (['Lingjie', 'Shaohanh', 'Label3_8B', \"gpt4_text\", \"gpt4_image\"], 'agreement_result_5.csv'),  \n",
    "    (['Lingjie-70B', 'shaohanh-70B', 'Label3-70B',\"text_70B\", \"image_70B\"], 'agreement_result_6.csv')  \n",
    "]  \n",
    "  \n",
    "for sheets, output_file in sheets_and_output_files:  \n",
    "    # 读取所有的表    \n",
    "    dfs = {sheet: process_sheet(file_path, sheet) for sheet in sheets}    \n",
    "  \n",
    "    # 计算每对工作表的一致性    \n",
    "    results = {}    \n",
    "    for i, sheet1 in enumerate(sheets):    \n",
    "        for j, sheet2 in enumerate(sheets):    \n",
    "            if i < j:    \n",
    "                agreement = calculate_agreement(dfs[sheet1], dfs[sheet2])    \n",
    "                results[f'{sheet1} vs {sheet2}'] = agreement    \n",
    "  \n",
    "    # 将结果转换为DataFrame    \n",
    "    agreement_df = pd.DataFrame(results).T    \n",
    "  \n",
    "    # 计算每列的平均一致性    \n",
    "    agreement_df['Average'] = agreement_df.mean(axis=1)    \n",
    "  \n",
    "    # 将结果写入CSV文件    \n",
    "    agreement_df.to_csv(output_file)    \n",
    "  \n",
    "    print(f'Results have been written to {output_file}')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Unnamed: 0  Meta-Llama-3.1-8B-Instruct  \\\n",
      "0      Lingjie vs Shaohanh                        0.72   \n",
      "1     Lingjie vs Label3_8B                        0.70   \n",
      "2     Lingjie vs gpt4_text                        0.56   \n",
      "3    Lingjie vs gpt4_image                        0.62   \n",
      "4    Shaohanh vs Label3_8B                        0.74   \n",
      "5    Shaohanh vs gpt4_text                        0.58   \n",
      "6   Shaohanh vs gpt4_image                        0.52   \n",
      "7   Label3_8B vs gpt4_text                        0.64   \n",
      "8  Label3_8B vs gpt4_image                        0.64   \n",
      "9  gpt4_text vs gpt4_image                        0.62   \n",
      "\n",
      "   Meta-Llama-3.1-70B-Instruct  Qwen2-72B-Instruct  tulu-2-dpo-70b  Average  \n",
      "0                         0.66                0.76            0.88   0.7750  \n",
      "1                         0.74                0.84            0.92   0.8075  \n",
      "2                         0.50                0.68            0.80   0.6700  \n",
      "3                         0.70                0.60            0.74   0.6575  \n",
      "4                         0.68                0.76            0.92   0.7825  \n",
      "5                         0.60                0.64            0.84   0.6900  \n",
      "6                         0.58                0.56            0.78   0.6075  \n",
      "7                         0.48                0.82            0.88   0.7000  \n",
      "8                         0.68                0.70            0.78   0.6800  \n",
      "9                         0.56                0.70            0.78   0.6175  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "  \n",
    "# 读取CSV文件  \n",
    "file1 = 'agreement_result_5.csv'  \n",
    "file2 = 'agreement_result_6.csv'  \n",
    "  \n",
    "df1 = pd.read_csv(file1)  \n",
    "df2 = pd.read_csv(file2)  \n",
    "  \n",
    "# 提取最后一列  \n",
    "last_col1 = df1.iloc[:, -1]  \n",
    "last_col2 = df2.iloc[:, -1]  \n",
    "  \n",
    "# 计算对应行的平均值  \n",
    "average_col = (last_col1 + last_col2) / 2  \n",
    "  \n",
    "# 将结果放在第三列  \n",
    "df1['Average'] = average_col  \n",
    "  \n",
    "# 保存结果到新的CSV文件  \n",
    "df1.to_csv('agreement_result_with_average_3.csv', index=False)  \n",
    "  \n",
    "print(df1)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Judge2     Label3_8B  Shaohanh  gpt4_image  gpt4_text  Lingjie\n",
      "Judge1                                                        \n",
      "Label3_8B     1.0000     0.000      0.6800       0.70      0.0\n",
      "Lingjie       0.8075     0.775      0.6575       0.67      1.0\n",
      "Shaohanh      0.7825     1.000      0.6075       0.69      0.0\n",
      "gpt4_text     0.0000     0.000      0.6175       1.00      0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "  \n",
    "# 读取CSV文件  \n",
    "file1 = 'agreement_result_5.csv'  \n",
    "file2 = 'agreement_result_6.csv'  \n",
    "  \n",
    "df1 = pd.read_csv(file1)  \n",
    "df2 = pd.read_csv(file2)  \n",
    "  \n",
    "# 提取最后一列  \n",
    "last_col1 = df1.iloc[:, -1]  \n",
    "last_col2 = df2.iloc[:, -1]  \n",
    "  \n",
    "# 计算对应行的平均值  \n",
    "average_col = (last_col1 + last_col2) / 2  \n",
    "  \n",
    "# 将结果放在第三列  \n",
    "df1['Average'] = average_col  \n",
    "  \n",
    "# 分离出行和列的标签  \n",
    "df1[['Judge1', 'Judge2']] = df1.iloc[:, 0].str.split(' vs ', expand=True)  \n",
    "  \n",
    "# 创建一个透视表  \n",
    "matrix = df1.pivot_table(index='Judge1', columns='Judge2', values='Average')  \n",
    "  \n",
    "# 添加对角线上的1.0  \n",
    "for judge in matrix.index:  \n",
    "    matrix.loc[judge, judge] = 1.0  \n",
    "  \n",
    "# 填充NaN值为0  \n",
    "matrix = matrix.fillna(0)  \n",
    "  \n",
    "# 输出结果  \n",
    "print(matrix)  \n",
    "  \n",
    "# 保存结果到新的CSV文件  \n",
    "matrix.to_csv('agreement_result_matrix.csv')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Judge2     Label3_8B  Shaohanh  gpt4_image  gpt4_text  Lingjie\n",
      "Judge1                                                        \n",
      "Label3_8B        1.0    0.7825         0.0        0.0      0.0\n",
      "Lingjie          0.0    0.0000         0.0        0.0      1.0\n",
      "Shaohanh         0.0    1.0000         0.0        0.0      0.0\n",
      "gpt4_text        0.7    0.6900         0.0        1.0      0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "  \n",
    "# 读取CSV文件  \n",
    "file1 = 'agreement_result_5.csv'  \n",
    "file2 = 'agreement_result_6.csv'  \n",
    "  \n",
    "df1 = pd.read_csv(file1)  \n",
    "df2 = pd.read_csv(file2)  \n",
    "  \n",
    "# 提取最后一列  \n",
    "last_col1 = df1.iloc[:, -1]  \n",
    "last_col2 = df2.iloc[:, -1]  \n",
    "  \n",
    "# 计算对应行的平均值  \n",
    "average_col = (last_col1 + last_col2) / 2  \n",
    "  \n",
    "# 将结果放在第三列  \n",
    "df1['Average'] = average_col  \n",
    "  \n",
    "# 分离出行和列的标签  \n",
    "df1[['Judge1', 'Judge2']] = df1.iloc[:, 0].str.split(' vs ', expand=True)  \n",
    "  \n",
    "# 创建一个透视表  \n",
    "matrix = df1.pivot_table(index='Judge1', columns='Judge2', values='Average')  \n",
    "  \n",
    "# 将数据重新对齐，确保所有组合都存在  \n",
    "matrix = matrix.unstack().reindex(pd.MultiIndex.from_product([matrix.index, matrix.columns])).unstack()  \n",
    "  \n",
    "# 添加对角线上的1.0  \n",
    "for judge in matrix.index:  \n",
    "    matrix.loc[judge, judge] = 1.0  \n",
    "  \n",
    "# 填充NaN值为0  \n",
    "matrix = matrix.fillna(0)  \n",
    "  \n",
    "# 输出结果  \n",
    "print(matrix)  \n",
    "  \n",
    "# 保存结果到新的CSV文件  \n",
    "matrix.to_csv('agreement_result_matrix.csv')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results have been written to agreement_result_7.csv\n",
      "Results have been written to agreement_result_8.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1244306/4002218421.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_1244306/4002218421.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_1244306/4002218421.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_1244306/4002218421.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_1244306/4002218421.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_1244306/4002218421.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_1244306/4002218421.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_1244306/4002218421.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_1244306/4002218421.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_1244306/4002218421.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "  \n",
    "def process_sheet(file_path, sheet_name):  \n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)  \n",
    "    df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)  \n",
    "    return df  \n",
    "  \n",
    "def calculate_agreement(df1, df2):  \n",
    "    df1 = df1.set_index(df1.columns[0])  \n",
    "    df2 = df2.set_index(df2.columns[0])  \n",
    "      \n",
    "    agreements = {}  \n",
    "    for col in df1.columns:  \n",
    "        comparison = df1[col] == df2[col]  \n",
    "        agreements[col] = comparison.mean()  \n",
    "    return agreements  \n",
    "  \n",
    "# 文件路径  \n",
    "file_path = 'Label_4.xlsx'  \n",
    "  \n",
    "# 需要处理的工作表名称和输出文件名  \n",
    "sheets_and_output_files = [  \n",
    "    (['Lingjie', 'Shaohanh', 'Label3_8B', \"gpt4_text\", \"gpt4_image\"], 'agreement_result_7.csv'),  \n",
    "    (['Lingjie-70B', 'shaohanh-70B', 'Label3-70B',\"gpt4_text_70B\", \"gpt4_image_70B\"], 'agreement_result_8.csv')  \n",
    "]  \n",
    "  \n",
    "for sheets, output_file in sheets_and_output_files:  \n",
    "    # 读取所有的表  \n",
    "    dfs = {sheet: process_sheet(file_path, sheet) for sheet in sheets}  \n",
    "      \n",
    "    # 计算每对工作表的一致性  \n",
    "    results = {}  \n",
    "    for i, sheet1 in enumerate(sheets):  \n",
    "        for j, sheet2 in enumerate(sheets):  \n",
    "            if i < j:  \n",
    "                agreement = calculate_agreement(dfs[sheet1], dfs[sheet2])  \n",
    "                results[f'{sheet1} vs {sheet2}'] = agreement  \n",
    "      \n",
    "    # 将结果转换为DataFrame  \n",
    "    agreement_df = pd.DataFrame(results).T  \n",
    "      \n",
    "    # 计算每列的平均一致性  \n",
    "    agreement_df['Average'] = agreement_df.mean(axis=1)  \n",
    "      \n",
    "    # 将结果写入CSV文件  \n",
    "    agreement_df.to_csv(output_file)  \n",
    "      \n",
    "    print(f'Results have been written to {output_file}')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对比矩阵1:\n",
      "           Lingjie Shaohanh Label3_8B gpt4_text gpt4_image\n",
      "Lingjie        1.0    0.755       0.8     0.635      0.665\n",
      "Shaohanh     0.755      1.0     0.775     0.665       0.61\n",
      "Label3_8B      0.8    0.775       1.0     0.705        0.7\n",
      "gpt4_text    0.635    0.665     0.705       1.0      0.665\n",
      "gpt4_image   0.665     0.61       0.7     0.665        1.0\n",
      "\n",
      "对比矩阵2:\n",
      "               Lingjie-70B shaohanh-70B Label3-70B gpt4_text_70B  \\\n",
      "Lingjie-70B            1.0        0.795      0.815         0.705   \n",
      "shaohanh-70B         0.795          1.0       0.79         0.715   \n",
      "Label3-70B           0.815         0.79        1.0         0.695   \n",
      "gpt4_text_70B        0.705        0.715      0.695           1.0   \n",
      "gpt4_image_70B        0.65        0.605       0.66          0.57   \n",
      "\n",
      "               gpt4_image_70B  \n",
      "Lingjie-70B              0.65  \n",
      "shaohanh-70B            0.605  \n",
      "Label3-70B               0.66  \n",
      "gpt4_text_70B            0.57  \n",
      "gpt4_image_70B            1.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "  \n",
    "# 读取CSV文件  \n",
    "df1 = pd.read_csv('agreement_result_7.csv', index_col=0)  \n",
    "df2 = pd.read_csv('agreement_result_8.csv', index_col=0)  \n",
    "  \n",
    "# 提取平均值并构造对比矩阵  \n",
    "def extract_avg_matrix(df, judges):  \n",
    "    matrix = pd.DataFrame(index=judges, columns=judges)  \n",
    "    for index, row in df.iterrows():  \n",
    "        judge1, judge2 = index.split(' vs ')  \n",
    "        matrix.loc[judge1, judge2] = row['Average']  \n",
    "        matrix.loc[judge2, judge1] = row['Average']  \n",
    "    for judge in judges:  \n",
    "        matrix.loc[judge, judge] = 1.0  \n",
    "    return matrix  \n",
    "  \n",
    "# 定义评审员  \n",
    "judges1 = ['Lingjie', 'Shaohanh', 'Label3_8B', 'gpt4_text', 'gpt4_image']  \n",
    "judges2 = ['Lingjie-70B', 'shaohanh-70B', 'Label3-70B', 'gpt4_text_70B', 'gpt4_image_70B']  \n",
    "  \n",
    "# 构造对比矩阵  \n",
    "matrix1 = extract_avg_matrix(df1, judges1)  \n",
    "matrix2 = extract_avg_matrix(df2, judges2)  \n",
    "  \n",
    "print(\"对比矩阵1:\")  \n",
    "print(matrix1)  \n",
    "print(\"\\n对比矩阵2:\")  \n",
    "print(matrix2)  \n",
    "  \n",
    "# 保存结果到CSV文件  \n",
    "matrix1.to_csv('comparison_matrix_1.csv')  \n",
    "matrix2.to_csv('comparison_matrix_2.csv')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最终对比矩阵:\n",
      "           shaohanh  label3 gpt4_text lingjie gpt4_image\n",
      "shaohanh        1.0  0.7825      0.69   0.775     0.6075\n",
      "label3       0.7825     1.0       0.7  0.8075       0.68\n",
      "gpt4_text      0.69     0.7       1.0    0.67     0.6175\n",
      "lingjie       0.775  0.8075      0.67     1.0     0.6575\n",
      "gpt4_image   0.6075    0.68    0.6175  0.6575        1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "  \n",
    "# 读取CSV文件  \n",
    "df1 = pd.read_csv('agreement_result_7.csv', index_col=0)  \n",
    "df2 = pd.read_csv('agreement_result_8.csv', index_col=0)  \n",
    "  \n",
    "# 提取平均值并构造对比矩阵  \n",
    "def extract_avg_dict(df):  \n",
    "    avg_dict = {}  \n",
    "    for index, row in df.iterrows():  \n",
    "        judge1, judge2 = index.split(' vs ')  \n",
    "        # 去掉 -70B, _70B 和 8B，并转为小写  \n",
    "        judge1 = judge1.replace('-70B', '').replace('_70B', '').replace('_8B', '').lower()  \n",
    "        judge2 = judge2.replace('-70B', '').replace('_70B', '').replace('_8B', '').lower()  \n",
    "        avg_dict[(judge1, judge2)] = row['Average']  \n",
    "        avg_dict[(judge2, judge1)] = row['Average']  \n",
    "    return avg_dict  \n",
    "  \n",
    "# 从两个表格中提取平均值  \n",
    "avg_dict1 = extract_avg_dict(df1)  \n",
    "avg_dict2 = extract_avg_dict(df2)  \n",
    "  \n",
    "# 合并两个字典并计算平均值  \n",
    "combined_avg_dict = {}  \n",
    "for key in set(avg_dict1.keys()).union(avg_dict2.keys()):  \n",
    "    combined_avg_dict[key] = (avg_dict1.get(key, 0) + avg_dict2.get(key, 0)) / 2  \n",
    "  \n",
    "# 定义所有评审员列表  \n",
    "judges = list(set([judge for pair in combined_avg_dict.keys() for judge in pair]))  \n",
    "  \n",
    "# 构造对比矩阵  \n",
    "matrix = pd.DataFrame(index=judges, columns=judges)  \n",
    "for (judge1, judge2), avg in combined_avg_dict.items():  \n",
    "    matrix.loc[judge1, judge2] = avg  \n",
    "    matrix.loc[judge2, judge1] = avg  \n",
    "  \n",
    "# 设置对角线为1  \n",
    "for judge in judges:  \n",
    "    matrix.loc[judge, judge] = 1.0  \n",
    "  \n",
    "# 打印和保存对比矩阵  \n",
    "print(\"最终对比矩阵:\")  \n",
    "print(matrix)  \n",
    "  \n",
    "matrix.to_csv('combined_comparison_matrix.csv')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最终对比矩阵:\n",
      "           shaohanh  label3 lingjie gpt4_image gpt4_text\n",
      "shaohanh    0.71375  0.7825   0.775     0.6075      0.69\n",
      "label3       0.7825  0.7425  0.8075       0.68       0.7\n",
      "lingjie       0.775  0.8075  0.7275     0.6575      0.67\n",
      "gpt4_image   0.6075    0.68  0.6575   0.640625    0.6175\n",
      "gpt4_text      0.69     0.7    0.67     0.6175  0.669375\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "  \n",
    "# 读取CSV文件  \n",
    "df1 = pd.read_csv('agreement_result_7.csv', index_col=0)  \n",
    "df2 = pd.read_csv('agreement_result_8.csv', index_col=0)  \n",
    "  \n",
    "# 提取平均值并构造对比矩阵  \n",
    "def extract_avg_dict(df):  \n",
    "    avg_dict = {}  \n",
    "    for index, row in df.iterrows():  \n",
    "        judge1, judge2 = index.split(' vs ')  \n",
    "        # 去掉 -70B, _70B 和 8B，并转为小写  \n",
    "        judge1 = judge1.replace('-70B', '').replace('_70B', '').replace('_8B', '').lower()  \n",
    "        judge2 = judge2.replace('-70B', '').replace('_70B', '').replace('_8B', '').lower()  \n",
    "        avg_dict[(judge1, judge2)] = row['Average']  \n",
    "        avg_dict[(judge2, judge1)] = row['Average']  \n",
    "    return avg_dict  \n",
    "  \n",
    "# 从两个表格中提取平均值  \n",
    "avg_dict1 = extract_avg_dict(df1)  \n",
    "avg_dict2 = extract_avg_dict(df2)  \n",
    "  \n",
    "# 合并两个字典并计算平均值  \n",
    "combined_avg_dict = {}  \n",
    "for key in set(avg_dict1.keys()).union(avg_dict2.keys()):  \n",
    "    combined_avg_dict[key] = (avg_dict1.get(key, 0) + avg_dict2.get(key, 0)) / 2  \n",
    "  \n",
    "# 定义评审员的特定顺序  \n",
    "judges_order = ['shaohanh', 'label3', 'lingjie', 'gpt4_image', 'gpt4_text']  \n",
    "  \n",
    "# 构造对比矩阵  \n",
    "matrix = pd.DataFrame(index=judges_order, columns=judges_order)  \n",
    "for (judge1, judge2), avg in combined_avg_dict.items():  \n",
    "    if judge1 in judges_order and judge2 in judges_order:  \n",
    "        matrix.loc[judge1, judge2] = avg  \n",
    "        matrix.loc[judge2, judge1] = avg  \n",
    "  \n",
    "# 设置对角线为每行其他列的平均值  \n",
    "for judge in judges_order:  \n",
    "    other_values = matrix.loc[judge, judges_order].drop(judge).dropna()  \n",
    "    if not other_values.empty:  \n",
    "        matrix.loc[judge, judge] = other_values.mean()  \n",
    "  \n",
    "# 打印和保存对比矩阵  \n",
    "print(\"最终对比矩阵:\")  \n",
    "print(matrix)  \n",
    "  \n",
    "matrix.to_csv('combined_comparison_matrix.csv')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最终对比矩阵:\n",
      "           shaohanh  label3 lingjie gpt4_image gpt4_text   average\n",
      "shaohanh        1.0  0.7825   0.775     0.6075      0.69  0.713750\n",
      "label3       0.7825     1.0  0.8075       0.68       0.7  0.742500\n",
      "lingjie       0.775  0.8075     1.0     0.6575      0.67  0.727500\n",
      "gpt4_image   0.6075    0.68  0.6575        1.0    0.6175  0.640625\n",
      "gpt4_text      0.69     0.7    0.67     0.6175       1.0  0.669375\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "  \n",
    "# 读取CSV文件  \n",
    "df1 = pd.read_csv('agreement_result_7.csv', index_col=0)  \n",
    "df2 = pd.read_csv('agreement_result_8.csv', index_col=0)  \n",
    "  \n",
    "# 提取平均值并构造对比矩阵  \n",
    "def extract_avg_dict(df):  \n",
    "    avg_dict = {}  \n",
    "    for index, row in df.iterrows():  \n",
    "        judge1, judge2 = index.split(' vs ')  \n",
    "        # 去掉 -70B, _70B 和 _8B，并转为小写  \n",
    "        judge1 = judge1.replace('-70B', '').replace('_70B', '').replace('_8B', '').lower()  \n",
    "        judge2 = judge2.replace('-70B', '').replace('_70B', '').replace('_8B', '').lower()  \n",
    "        avg_dict[(judge1, judge2)] = row['Average']  \n",
    "        avg_dict[(judge2, judge1)] = row['Average']  \n",
    "    return avg_dict  \n",
    "  \n",
    "# 从两个表格中提取平均值  \n",
    "avg_dict1 = extract_avg_dict(df1)  \n",
    "avg_dict2 = extract_avg_dict(df2)  \n",
    "  \n",
    "# 合并两个字典并计算平均值  \n",
    "combined_avg_dict = {}  \n",
    "for key in set(avg_dict1.keys()).union(avg_dict2.keys()):  \n",
    "    combined_avg_dict[key] = (avg_dict1.get(key, 0) + avg_dict2.get(key, 0)) / 2  \n",
    "  \n",
    "# 定义评审员的特定顺序  \n",
    "judges_order = ['shaohanh', 'label3', 'lingjie', 'gpt4_image', 'gpt4_text']  \n",
    "  \n",
    "# 构造对比矩阵  \n",
    "matrix = pd.DataFrame(index=judges_order, columns=judges_order)  \n",
    "for (judge1, judge2), avg in combined_avg_dict.items():  \n",
    "    if judge1 in judges_order and judge2 in judges_order:  \n",
    "        matrix.loc[judge1, judge2] = avg  \n",
    "        matrix.loc[judge2, judge1] = avg  \n",
    "  \n",
    "# 设置对角线为1  \n",
    "for judge in judges_order:  \n",
    "    matrix.loc[judge, judge] = 1.0  \n",
    "  \n",
    "# 添加最后一列为每行其他列的平均值，排除对角线的1  \n",
    "def calculate_average(row):  \n",
    "    # 排除对角线的1  \n",
    "    other_values = row.drop(labels=row.name).dropna()  \n",
    "    if not other_values.empty:  \n",
    "        return other_values.mean()  \n",
    "    return None  \n",
    "  \n",
    "matrix['average'] = matrix.apply(calculate_average, axis=1)  \n",
    "  \n",
    "# 打印和保存对比矩阵  \n",
    "print(\"最终对比矩阵:\")  \n",
    "print(matrix)  \n",
    "  \n",
    "matrix.to_csv('combined_comparison_matrix.csv')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results have been written to agreement_result_9.csv\n",
      "Results have been written to agreement_result_10.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1244306/3981906202.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_1244306/3981906202.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_1244306/3981906202.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_1244306/3981906202.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_1244306/3981906202.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_1244306/3981906202.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_1244306/3981906202.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_1244306/3981906202.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_1244306/3981906202.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_1244306/3981906202.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "  \n",
    "def process_sheet(file_path, sheet_name):  \n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)  \n",
    "    df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)  \n",
    "    return df  \n",
    "  \n",
    "def calculate_agreement(df1, df2):  \n",
    "    df1 = df1.set_index(df1.columns[0])  \n",
    "    df2 = df2.set_index(df2.columns[0])  \n",
    "      \n",
    "    agreements = {}  \n",
    "    for col in df1.columns:  \n",
    "        comparison = df1[col] == df2[col]  \n",
    "        agreements[col] = comparison.mean()  \n",
    "    return agreements  \n",
    "  \n",
    "# 文件路径  \n",
    "file_path = 'Label_5.xlsx'  \n",
    "  \n",
    "# 需要处理的工作表名称和输出文件名  \n",
    "sheets_and_output_files = [  \n",
    "    (['Lingjie', 'Shaohanh', 'Label3_8B', \"gpt4_text\", \"gpt4_image\"], 'agreement_result_9.csv'),  \n",
    "    (['Lingjie-70B', 'shaohanh-70B', 'Label3-70B',\"gpt4_text_70B\", \"gpt4_image_70B\"], 'agreement_result_10.csv')  \n",
    "]  \n",
    "  \n",
    "for sheets, output_file in sheets_and_output_files:  \n",
    "    # 读取所有的表  \n",
    "    dfs = {sheet: process_sheet(file_path, sheet) for sheet in sheets}  \n",
    "      \n",
    "    # 计算每对工作表的一致性  \n",
    "    results = {}  \n",
    "    for i, sheet1 in enumerate(sheets):  \n",
    "        for j, sheet2 in enumerate(sheets):  \n",
    "            if i < j:  \n",
    "                agreement = calculate_agreement(dfs[sheet1], dfs[sheet2])  \n",
    "                results[f'{sheet1} vs {sheet2}'] = agreement  \n",
    "      \n",
    "    # 将结果转换为DataFrame  \n",
    "    agreement_df = pd.DataFrame(results).T  \n",
    "      \n",
    "    # 计算每列的平均一致性  \n",
    "    agreement_df['Average'] = agreement_df.mean(axis=1)  \n",
    "      \n",
    "    # 将结果写入CSV文件  \n",
    "    agreement_df.to_csv(output_file)  \n",
    "      \n",
    "    print(f'Results have been written to {output_file}')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最终对比矩阵:\n",
      "           shaohanh  label3 lingjie gpt4_image gpt4_text   average\n",
      "shaohanh        1.0  0.7825   0.775      0.595      0.69  0.710625\n",
      "label3       0.7825     1.0  0.8075     0.6375       0.7  0.731875\n",
      "lingjie       0.775  0.8075     1.0     0.5875      0.67  0.710000\n",
      "gpt4_image    0.595  0.6375  0.5875        1.0     0.635  0.613750\n",
      "gpt4_text      0.69     0.7    0.67      0.635       1.0  0.673750\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "  \n",
    "# 读取CSV文件  \n",
    "df1 = pd.read_csv('agreement_result_9.csv', index_col=0)  \n",
    "df2 = pd.read_csv('agreement_result_10.csv', index_col=0)  \n",
    "  \n",
    "# 提取平均值并构造对比矩阵  \n",
    "def extract_avg_dict(df):  \n",
    "    avg_dict = {}  \n",
    "    for index, row in df.iterrows():  \n",
    "        judge1, judge2 = index.split(' vs ')  \n",
    "        # 去掉 -70B, _70B 和 _8B，并转为小写  \n",
    "        judge1 = judge1.replace('-70B', '').replace('_70B', '').replace('_8B', '').lower()  \n",
    "        judge2 = judge2.replace('-70B', '').replace('_70B', '').replace('_8B', '').lower()  \n",
    "        avg_dict[(judge1, judge2)] = row['Average']  \n",
    "        avg_dict[(judge2, judge1)] = row['Average']  \n",
    "    return avg_dict  \n",
    "  \n",
    "# 从两个表格中提取平均值  \n",
    "avg_dict1 = extract_avg_dict(df1)  \n",
    "avg_dict2 = extract_avg_dict(df2)  \n",
    "  \n",
    "# 合并两个字典并计算平均值  \n",
    "combined_avg_dict = {}  \n",
    "for key in set(avg_dict1.keys()).union(avg_dict2.keys()):  \n",
    "    combined_avg_dict[key] = (avg_dict1.get(key, 0) + avg_dict2.get(key, 0)) / 2  \n",
    "  \n",
    "# 定义评审员的特定顺序  \n",
    "judges_order = ['shaohanh', 'label3', 'lingjie', 'gpt4_image', 'gpt4_text']  \n",
    "  \n",
    "# 构造对比矩阵  \n",
    "matrix = pd.DataFrame(index=judges_order, columns=judges_order)  \n",
    "for (judge1, judge2), avg in combined_avg_dict.items():  \n",
    "    if judge1 in judges_order and judge2 in judges_order:  \n",
    "        matrix.loc[judge1, judge2] = avg  \n",
    "        matrix.loc[judge2, judge1] = avg  \n",
    "  \n",
    "# 设置对角线为1  \n",
    "for judge in judges_order:  \n",
    "    matrix.loc[judge, judge] = 1.0  \n",
    "  \n",
    "# 添加最后一列为每行其他列的平均值，排除对角线的1  \n",
    "def calculate_average(row):  \n",
    "    # 排除对角线的1  \n",
    "    other_values = row.drop(labels=row.name).dropna()  \n",
    "    if not other_values.empty:  \n",
    "        return other_values.mean()  \n",
    "    return None  \n",
    "  \n",
    "matrix['average'] = matrix.apply(calculate_average, axis=1)  \n",
    "  \n",
    "# 打印和保存对比矩阵  \n",
    "print(\"最终对比矩阵:\")  \n",
    "print(matrix)  \n",
    "  \n",
    "matrix.to_csv('combined_comparison_matrix.csv')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1244306/2739792519.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_1244306/2739792519.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_1244306/2739792519.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_1244306/2739792519.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "  \n",
    "def process_sheet(file_path, sheet_name):  \n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)  \n",
    "    df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)  \n",
    "    result = {}  \n",
    "  \n",
    "    for column in df.columns[1:]:  \n",
    "        counts = df[column].value_counts().to_dict()  \n",
    "        w_count = counts.get('W', 0)  \n",
    "        t_count = counts.get('T', 0)  \n",
    "        l_count = counts.get('L', 0)  \n",
    "        result[column] = f'{w_count}:{t_count}:{l_count}'  \n",
    "  \n",
    "    return result  \n",
    "  \n",
    "def process_all_sheets(file_path, sheets):  \n",
    "    all_results = pd.DataFrame()  \n",
    "  \n",
    "    for sheet in sheets:  \n",
    "        sheet_result = process_sheet(file_path, sheet)  \n",
    "        sheet_df = pd.DataFrame(list(sheet_result.items()), columns=['Model', sheet])  \n",
    "        if all_results.empty:  \n",
    "            all_results = sheet_df  \n",
    "        else:  \n",
    "            all_results = pd.merge(all_results, sheet_df, on='Model', how='outer')  \n",
    "  \n",
    "    return all_results  \n",
    "  \n",
    "def process_wtl(wtl_str):  \n",
    "    w, t, l = map(int, wtl_str.split(':'))  \n",
    "    return w, t, l  \n",
    "  \n",
    "file_path = 'Label_3_2.xlsx'  \n",
    "# sheets1 = ['Lingjie', 'Shaohanh', 'Label3_8B']  \n",
    "# sheets2 = ['Lingjie-70B', 'shaohanh-70B', 'Label3-70B']  \n",
    "sheets1 = [\"gpt4_text\", \"gpt4_image\"]  \n",
    "sheets2 = [\"text_70B\", \"image_70B\"]  \n",
    "  \n",
    "results1 = process_all_sheets(file_path, sheets1)  \n",
    "results2 = process_all_sheets(file_path, sheets2)  \n",
    "  \n",
    "all_results = pd.merge(results1, results2, on='Model', how='outer')  \n",
    "  \n",
    "for index, row in all_results.iterrows():  \n",
    "    w_sum = t_sum = l_sum = 0  \n",
    "    for column in sheets1:  \n",
    "        w, t, l = process_wtl(row[column])  \n",
    "        w_sum += w  \n",
    "        t_sum += t  \n",
    "        l_sum += l  \n",
    "      \n",
    "    total_sum_1 = w_sum + t_sum + l_sum  \n",
    "    w1_avg = w_sum / total_sum_1 * 100 if total_sum_1 != 0 else 0  \n",
    "    t1_avg = t_sum / total_sum_1 * 100 if total_sum_1 != 0 else 0  \n",
    "    l1_avg = l_sum / total_sum_1 * 100 if total_sum_1 != 0 else 0  \n",
    "      \n",
    "    all_results.loc[index, 'group_1_sum'] = f'{w_sum}/{t_sum}/{l_sum}'  \n",
    "    all_results.loc[index, 'group_1_avg'] = f'{w1_avg:.1f}/{t1_avg:.1f}/{l1_avg:.1f}'  \n",
    "  \n",
    "    w_sum = t_sum = l_sum = 0  \n",
    "    for column in sheets2:  \n",
    "        w, t, l = process_wtl(row[column])  \n",
    "        w_sum += w  \n",
    "        t_sum += t  \n",
    "        l_sum += l  \n",
    "      \n",
    "    total_sum_2 = w_sum + t_sum + l_sum  \n",
    "    w2_avg = w_sum / total_sum_2 * 100 if total_sum_2 != 0 else 0  \n",
    "    t2_avg = t_sum / total_sum_2 * 100 if total_sum_2 != 0 else 0  \n",
    "    l2_avg = l_sum / total_sum_2 * 100 if total_sum_2 != 0 else 0  \n",
    "      \n",
    "    all_results.loc[index, 'group_2_sum'] = f'{w_sum}/{t_sum}/{l_sum}'  \n",
    "    all_results.loc[index, 'group_2_avg'] = f'{w2_avg:.1f}/{t2_avg:.1f}/{l2_avg:.1f}'  \n",
    "  \n",
    "all_results.to_csv('result_9_group_sum_avg.csv', index=False)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New CSV file with averages has been saved as output_combined_comparison_matrix.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1244306/3106437114.py:10: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  values = [row[1], row[2], row[3]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "  \n",
    "# 读取CSV文件  \n",
    "input_filename = 'combined_comparison_matrix.csv'  \n",
    "output_filename = 'output_combined_comparison_matrix.csv'  \n",
    "df = pd.read_csv(input_filename)  \n",
    "  \n",
    "# 定义一个函数来计算前三列中的非1.0值的平均值  \n",
    "def calculate_average(row):  \n",
    "    values = [row[1], row[2], row[3]]  \n",
    "    non_one_values = [v for v in values if v != 1.0]  \n",
    "    if non_one_values:  \n",
    "        return sum(non_one_values) / len(non_one_values)  \n",
    "    else:  \n",
    "        return 1.0  # 如果前三列全是1.0，则返回1.0  \n",
    "  \n",
    "# 计算平均值并添加到新列  \n",
    "df['average'] = df.apply(calculate_average, axis=1)  \n",
    "  \n",
    "# 写入新的CSV文件  \n",
    "df.to_csv(output_filename, index=False)  \n",
    "  \n",
    "print(f'New CSV file with averages has been saved as {output_filename}')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将这个代码中的平均结果写入到另外一个csv中，列名w1，t1,l1,w2,t2,l2\n",
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "  \n",
    "def process_sheet(file_path, sheet_name):  \n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)  \n",
    "    df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)  \n",
    "    result = {}  \n",
    "  \n",
    "    for column in df.columns[1:]:  \n",
    "        counts = df[column].value_counts().to_dict()  \n",
    "        w_count = counts.get('W', 0)  \n",
    "        t_count = counts.get('T', 0)  \n",
    "        l_count = counts.get('L', 0)  \n",
    "        result[column] = f'{w_count}:{t_count}:{l_count}'  \n",
    "  \n",
    "    return result  \n",
    "  \n",
    "def process_all_sheets(file_path, sheets):  \n",
    "    all_results = pd.DataFrame()  \n",
    "  \n",
    "    for sheet in sheets:  \n",
    "        sheet_result = process_sheet(file_path, sheet)  \n",
    "        sheet_df = pd.DataFrame(list(sheet_result.items()), columns=['Model', sheet])  \n",
    "        if all_results.empty:  \n",
    "            all_results = sheet_df  \n",
    "        else:  \n",
    "            all_results = pd.merge(all_results, sheet_df, on='Model', how='outer')  \n",
    "  \n",
    "    return all_results  \n",
    "  \n",
    "def process_wtl(wtl_str):  \n",
    "    w, t, l = map(int, wtl_str.split(':'))  \n",
    "    return w, t, l  \n",
    "  \n",
    "file_path = 'Label_2.xlsx'  \n",
    "sheets1 = ['Lingjie', 'Shaohanh', 'Label3_8B']  \n",
    "sheets2 = ['Lingjie-70B', 'shaohanh-70B', 'Label3-70B']  \n",
    "  \n",
    "results1 = process_all_sheets(file_path, sheets1)  \n",
    "results2 = process_all_sheets(file_path, sheets2)  \n",
    "  \n",
    "all_results = pd.merge(results1, results2, on='Model', how='outer')  \n",
    "  \n",
    "for index, row in all_results.iterrows():  \n",
    "    w_sum = t_sum = l_sum = 0  \n",
    "    for column in sheets1:  \n",
    "        w, t, l = process_wtl(row[column])  \n",
    "        w_sum += w  \n",
    "        t_sum += t  \n",
    "        l_sum += l  \n",
    "    all_results.loc[index, 'group_1_sum'] = f'{w_sum}/{t_sum}/{l_sum}'  \n",
    "    all_results.loc[index, 'group_1_avg'] = f'{w_sum/len(sheets1):.1f}/{t_sum/len(sheets1):.1f}/{l_sum/len(sheets1):.1f}'  \n",
    "  \n",
    "    w_sum = t_sum = l_sum = 0  \n",
    "    for column in sheets2:  \n",
    "        w, t, l = process_wtl(row[column])  \n",
    "        w_sum += w  \n",
    "        t_sum += t  \n",
    "        l_sum += l  \n",
    "    all_results.loc[index, 'group_2_sum'] = f'{w_sum}/{t_sum}/{l_sum}'  \n",
    "    all_results.loc[index, 'group_2_avg'] = f'{w_sum/len(sheets2):.1f}/{t_sum/len(sheets2):.1f}/{l_sum/len(sheets2):.1f}'  \n",
    "  \n",
    "all_results.to_csv('result_3_group_sum_avg.csv', index=False)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
