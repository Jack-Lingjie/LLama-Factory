{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-Llama-3.1-8B-Instruct: 23:24:3\n",
      "Meta-Llama-3.1-70B-Instruct: 14:32:4\n",
      "Qwen2-72B-Instruct: 30:18:2\n",
      "tulu-2-dpo-70b: 43:5:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_610907/220148569.py:9: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "  \n",
    "# 读取Excel文件  \n",
    "file_path = 'Label_two.xlsx'  \n",
    "sheet_name = 'Lingjie'  \n",
    "df = pd.read_excel(file_path, sheet_name=sheet_name)  \n",
    "  \n",
    "# 将所有字符转换为大写  \n",
    "df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)  \n",
    "  \n",
    "# 初始化一个字典来存储每列的统计结果  \n",
    "result = {}  \n",
    "  \n",
    "# 遍历每一列并统计W:T:L的数量  \n",
    "for column in df.columns[1:]:  # 跳过第一列（假设第一列是索引或非统计列）  \n",
    "    counts = df[column].value_counts().to_dict()  \n",
    "    w_count = counts.get('W', 0)  \n",
    "    t_count = counts.get('T', 0)  \n",
    "    l_count = counts.get('L', 0)  \n",
    "    result[column] = f'{w_count}:{t_count}:{l_count}'  \n",
    "  \n",
    "# 打印结果  \n",
    "for column, count in result.items():  \n",
    "    print(f'{column}: {count}')  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我有一个数据标表格的前几列如下，代表着我们的模型和这些模型比较的结果，W代表我们的模型更好，T代表相同，L代表我们的模型不如对比的模型好，帮我统计每一列的W:T:L的数量，文件名如下Label_two.xlsx，表格前几列如下\n",
    "Index\tMeta-Llama-3.1-8B-Instruct\tMeta-Llama-3.1-70B-Instruct\tQwen2-72B-Instruct\ttulu-2-dpo-70b\n",
    "0\tT\tT\tW\tW\n",
    "1\tT\tT\tW\tW\n",
    "2\tW\tW\tW\tW\n",
    "3\tT\tT\tW\tW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results have been written to result.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_610907/922062794.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_610907/922062794.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_610907/922062794.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "  \n",
    "def process_sheet(file_path, sheet_name):  \n",
    "    # 读取指定工作表  \n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)  \n",
    "  \n",
    "    # 将所有字符转换为大写  \n",
    "    df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)  \n",
    "  \n",
    "    # 初始化一个字典来存储每列的统计结果  \n",
    "    result = {}  \n",
    "  \n",
    "    # 遍历每一列并统计W:T:L的数量  \n",
    "    for column in df.columns[1:]:  # 跳过第一列（假设第一列是索引或非统计列）  \n",
    "        counts = df[column].value_counts().to_dict()  \n",
    "        w_count = counts.get('W', 0)  \n",
    "        t_count = counts.get('T', 0)  \n",
    "        l_count = counts.get('L', 0)  \n",
    "        result[column] = f'{w_count}:{t_count}:{l_count}'  \n",
    "  \n",
    "    return result  \n",
    "  \n",
    "# 文件路径  \n",
    "file_path = 'Label_two.xlsx'  \n",
    "  \n",
    "# 需要处理的工作表名称  \n",
    "sheets = ['Lingjie', 'Shaohanh', 'Label3_8B']  # 假设另外两个工作表名为Sheet1和Sheet2，根据实际情况修改  \n",
    "  \n",
    "# 初始化一个DataFrame来存储所有结果  \n",
    "all_results = pd.DataFrame()  \n",
    "  \n",
    "# 处理每个工作表  \n",
    "for sheet in sheets:  \n",
    "    sheet_result = process_sheet(file_path, sheet)  \n",
    "    sheet_df = pd.DataFrame(list(sheet_result.items()), columns=['Model', sheet])  \n",
    "    if all_results.empty:  \n",
    "        all_results = sheet_df  \n",
    "    else:  \n",
    "        all_results = all_results.merge(sheet_df, on='Model', how='outer')  \n",
    "  \n",
    "# 将结果写入CSV文件  \n",
    "output_file = 'result.csv'  \n",
    "all_results.to_csv(output_file, index=False)  \n",
    "  \n",
    "print(f'Results have been written to {output_file}')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results have been written to agreement_result.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_610907/3209199104.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_610907/3209199104.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_610907/3209199104.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "  \n",
    "def process_sheet(file_path, sheet_name):  \n",
    "    # 读取指定工作表  \n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)  \n",
    "  \n",
    "    # 将所有字符转换为大写  \n",
    "    df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)  \n",
    "      \n",
    "    return df  \n",
    "  \n",
    "def calculate_agreement(df1, df2):  \n",
    "    # 确保两个DataFrame的索引和列对齐  \n",
    "    df1 = df1.set_index(df1.columns[0])  \n",
    "    df2 = df2.set_index(df2.columns[0])  \n",
    "      \n",
    "    agreements = {}  \n",
    "    for col in df1.columns:  \n",
    "        comparison = df1[col] == df2[col]  \n",
    "        agreements[col] = comparison.mean()  \n",
    "          \n",
    "    return agreements  \n",
    "  \n",
    "# 文件路径  \n",
    "file_path = 'Label_two.xlsx'  \n",
    "  \n",
    "# 需要处理的工作表名称  \n",
    "sheets = ['Lingjie', 'Shaohanh', 'Label3_8B']  # 假设另外两个工作表名为Sheet1和Sheet2，根据实际情况修改  \n",
    "  \n",
    "# 读取所有的表  \n",
    "dfs = {sheet: process_sheet(file_path, sheet) for sheet in sheets}  \n",
    "  \n",
    "# 计算每对工作表的一致性  \n",
    "results = {}  \n",
    "for i, sheet1 in enumerate(sheets):  \n",
    "    for j, sheet2 in enumerate(sheets):  \n",
    "        if i < j:  \n",
    "            agreement = calculate_agreement(dfs[sheet1], dfs[sheet2])  \n",
    "            results[f'{sheet1} vs {sheet2}'] = agreement  \n",
    "  \n",
    "# 将结果转换为DataFrame  \n",
    "agreement_df = pd.DataFrame(results).T  \n",
    "  \n",
    "# 计算每列的平均一致性  \n",
    "agreement_df['Average'] = agreement_df.mean(axis=1)  \n",
    "  \n",
    "# 将结果写入CSV文件  \n",
    "output_file = 'agreement_result.csv'  \n",
    "agreement_df.to_csv(output_file)  \n",
    "  \n",
    "print(f'Results have been written to {output_file}')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results have been written to agreement_result_2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_610907/454848843.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_610907/454848843.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_610907/454848843.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "  \n",
    "def process_sheet(file_path, sheet_name):  \n",
    "    # 读取指定工作表  \n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)  \n",
    "  \n",
    "    # 将所有字符转换为大写  \n",
    "    df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)  \n",
    "      \n",
    "    return df  \n",
    "  \n",
    "def calculate_agreement(df1, df2):  \n",
    "    # 确保两个DataFrame的索引和列对齐  \n",
    "    df1 = df1.set_index(df1.columns[0])  \n",
    "    df2 = df2.set_index(df2.columns[0])  \n",
    "      \n",
    "    agreements = {}  \n",
    "    for col in df1.columns:  \n",
    "        comparison = df1[col] == df2[col]  \n",
    "        agreements[col] = comparison.mean()  \n",
    "          \n",
    "    return agreements  \n",
    "  \n",
    "# 文件路径  \n",
    "file_path = 'Label_two.xlsx'  \n",
    "  \n",
    "# 需要处理的工作表名称  \n",
    "sheets = ['Lingjie-70B', 'shaohanh-70B', 'Label3-70B']  # 假设另外两个工作表名为Sheet1和Sheet2，根据实际情况修改  \n",
    "  \n",
    "# 读取所有的表  \n",
    "dfs = {sheet: process_sheet(file_path, sheet) for sheet in sheets}  \n",
    "  \n",
    "# 计算每对工作表的一致性  \n",
    "results = {}  \n",
    "for i, sheet1 in enumerate(sheets):  \n",
    "    for j, sheet2 in enumerate(sheets):  \n",
    "        if i < j:  \n",
    "            agreement = calculate_agreement(dfs[sheet1], dfs[sheet2])  \n",
    "            results[f'{sheet1} vs {sheet2}'] = agreement  \n",
    "  \n",
    "# 将结果转换为DataFrame  \n",
    "agreement_df = pd.DataFrame(results).T  \n",
    "  \n",
    "# 计算每列的平均一致性  \n",
    "agreement_df['Average'] = agreement_df.mean(axis=1)  \n",
    "  \n",
    "# 将结果写入CSV文件  \n",
    "output_file = 'agreement_result_2.csv'  \n",
    "agreement_df.to_csv(output_file)  \n",
    "  \n",
    "print(f'Results have been written to {output_file}')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "  \n",
    "def process_sheet(file_path, sheet_name):  \n",
    "    # 读取指定工作表  \n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)  \n",
    "  \n",
    "    # 将所有字符转换为大写  \n",
    "    df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)  \n",
    "  \n",
    "    # 初始化一个字典来存储每列的统计结果  \n",
    "    result = {}  \n",
    "  \n",
    "    # 遍历每一列并统计W:T:L的数量  \n",
    "    for column in df.columns[1:]:  # 跳过第一列（假设第一列是索引或非统计列）  \n",
    "        counts = df[column].value_counts().to_dict()  \n",
    "        w_count = counts.get('W', 0)  \n",
    "        t_count = counts.get('T', 0)  \n",
    "        l_count = counts.get('L', 0)  \n",
    "        result[column] = f'{w_count}:{t_count}:{l_count}'  \n",
    "  \n",
    "    return result  \n",
    "  \n",
    "# 文件路径  \n",
    "file_path = 'Label_two.xlsx'  \n",
    "  \n",
    "# 需要处理的工作表名称  \n",
    "sheets = ['Lingjie', 'Shaohanh', 'Label3_8B']  # 假设另外两个工作表名为Sheet1和Sheet2，根据实际情况修改  \n",
    "  \n",
    "# 初始化一个DataFrame来存储所有结果  \n",
    "all_results = pd.DataFrame()  \n",
    "  \n",
    "# 处理每个工作表  \n",
    "for sheet in sheets:  \n",
    "    sheet_result = process_sheet(file_path, sheet)  \n",
    "    sheet_df = pd.DataFrame(list(sheet_result.items()), columns=['Model', sheet])  \n",
    "    if all_results.empty:  \n",
    "        all_results = sheet_df  \n",
    "    else:  \n",
    "        all_results = all_results.merge(sheet_df, on='Model', how='outer')  \n",
    "  \n",
    "# 将结果写入CSV文件  \n",
    "output_file = 'result.csv'  \n",
    "all_results.to_csv(output_file, index=False)  \n",
    "  \n",
    "print(f'Results have been written to {output_file}')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results have been written to result_70B.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_610907/3872925005.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_610907/3872925005.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_610907/3872925005.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "  \n",
    "def process_sheet(file_path, sheet_name):  \n",
    "    # 读取指定工作表  \n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)  \n",
    "  \n",
    "    # 将所有字符转换为大写  \n",
    "    df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)  \n",
    "  \n",
    "    # 初始化一个字典来存储每列的统计结果  \n",
    "    result = {}  \n",
    "  \n",
    "    # 遍历每一列并统计W:T:L的数量  \n",
    "    for column in df.columns[1:]:  # 跳过第一列（假设第一列是索引或非统计列）  \n",
    "        counts = df[column].value_counts().to_dict()  \n",
    "        w_count = counts.get('W', 0)  \n",
    "        t_count = counts.get('T', 0)  \n",
    "        l_count = counts.get('L', 0)  \n",
    "        result[column] = f'{w_count}:{t_count}:{l_count}'  \n",
    "  \n",
    "    return result  \n",
    "  \n",
    "# 文件路径  \n",
    "file_path = 'Label_two.xlsx'  \n",
    "  \n",
    "# 需要处理的工作表名称  \n",
    "sheets = ['Lingjie-70B', 'shaohanh-70B', 'Label3-70B']  # 假设另外两个工作表名为Sheet1和Sheet2，根据实际情况修改   \n",
    "  \n",
    "# 初始化一个DataFrame来存储所有结果  \n",
    "all_results = pd.DataFrame()  \n",
    "  \n",
    "# 处理每个工作表  \n",
    "for sheet in sheets:  \n",
    "    sheet_result = process_sheet(file_path, sheet)  \n",
    "    sheet_df = pd.DataFrame(list(sheet_result.items()), columns=['Model', sheet])  \n",
    "    if all_results.empty:  \n",
    "        all_results = sheet_df  \n",
    "    else:  \n",
    "        all_results = all_results.merge(sheet_df, on='Model', how='outer')  \n",
    "  \n",
    "# 将结果写入CSV文件  \n",
    "output_file = 'result_70B.csv'  \n",
    "all_results.to_csv(output_file, index=False)  \n",
    "  \n",
    "print(f'Results have been written to {output_file}')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged results have been written to merged_result.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "  \n",
    "# 读取第一个CSV文件  \n",
    "result_8B = pd.read_csv('result.csv')  \n",
    "  \n",
    "# 读取第二个CSV文件  \n",
    "result_70B = pd.read_csv('result_70B.csv')  \n",
    "  \n",
    "# 合并两个DataFrame  \n",
    "merged_results = pd.merge(result_8B, result_70B, on='Model', how='outer')  \n",
    "  \n",
    "# 将合并后的结果写入新的CSV文件  \n",
    "output_file = 'merged_result.csv'  \n",
    "merged_results.to_csv(output_file, index=False)  \n",
    "  \n",
    "print(f'Merged results have been written to {output_file}')  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "  \n",
    "def process_sheet(file_path, sheet_name):  \n",
    "    # 读取指定工作表  \n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)  \n",
    "  \n",
    "    # 将所有字符转换为大写  \n",
    "    df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)  \n",
    "  \n",
    "    # 初始化一个字典来存储每列的统计结果  \n",
    "    result = {}  \n",
    "  \n",
    "    # 遍历每一列并统计W:T:L的数量  \n",
    "    for column in df.columns[1:]:  # 跳过第一列（假设第一列是索引或非统计列）  \n",
    "        counts = df[column].value_counts().to_dict()  \n",
    "        w_count = counts.get('W', 0)  \n",
    "        t_count = counts.get('T', 0)  \n",
    "        l_count = counts.get('L', 0)  \n",
    "        result[column] = f'{w_count}:{t_count}:{l_count}'  \n",
    "  \n",
    "    return result  \n",
    "  \n",
    "# 文件路径  \n",
    "file_path = 'Label_two.xlsx'  \n",
    "  \n",
    "# 需要处理的工作表名称  \n",
    "sheets = ['Lingjie', 'Shaohanh', 'Label3_8B']  # 假设另外两个工作表名为Sheet1和Sheet2，根据实际情况修改  \n",
    "  \n",
    "# 初始化一个DataFrame来存储所有结果  \n",
    "all_results = pd.DataFrame()  \n",
    "  \n",
    "# 处理每个工作表  \n",
    "for sheet in sheets:  \n",
    "    sheet_result = process_sheet(file_path, sheet)  \n",
    "    sheet_df = pd.DataFrame(list(sheet_result.items()), columns=['Model', sheet])  \n",
    "    if all_results.empty:  \n",
    "        all_results = sheet_df  \n",
    "    else:  \n",
    "        all_results = all_results.merge(sheet_df, on='Model', how='outer')  \n",
    "  \n",
    "# 将结果写入CSV文件  \n",
    "output_file = 'result.csv'  \n",
    "all_results.to_csv(output_file, index=False)  \n",
    "  \n",
    "print(f'Results have been written to {output_file}')  \n",
    "\n",
    "import pandas as pd  \n",
    "  \n",
    "def process_sheet(file_path, sheet_name):  \n",
    "    # 读取指定工作表  \n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)  \n",
    "  \n",
    "    # 将所有字符转换为大写  \n",
    "    df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)  \n",
    "      \n",
    "    return df  \n",
    "  \n",
    "def calculate_agreement(df1, df2):  \n",
    "    # 确保两个DataFrame的索引和列对齐  \n",
    "    df1 = df1.set_index(df1.columns[0])  \n",
    "    df2 = df2.set_index(df2.columns[0])  \n",
    "      \n",
    "    agreements = {}  \n",
    "    for col in df1.columns:  \n",
    "        comparison = df1[col] == df2[col]  \n",
    "        agreements[col] = comparison.mean()  \n",
    "          \n",
    "    return agreements  \n",
    "  \n",
    "# 文件路径  \n",
    "file_path = 'Label_two.xlsx'  \n",
    "  \n",
    "# 需要处理的工作表名称  \n",
    "sheets = ['Lingjie-70B', 'shaohanh-70B', 'Label3-70B']  # 假设另外两个工作表名为Sheet1和Sheet2，根据实际情况修改  \n",
    "  \n",
    "# 读取所有的表  \n",
    "dfs = {sheet: process_sheet(file_path, sheet) for sheet in sheets}  \n",
    "  \n",
    "# 计算每对工作表的一致性  \n",
    "results = {}  \n",
    "for i, sheet1 in enumerate(sheets):  \n",
    "    for j, sheet2 in enumerate(sheets):  \n",
    "        if i < j:  \n",
    "            agreement = calculate_agreement(dfs[sheet1], dfs[sheet2])  \n",
    "            results[f'{sheet1} vs {sheet2}'] = agreement  \n",
    "  \n",
    "# 将结果转换为DataFrame  \n",
    "agreement_df = pd.DataFrame(results).T  \n",
    "  \n",
    "# 计算每列的平均一致性  \n",
    "agreement_df['Average'] = agreement_df.mean(axis=1)  \n",
    "  \n",
    "# 将结果写入CSV文件  \n",
    "output_file = 'agreement_result_2.csv'  \n",
    "agreement_df.to_csv(output_file)  \n",
    "  \n",
    "print(f'Results have been written to {output_file}')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "  \n",
    "def process_sheet(file_path, sheet_name):  \n",
    "    # 读取指定工作表  \n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)  \n",
    "  \n",
    "    # 将所有字符转换为大写  \n",
    "    df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)  \n",
    "  \n",
    "    # 初始化一个字典来存储每列的统计结果  \n",
    "    result = {}  \n",
    "  \n",
    "    # 遍历每一列并统计W:T:L的数量  \n",
    "    for column in df.columns[1:]:  # 跳过第一列（假设第一列是索引或非统计列）  \n",
    "        counts = df[column].value_counts().to_dict()  \n",
    "        w_count = counts.get('W', 0)  \n",
    "        t_count = counts.get('T', 0)  \n",
    "        l_count = counts.get('L', 0)  \n",
    "        result[column] = f'{w_count}:{t_count}:{l_count}'  \n",
    "  \n",
    "    return result  \n",
    "  \n",
    "# 文件路径  \n",
    "file_path = 'Label_two.xlsx'  \n",
    "  \n",
    "# 需要处理的工作表名称  \n",
    "sheets = ['Lingjie', 'Shaohanh', 'Label3_8B']  # 假设另外两个工作表名为Sheet1和Sheet2，根据实际情况修改  \n",
    "  \n",
    "# 初始化一个DataFrame来存储所有结果  \n",
    "all_results = pd.DataFrame()  \n",
    "  \n",
    "# 处理每个工作表  \n",
    "for sheet in sheets:  \n",
    "    sheet_result = process_sheet(file_path, sheet)  \n",
    "    sheet_df = pd.DataFrame(list(sheet_result.items()), columns=['Model', sheet])  \n",
    "    if all_results.empty:  \n",
    "        all_results = sheet_df  \n",
    "    else:  \n",
    "        all_results = all_results.merge(sheet_df, on='Model', how='outer')  \n",
    "  \n",
    "# 将结果写入CSV文件  \n",
    "output_file = 'result.csv'  \n",
    "all_results.to_csv(output_file, index=False)  \n",
    "  \n",
    "print(f'Results have been written to {output_file}')  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "  \n",
    "def process_sheet(file_path, sheet_name):  \n",
    "    # 读取指定工作表  \n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)  \n",
    "  \n",
    "    # 将所有字符转换为大写  \n",
    "    df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)  \n",
    "  \n",
    "    # 初始化一个字典来存储每列的统计结果  \n",
    "    result = {}  \n",
    "  \n",
    "    # 遍历每一列并统计W:T:L的数量  \n",
    "    for column in df.columns[1:]:  # 跳过第一列（假设第一列是索引或非统计列）  \n",
    "        counts = df[column].value_counts().to_dict()  \n",
    "        w_count = counts.get('W', 0)  \n",
    "        t_count = counts.get('T', 0)  \n",
    "        l_count = counts.get('L', 0)  \n",
    "        result[column] = f'{w_count}:{t_count}:{l_count}'  \n",
    "  \n",
    "    return result  \n",
    "  \n",
    "# 文件路径  \n",
    "file_path = 'Label_two.xlsx'  \n",
    "  \n",
    "# 需要处理的工作表名称  \n",
    "sheets = ['Lingjie', 'Shaohanh', 'Label3_8B']  # 假设另外两个工作表名为Sheet1和Sheet2，根据实际情况修改  \n",
    "  \n",
    "# 初始化一个DataFrame来存储所有结果  \n",
    "all_results = pd.DataFrame()  \n",
    "  \n",
    "# 处理每个工作表  \n",
    "for sheet in sheets:  \n",
    "    sheet_result = process_sheet(file_path, sheet)  \n",
    "    sheet_df = pd.DataFrame(list(sheet_result.items()), columns=['Model', sheet])  \n",
    "    if all_results.empty:  \n",
    "        all_results = sheet_df  \n",
    "    else:  \n",
    "        all_results = all_results.merge(sheet_df, on='Model', how='outer')  \n",
    "  \n",
    "# 将结果写入CSV文件  \n",
    "output_file = 'result.csv'  \n",
    "all_results.to_csv(output_file, index=False)  \n",
    "  \n",
    "print(f'Results have been written to {output_file}')  \n",
    "\n",
    "\n",
    "import pandas as pd  \n",
    "  \n",
    "def process_sheet(file_path, sheet_name):  \n",
    "    # 读取指定工作表  \n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)  \n",
    "  \n",
    "    # 将所有字符转换为大写  \n",
    "    df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)  \n",
    "  \n",
    "    # 初始化一个字典来存储每列的统计结果  \n",
    "    result = {}  \n",
    "  \n",
    "    # 遍历每一列并统计W:T:L的数量  \n",
    "    for column in df.columns[1:]:  # 跳过第一列（假设第一列是索引或非统计列）  \n",
    "        counts = df[column].value_counts().to_dict()  \n",
    "        w_count = counts.get('W', 0)  \n",
    "        t_count = counts.get('T', 0)  \n",
    "        l_count = counts.get('L', 0)  \n",
    "        result[column] = f'{w_count}:{t_count}:{l_count}'  \n",
    "  \n",
    "    return result  \n",
    "  \n",
    "# 文件路径  \n",
    "file_path = 'Label_two.xlsx'  \n",
    "  \n",
    "# 需要处理的工作表名称  \n",
    "sheets = ['Lingjie-70B', 'shaohanh-70B', 'Label3-70B']  # 假设另外两个工作表名为Sheet1和Sheet2，根据实际情况修改   \n",
    "  \n",
    "# 初始化一个DataFrame来存储所有结果  \n",
    "all_results = pd.DataFrame()  \n",
    "  \n",
    "# 处理每个工作表  \n",
    "for sheet in sheets:  \n",
    "    sheet_result = process_sheet(file_path, sheet)  \n",
    "    sheet_df = pd.DataFrame(list(sheet_result.items()), columns=['Model', sheet])  \n",
    "    if all_results.empty:  \n",
    "        all_results = sheet_df  \n",
    "    else:  \n",
    "        all_results = all_results.merge(sheet_df, on='Model', how='outer')  \n",
    "  \n",
    "# 将结果写入CSV文件  \n",
    "output_file = 'result_70B.csv'  \n",
    "all_results.to_csv(output_file, index=False)  \n",
    "  \n",
    "print(f'Results have been written to {output_file}')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results have been written to result.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_717019/4245012563.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/4245012563.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/4245012563.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/4245012563.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/4245012563.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/4245012563.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd    \n",
    "  \n",
    "def process_sheet(file_path, sheet_name):    \n",
    "    # 读取指定工作表    \n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)    \n",
    "  \n",
    "    # 将所有字符转换为大写    \n",
    "    df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)    \n",
    "  \n",
    "    # 初始化一个字典来存储每列的统计结果    \n",
    "    result = {}    \n",
    "  \n",
    "    # 遍历每一列并统计W:T:L的数量    \n",
    "    for column in df.columns[1:]:  # 跳过第一列（假设第一列是索引或非统计列）    \n",
    "        counts = df[column].value_counts().to_dict()    \n",
    "        w_count = counts.get('W', 0)    \n",
    "        t_count = counts.get('T', 0)    \n",
    "        l_count = counts.get('L', 0)    \n",
    "        result[column] = f'{w_count}:{t_count}:{l_count}'    \n",
    "  \n",
    "    return result    \n",
    "  \n",
    "def process_all_sheets(file_path, sheets):    \n",
    "    # 初始化一个DataFrame来存储所有结果    \n",
    "    all_results = pd.DataFrame()    \n",
    "  \n",
    "    # 处理每个工作表    \n",
    "    for sheet in sheets:    \n",
    "        sheet_result = process_sheet(file_path, sheet)    \n",
    "        sheet_df = pd.DataFrame(list(sheet_result.items()), columns=['Model', sheet])    \n",
    "        if all_results.empty:    \n",
    "            all_results = sheet_df    \n",
    "        else:    \n",
    "            all_results = pd.merge(all_results, sheet_df, on='Model', how='outer')    \n",
    "  \n",
    "    return all_results  \n",
    "  \n",
    "# 文件路径    \n",
    "file_path = 'Label_two.xlsx'    \n",
    "  \n",
    "# 需要处理的工作表名称    \n",
    "sheets1 = ['Lingjie', 'Shaohanh', 'Label3_8B']    \n",
    "sheets2 = ['Lingjie-70B', 'shaohanh-70B', 'Label3-70B']    \n",
    "  \n",
    "results1 = process_all_sheets(file_path, sheets1)  \n",
    "results2 = process_all_sheets(file_path, sheets2)  \n",
    "  \n",
    "# 合并结果  \n",
    "all_results = pd.merge(results1, results2, on='Model', how='outer')  \n",
    "  \n",
    "# 将结果写入CSV文件    \n",
    "output_file = 'result.csv'    \n",
    "all_results.to_csv(output_file, index=False)    \n",
    "  \n",
    "print(f'Results have been written to {output_file}')    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results have been written to result_2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_717019/1442869200.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/1442869200.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/1442869200.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/1442869200.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/1442869200.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/1442869200.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd    \n",
    "  \n",
    "def process_sheet(file_path, sheet_name):    \n",
    "    # 读取指定工作表    \n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)    \n",
    "  \n",
    "    # 将所有字符转换为大写    \n",
    "    df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)    \n",
    "  \n",
    "    # 初始化一个字典来存储每列的统计结果    \n",
    "    result = {}    \n",
    "  \n",
    "    # 遍历每一列并统计W:T:L的数量    \n",
    "    for column in df.columns[1:]:  # 跳过第一列（假设第一列是索引或非统计列）    \n",
    "        counts = df[column].value_counts().to_dict()    \n",
    "        w_count = counts.get('W', 0)    \n",
    "        t_count = counts.get('T', 0)    \n",
    "        l_count = counts.get('L', 0)    \n",
    "        result[column] = f'{w_count}:{t_count}:{l_count}'    \n",
    "  \n",
    "    return result    \n",
    "  \n",
    "def process_all_sheets(file_path, sheets):    \n",
    "    # 初始化一个DataFrame来存储所有结果    \n",
    "    all_results = pd.DataFrame()    \n",
    "  \n",
    "    # 处理每个工作表    \n",
    "    for sheet in sheets:    \n",
    "        sheet_result = process_sheet(file_path, sheet)    \n",
    "        sheet_df = pd.DataFrame(list(sheet_result.items()), columns=['Model', sheet])    \n",
    "        if all_results.empty:    \n",
    "            all_results = sheet_df    \n",
    "        else:    \n",
    "            all_results = pd.merge(all_results, sheet_df, on='Model', how='outer')    \n",
    "  \n",
    "    return all_results  \n",
    "  \n",
    "# 文件路径    \n",
    "file_path = 'Label_2.xlsx'    \n",
    "  \n",
    "# 需要处理的工作表名称    \n",
    "sheets1 = ['Lingjie', 'Shaohanh', 'Label3_8B']    \n",
    "sheets2 = ['Lingjie-70B', 'shaohanh-70B', 'Label3-70B']    \n",
    "  \n",
    "results1 = process_all_sheets(file_path, sheets1)  \n",
    "results2 = process_all_sheets(file_path, sheets2)  \n",
    "  \n",
    "# 合并结果  \n",
    "all_results = pd.merge(results1, results2, on='Model', how='outer')  \n",
    "  \n",
    "# 将结果写入CSV文件    \n",
    "output_file = 'result_2.csv'    \n",
    "all_results.to_csv(output_file, index=False)    \n",
    "  \n",
    "print(f'Results have been written to {output_file}')    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results have been written to result3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_717019/79655812.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/79655812.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/79655812.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/79655812.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/79655812.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/79655812.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd    \n",
    "  \n",
    "def process_sheet(file_path, sheet_name):    \n",
    "    # 读取指定工作表    \n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)    \n",
    "  \n",
    "    # 将所有字符转换为大写    \n",
    "    df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)    \n",
    "  \n",
    "    # 初始化一个字典来存储每列的统计结果    \n",
    "    result = {}    \n",
    "  \n",
    "    # 遍历每一列并统计W:T:L的数量    \n",
    "    for column in df.columns[1:]:  # 跳过第一列（假设第一列是索引或非统计列）    \n",
    "        counts = df[column].value_counts().to_dict()    \n",
    "        w_count = counts.get('W', 0)    \n",
    "        t_count = counts.get('T', 0)    \n",
    "        l_count = counts.get('L', 0)    \n",
    "        result[column] = f'{w_count}:{t_count}:{l_count}'    \n",
    "  \n",
    "    return result    \n",
    "  \n",
    "def process_all_sheets(file_path, sheets):    \n",
    "    # 初始化一个DataFrame来存储所有结果    \n",
    "    all_results = pd.DataFrame()    \n",
    "  \n",
    "    # 处理每个工作表    \n",
    "    for sheet in sheets:    \n",
    "        sheet_result = process_sheet(file_path, sheet)    \n",
    "        sheet_df = pd.DataFrame(list(sheet_result.items()), columns=['Model', sheet])    \n",
    "        if all_results.empty:    \n",
    "            all_results = sheet_df    \n",
    "        else:    \n",
    "            all_results = pd.merge(all_results, sheet_df, on='Model', how='outer')    \n",
    "  \n",
    "    return all_results  \n",
    "  \n",
    "# 文件路径    \n",
    "file_path = 'Label_two.xlsx'    \n",
    "  \n",
    "# 需要处理的工作表名称    \n",
    "sheets1 = ['Lingjie', 'Shaohanh', 'Label3_8B']    \n",
    "sheets2 = ['Lingjie-70B', 'shaohanh-70B', 'Label3-70B']    \n",
    "  \n",
    "results1 = process_all_sheets(file_path, sheets1)  \n",
    "results2 = process_all_sheets(file_path, sheets2)  \n",
    "  \n",
    "# 合并结果  \n",
    "all_results = pd.merge(results1, results2, on='Model', how='outer')  \n",
    "  \n",
    "# 计算每个表格W:T:L的总和和平均值  \n",
    "for sheet in all_results.columns[1:]:  \n",
    "    all_results[sheet+\"_sum\"] = all_results[sheet].apply(lambda x: sum(map(int, str(x).split(\":\"))))  \n",
    "    all_results[sheet+\"_average\"] = all_results[sheet].apply(lambda x: round(sum(map(int, str(x).split(\":\")))/3, 2))  \n",
    "  \n",
    "# 将结果写入CSV文件    \n",
    "output_file = 'result3.csv'    \n",
    "all_results.to_csv(output_file, index=False)    \n",
    "  \n",
    "print(f'Results have been written to {output_file}')    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results have been written to result1.csv and result2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_717019/2704018744.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/2704018744.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/2704018744.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/2704018744.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/2704018744.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/2704018744.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "  \n",
    "def process_sheet(file_path, sheet_name):  \n",
    "    # 读取指定工作表  \n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)  \n",
    "  \n",
    "    # 将所有字符转换为大写  \n",
    "    df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)  \n",
    "  \n",
    "    # 遍历每一列并统计W:T:L的数量  \n",
    "    for column in df.columns[1:]:  # 跳过第一列（假设第一列是索引或非统计列）  \n",
    "        counts = df[column].value_counts().to_dict()  \n",
    "        w_count = counts.get('W', 0)  \n",
    "        t_count = counts.get('T', 0)  \n",
    "        l_count = counts.get('L', 0)  \n",
    "        df[column] = f'{w_count}:{t_count}:{l_count}'  \n",
    "  \n",
    "    return df  \n",
    "  \n",
    "def process_all_sheets(file_path, sheets):  \n",
    "    # 初始化一个DataFrame来存储所有结果  \n",
    "    all_results = pd.DataFrame()  \n",
    "  \n",
    "    # 处理每个工作表  \n",
    "    for sheet in sheets:  \n",
    "        sheet_df = process_sheet(file_path, sheet)  \n",
    "        if all_results.empty:  \n",
    "            all_results = sheet_df  \n",
    "        else:  \n",
    "            all_results = pd.concat([all_results, sheet_df], ignore_index=True)  \n",
    "  \n",
    "    # 计算每一列的W:T:L的总和和平均值  \n",
    "    for column in all_results.columns[1:]:  \n",
    "        all_results[column+\"_sum\"] = all_results[column].apply(lambda x: sum(map(int, str(x).split(\":\"))))  \n",
    "        all_results[column+\"_average\"] = all_results[column].apply(lambda x: round(sum(map(int, str(x).split(\":\")))/3, 2))  \n",
    "  \n",
    "    return all_results  \n",
    "  \n",
    "# 文件路径  \n",
    "file_path = 'Label_two.xlsx'  \n",
    "  \n",
    "# 需要处理的工作表名称  \n",
    "sheets1 = ['Lingjie', 'Shaohanh', 'Label3_8B']  \n",
    "sheets2 = ['Lingjie-70B', 'shaohanh-70B', 'Label3-70B']  \n",
    "  \n",
    "results1 = process_all_sheets(file_path, sheets1)  \n",
    "results2 = process_all_sheets(file_path, sheets2)  \n",
    "  \n",
    "# 将结果写入CSV文件  \n",
    "output_file1 = 'result1.csv'  \n",
    "results1.to_csv(output_file1, index=False)  \n",
    "  \n",
    "output_file2 = 'result2.csv'  \n",
    "results2.to_csv(output_file2, index=False)  \n",
    "  \n",
    "print(f'Results have been written to {output_file1} and {output_file2}')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_717019/448725002.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/448725002.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/448725002.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/448725002.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/448725002.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/448725002.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "  \n",
    "def process_sheet(file_path, sheet_name):      \n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)      \n",
    "    df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)      \n",
    "    result = {}      \n",
    "    \n",
    "    for column in df.columns[1:]:  \n",
    "        counts = df[column].value_counts().to_dict()      \n",
    "        w_count = counts.get('W', 0)      \n",
    "        t_count = counts.get('T', 0)      \n",
    "        l_count = counts.get('L', 0)      \n",
    "        result[column] = f'{w_count}:{t_count}:{l_count}'      \n",
    "    \n",
    "    return result      \n",
    "  \n",
    "def process_all_sheets(file_path, sheets):      \n",
    "    all_results = pd.DataFrame()      \n",
    "  \n",
    "    for sheet in sheets:      \n",
    "        sheet_result = process_sheet(file_path, sheet)      \n",
    "        sheet_df = pd.DataFrame(list(sheet_result.items()), columns=['Model', sheet])      \n",
    "        if all_results.empty:      \n",
    "            all_results = sheet_df      \n",
    "        else:      \n",
    "            all_results = pd.merge(all_results, sheet_df, on='Model', how='outer')      \n",
    "    \n",
    "    return all_results    \n",
    "  \n",
    "def process_wtl(wtl_str):  \n",
    "    w, t, l = map(int, wtl_str.split(':'))  \n",
    "    return w, t, l  \n",
    "  \n",
    "file_path = 'Label_2.xlsx'      \n",
    "sheets1 = ['Lingjie', 'Shaohanh', 'Label3_8B']      \n",
    "sheets2 = ['Lingjie-70B', 'shaohanh-70B', 'Label3-70B']      \n",
    "  \n",
    "results1 = process_all_sheets(file_path, sheets1)    \n",
    "results2 = process_all_sheets(file_path, sheets2)    \n",
    "  \n",
    "all_results = pd.merge(results1, results2, on='Model', how='outer')    \n",
    "  \n",
    "groups = [sheets1, sheets2]  \n",
    "for group in groups:  \n",
    "    for column in group:  \n",
    "        all_results[[f'{column}_W', f'{column}_T', f'{column}_L']] = all_results[column].apply(process_wtl).apply(pd.Series)  \n",
    "  \n",
    "    group_columns = [f'{column}_W' for column in group] + [f'{column}_T' for column in group] + [f'{column}_L' for column in group]  \n",
    "    all_results[f'{group[0]}_group_sum'] = all_results[group_columns].sum(axis=1)  \n",
    "    all_results[f'{group[0]}_group_avg'] = all_results[group_columns].mean(axis=1)  \n",
    "  \n",
    "all_results.to_csv('result_2_group_sum_avg.csv', index=False)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_717019/4063661493.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/4063661493.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/4063661493.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/4063661493.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/4063661493.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/4063661493.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "  \n",
    "def process_sheet(file_path, sheet_name):      \n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)      \n",
    "    df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)      \n",
    "    result = {}      \n",
    "    \n",
    "    for column in df.columns[1:]:  \n",
    "        counts = df[column].value_counts().to_dict()      \n",
    "        w_count = counts.get('W', 0)      \n",
    "        t_count = counts.get('T', 0)      \n",
    "        l_count = counts.get('L', 0)      \n",
    "        result[column] = f'{w_count}:{t_count}:{l_count}'      \n",
    "    \n",
    "    return result      \n",
    "  \n",
    "def process_all_sheets(file_path, sheets):      \n",
    "    all_results = pd.DataFrame()      \n",
    "  \n",
    "    for sheet in sheets:      \n",
    "        sheet_result = process_sheet(file_path, sheet)      \n",
    "        sheet_df = pd.DataFrame(list(sheet_result.items()), columns=['Model', sheet])      \n",
    "        if all_results.empty:      \n",
    "            all_results = sheet_df      \n",
    "        else:      \n",
    "            all_results = pd.merge(all_results, sheet_df, on='Model', how='outer')      \n",
    "    \n",
    "    return all_results    \n",
    "  \n",
    "def process_wtl(wtl_str):  \n",
    "    w, t, l = map(int, wtl_str.split(':'))  \n",
    "    return w, t, l  \n",
    "  \n",
    "file_path = 'Label_2.xlsx'      \n",
    "sheets1 = ['Lingjie', 'Shaohanh', 'Label3_8B']      \n",
    "sheets2 = ['Lingjie-70B', 'shaohanh-70B', 'Label3-70B']      \n",
    "  \n",
    "results1 = process_all_sheets(file_path, sheets1)    \n",
    "results2 = process_all_sheets(file_path, sheets2)    \n",
    "  \n",
    "all_results = pd.merge(results1, results2, on='Model', how='outer')    \n",
    "  \n",
    "groups = [sheets1, sheets2]  \n",
    "for group in groups:  \n",
    "    group_results = pd.DataFrame()  \n",
    "    for column in group:  \n",
    "        group_results[[f'{column}_W', f'{column}_T', f'{column}_L']] = all_results[column].apply(process_wtl).apply(pd.Series)  \n",
    "  \n",
    "    all_results[f'{group[0]}_group_sum'] = group_results.sum(axis=1)  \n",
    "    all_results[f'{group[0]}_group_avg'] = group_results.mean(axis=1)  \n",
    "  \n",
    "all_results.to_csv('result_2_group_sum_avg.csv', index=False)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_717019/3729521858.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/3729521858.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/3729521858.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/3729521858.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/3729521858.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/3729521858.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "  \n",
    "def process_sheet(file_path, sheet_name):      \n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)      \n",
    "    df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)      \n",
    "    result = {}      \n",
    "    \n",
    "    for column in df.columns[1:]:  \n",
    "        counts = df[column].value_counts().to_dict()      \n",
    "        w_count = counts.get('W', 0)      \n",
    "        t_count = counts.get('T', 0)      \n",
    "        l_count = counts.get('L', 0)      \n",
    "        result[column] = f'{w_count}:{t_count}:{l_count}'      \n",
    "    \n",
    "    return result      \n",
    "  \n",
    "def process_all_sheets(file_path, sheets):      \n",
    "    all_results = pd.DataFrame()      \n",
    "  \n",
    "    for sheet in sheets:      \n",
    "        sheet_result = process_sheet(file_path, sheet)      \n",
    "        sheet_df = pd.DataFrame(list(sheet_result.items()), columns=['Model', sheet])      \n",
    "        if all_results.empty:      \n",
    "            all_results = sheet_df      \n",
    "        else:      \n",
    "            all_results = pd.merge(all_results, sheet_df, on='Model', how='outer')      \n",
    "    \n",
    "    return all_results    \n",
    "  \n",
    "def process_wtl(wtl_str):  \n",
    "    w, t, l = map(int, wtl_str.split(':'))  \n",
    "    return w, t, l  \n",
    "  \n",
    "file_path = 'Label_2.xlsx'      \n",
    "sheets1 = ['Lingjie', 'Shaohanh', 'Label3_8B']   \n",
    "sheets2 = ['Lingjie-70B', 'shaohanh-70B', 'Label3-70B']     \n",
    "  \n",
    "results1 = process_all_sheets(file_path, sheets1)    \n",
    "results2 = process_all_sheets(file_path, sheets2)    \n",
    "  \n",
    "all_results = pd.merge(results1, results2, on='Model', how='outer')    \n",
    "  \n",
    "for index, row in all_results.iterrows():  \n",
    "    w_sum = t_sum = l_sum = 0  \n",
    "    for column in sheets1:  \n",
    "        w, t, l = process_wtl(row[column])  \n",
    "        w_sum += w  \n",
    "        t_sum += t  \n",
    "        l_sum += l  \n",
    "    all_results.loc[index, 'group_1_sum'] = f'{w_sum}:{t_sum}:{l_sum}'  \n",
    "    all_results.loc[index, 'group_1_avg'] = f'{w_sum//len(sheets1)}:{t_sum//len(sheets1)}:{l_sum//len(sheets1)}'  \n",
    "  \n",
    "    w_sum = t_sum = l_sum = 0  \n",
    "    for column in sheets2:  \n",
    "        w, t, l = process_wtl(row[column])  \n",
    "        w_sum += w  \n",
    "        t_sum += t  \n",
    "        l_sum += l  \n",
    "    all_results.loc[index, 'group_2_sum'] = f'{w_sum}:{t_sum}:{l_sum}'  \n",
    "    all_results.loc[index, 'group_2_avg'] = f'{w_sum//len(sheets2)}:{t_sum//len(sheets2)}:{l_sum//len(sheets2)}'  \n",
    "  \n",
    "all_results.to_csv('result_2_group_sum_avg.csv', index=False)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_717019/1244520072.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/1244520072.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/1244520072.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/1244520072.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/1244520072.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/1244520072.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "  \n",
    "def process_sheet(file_path, sheet_name):  \n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)  \n",
    "    df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)  \n",
    "    result = {}  \n",
    "  \n",
    "    for column in df.columns[1:]:  \n",
    "        counts = df[column].value_counts().to_dict()  \n",
    "        w_count = counts.get('W', 0)  \n",
    "        t_count = counts.get('T', 0)  \n",
    "        l_count = counts.get('L', 0)  \n",
    "        result[column] = f'{w_count}:{t_count}:{l_count}'  \n",
    "  \n",
    "    return result  \n",
    "  \n",
    "def process_all_sheets(file_path, sheets):  \n",
    "    all_results = pd.DataFrame()  \n",
    "  \n",
    "    for sheet in sheets:  \n",
    "        sheet_result = process_sheet(file_path, sheet)  \n",
    "        sheet_df = pd.DataFrame(list(sheet_result.items()), columns=['Model', sheet])  \n",
    "        if all_results.empty:  \n",
    "            all_results = sheet_df  \n",
    "        else:  \n",
    "            all_results = pd.merge(all_results, sheet_df, on='Model', how='outer')  \n",
    "  \n",
    "    return all_results  \n",
    "  \n",
    "def process_wtl(wtl_str):  \n",
    "    w, t, l = map(int, wtl_str.split(':'))  \n",
    "    return w, t, l  \n",
    "  \n",
    "file_path = 'Label_2.xlsx'  \n",
    "sheets1 = ['Lingjie', 'Shaohanh', 'Label3_8B']  \n",
    "sheets2 = ['Lingjie-70B', 'shaohanh-70B', 'Label3-70B']  \n",
    "  \n",
    "results1 = process_all_sheets(file_path, sheets1)  \n",
    "results2 = process_all_sheets(file_path, sheets2)  \n",
    "  \n",
    "all_results = pd.merge(results1, results2, on='Model', how='outer')  \n",
    "  \n",
    "for index, row in all_results.iterrows():  \n",
    "    w_sum = t_sum = l_sum = 0  \n",
    "    for column in sheets1:  \n",
    "        w, t, l = process_wtl(row[column])  \n",
    "        w_sum += w  \n",
    "        t_sum += t  \n",
    "        l_sum += l  \n",
    "    all_results.loc[index, 'group_1_sum'] = f'{w_sum}:{t_sum}:{l_sum}'  \n",
    "    all_results.loc[index, 'group_1_avg'] = f'{w_sum/len(sheets1):.1f}:{t_sum/len(sheets1):.1f}:{l_sum/len(sheets1):.1f}'  \n",
    "  \n",
    "    w_sum = t_sum = l_sum = 0  \n",
    "    for column in sheets2:  \n",
    "        w, t, l = process_wtl(row[column])  \n",
    "        w_sum += w  \n",
    "        t_sum += t  \n",
    "        l_sum += l  \n",
    "    all_results.loc[index, 'group_2_sum'] = f'{w_sum}:{t_sum}:{l_sum}'  \n",
    "    all_results.loc[index, 'group_2_avg'] = f'{w_sum/len(sheets2):.1f}:{t_sum/len(sheets2):.1f}:{l_sum/len(sheets2):.1f}'  \n",
    "  \n",
    "all_results.to_csv('result_2_group_sum_avg.csv', index=False)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results have been written to agreement_result.csv\n",
      "Results have been written to agreement_result_2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_717019/2301225137.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/2301225137.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/2301225137.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/2301225137.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/2301225137.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/2301225137.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "  \n",
    "def process_sheet(file_path, sheet_name):    \n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)    \n",
    "    df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)  \n",
    "    return df    \n",
    "  \n",
    "def calculate_agreement(df1, df2):    \n",
    "    df1 = df1.set_index(df1.columns[0])    \n",
    "    df2 = df2.set_index(df2.columns[0])    \n",
    "        \n",
    "    agreements = {}    \n",
    "    for col in df1.columns:    \n",
    "        comparison = df1[col] == df2[col]    \n",
    "        agreements[col] = comparison.mean()  \n",
    "    return agreements    \n",
    "  \n",
    "# 文件路径    \n",
    "file_path = 'Label_2.xlsx'    \n",
    "  \n",
    "# 需要处理的工作表名称和输出文件名  \n",
    "sheets_and_output_files = [  \n",
    "    (['Lingjie', 'Shaohanh', 'Label3_8B'], 'agreement_result.csv'),  \n",
    "    (['Lingjie-70B', 'shaohanh-70B', 'Label3-70B'], 'agreement_result_2.csv')  \n",
    "]  \n",
    "  \n",
    "for sheets, output_file in sheets_and_output_files:  \n",
    "    # 读取所有的表    \n",
    "    dfs = {sheet: process_sheet(file_path, sheet) for sheet in sheets}    \n",
    "  \n",
    "    # 计算每对工作表的一致性    \n",
    "    results = {}    \n",
    "    for i, sheet1 in enumerate(sheets):    \n",
    "        for j, sheet2 in enumerate(sheets):    \n",
    "            if i < j:    \n",
    "                agreement = calculate_agreement(dfs[sheet1], dfs[sheet2])    \n",
    "                results[f'{sheet1} vs {sheet2}'] = agreement    \n",
    "  \n",
    "    # 将结果转换为DataFrame    \n",
    "    agreement_df = pd.DataFrame(results).T    \n",
    "  \n",
    "    # 计算每列的平均一致性    \n",
    "    agreement_df['Average'] = agreement_df.mean(axis=1)    \n",
    "  \n",
    "    # 将结果写入CSV文件    \n",
    "    agreement_df.to_csv(output_file)    \n",
    "  \n",
    "    print(f'Results have been written to {output_file}')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Unnamed: 0  Meta-Llama-3.1-8B-Instruct  \\\n",
      "0    Lingjie vs Shaohanh                        0.72   \n",
      "1   Lingjie vs Label3_8B                        0.70   \n",
      "2  Shaohanh vs Label3_8B                        0.74   \n",
      "\n",
      "   Meta-Llama-3.1-70B-Instruct  Qwen2-72B-Instruct  tulu-2-dpo-70b  Average  \n",
      "0                         0.66                0.76            0.88   0.7825  \n",
      "1                         0.74                0.84            0.92   0.8100  \n",
      "2                         0.68                0.76            0.92   0.7875  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "  \n",
    "# 读取CSV文件  \n",
    "file1 = 'agreement_result.csv'  \n",
    "file2 = 'agreement_result_2.csv'  \n",
    "  \n",
    "df1 = pd.read_csv(file1)  \n",
    "df2 = pd.read_csv(file2)  \n",
    "  \n",
    "# 提取最后一列  \n",
    "last_col1 = df1.iloc[:, -1]  \n",
    "last_col2 = df2.iloc[:, -1]  \n",
    "  \n",
    "# 计算对应行的平均值  \n",
    "average_col = (last_col1 + last_col2) / 2  \n",
    "  \n",
    "# 将结果放在第三列  \n",
    "df1['Average'] = average_col  \n",
    "  \n",
    "# 保存结果到新的CSV文件  \n",
    "df1.to_csv('agreement_result_with_average.csv', index=False)  \n",
    "  \n",
    "print(df1)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "将这个代码中的平均结果写入到另外一个csv中，列名w1，t1,l1,w2,t2,l2\n",
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "  \n",
    "def process_sheet(file_path, sheet_name):  \n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)  \n",
    "    df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)  \n",
    "    result = {}  \n",
    "  \n",
    "    for column in df.columns[1:]:  \n",
    "        counts = df[column].value_counts().to_dict()  \n",
    "        w_count = counts.get('W', 0)  \n",
    "        t_count = counts.get('T', 0)  \n",
    "        l_count = counts.get('L', 0)  \n",
    "        result[column] = f'{w_count}:{t_count}:{l_count}'  \n",
    "  \n",
    "    return result  \n",
    "  \n",
    "def process_all_sheets(file_path, sheets):  \n",
    "    all_results = pd.DataFrame()  \n",
    "  \n",
    "    for sheet in sheets:  \n",
    "        sheet_result = process_sheet(file_path, sheet)  \n",
    "        sheet_df = pd.DataFrame(list(sheet_result.items()), columns=['Model', sheet])  \n",
    "        if all_results.empty:  \n",
    "            all_results = sheet_df  \n",
    "        else:  \n",
    "            all_results = pd.merge(all_results, sheet_df, on='Model', how='outer')  \n",
    "  \n",
    "    return all_results  \n",
    "  \n",
    "def process_wtl(wtl_str):  \n",
    "    w, t, l = map(int, wtl_str.split(':'))  \n",
    "    return w, t, l  \n",
    "  \n",
    "file_path = 'Label_2.xlsx'  \n",
    "sheets1 = ['Lingjie', 'Shaohanh', 'Label3_8B']  \n",
    "sheets2 = ['Lingjie-70B', 'shaohanh-70B', 'Label3-70B']  \n",
    "  \n",
    "results1 = process_all_sheets(file_path, sheets1)  \n",
    "results2 = process_all_sheets(file_path, sheets2)  \n",
    "  \n",
    "all_results = pd.merge(results1, results2, on='Model', how='outer')  \n",
    "  \n",
    "for index, row in all_results.iterrows():  \n",
    "    w_sum = t_sum = l_sum = 0  \n",
    "    for column in sheets1:  \n",
    "        w, t, l = process_wtl(row[column])  \n",
    "        w_sum += w  \n",
    "        t_sum += t  \n",
    "        l_sum += l  \n",
    "    all_results.loc[index, 'group_1_sum'] = f'{w_sum}:{t_sum}:{l_sum}'  \n",
    "    all_results.loc[index, 'group_1_avg'] = f'{w_sum/len(sheets1):.1f}:{t_sum/len(sheets1):.1f}:{l_sum/len(sheets1):.1f}'  \n",
    "  \n",
    "    w_sum = t_sum = l_sum = 0  \n",
    "    for column in sheets2:  \n",
    "        w, t, l = process_wtl(row[column])  \n",
    "        w_sum += w  \n",
    "        t_sum += t  \n",
    "        l_sum += l  \n",
    "    all_results.loc[index, 'group_2_sum'] = f'{w_sum}:{t_sum}:{l_sum}'  \n",
    "    all_results.loc[index, 'group_2_avg'] = f'{w_sum/len(sheets2):.1f}:{t_sum/len(sheets2):.1f}:{l_sum/len(sheets2):.1f}'  \n",
    "  \n",
    "all_results.to_csv('result_2_group_sum_avg.csv', index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_717019/2766127693.py:7: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/2766127693.py:7: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/2766127693.py:7: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/2766127693.py:7: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/2766127693.py:7: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/2766127693.py:7: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "# 将这个代码中的平均结果写入到另外一个csv中，列名w1，t1,l1,w2,t2,l2\n",
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "  \n",
    "def process_sheet(file_path, sheet_name):  \n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)  \n",
    "    df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)  \n",
    "    result = {}  \n",
    "  \n",
    "    for column in df.columns[1:]:  \n",
    "        counts = df[column].value_counts().to_dict()  \n",
    "        w_count = counts.get('W', 0)  \n",
    "        t_count = counts.get('T', 0)  \n",
    "        l_count = counts.get('L', 0)  \n",
    "        result[column] = f'{w_count}:{t_count}:{l_count}'  \n",
    "  \n",
    "    return result  \n",
    "  \n",
    "def process_all_sheets(file_path, sheets):  \n",
    "    all_results = pd.DataFrame()  \n",
    "  \n",
    "    for sheet in sheets:  \n",
    "        sheet_result = process_sheet(file_path, sheet)  \n",
    "        sheet_df = pd.DataFrame(list(sheet_result.items()), columns=['Model', sheet])  \n",
    "        if all_results.empty:  \n",
    "            all_results = sheet_df  \n",
    "        else:  \n",
    "            all_results = pd.merge(all_results, sheet_df, on='Model', how='outer')  \n",
    "  \n",
    "    return all_results  \n",
    "  \n",
    "def process_wtl(wtl_str):  \n",
    "    w, t, l = map(int, wtl_str.split(':'))  \n",
    "    return w, t, l  \n",
    "  \n",
    "file_path = 'Label_2.xlsx'  \n",
    "sheets1 = ['Lingjie', 'Shaohanh', 'Label3_8B']  \n",
    "sheets2 = ['Lingjie-70B', 'shaohanh-70B', 'Label3-70B']  \n",
    "  \n",
    "results1 = process_all_sheets(file_path, sheets1)  \n",
    "results2 = process_all_sheets(file_path, sheets2)  \n",
    "  \n",
    "all_results = pd.merge(results1, results2, on='Model', how='outer')  \n",
    "  \n",
    "for index, row in all_results.iterrows():  \n",
    "    w_sum = t_sum = l_sum = 0  \n",
    "    for column in sheets1:  \n",
    "        w, t, l = process_wtl(row[column])  \n",
    "        w_sum += w  \n",
    "        t_sum += t  \n",
    "        l_sum += l  \n",
    "    all_results.loc[index, 'group_1_sum'] = f'{w_sum}/{t_sum}/{l_sum}'  \n",
    "    all_results.loc[index, 'group_1_avg'] = f'{w_sum/len(sheets1):.1f}/{t_sum/len(sheets1):.1f}/{l_sum/len(sheets1):.1f}'  \n",
    "  \n",
    "    w_sum = t_sum = l_sum = 0  \n",
    "    for column in sheets2:  \n",
    "        w, t, l = process_wtl(row[column])  \n",
    "        w_sum += w  \n",
    "        t_sum += t  \n",
    "        l_sum += l  \n",
    "    all_results.loc[index, 'group_2_sum'] = f'{w_sum}/{t_sum}/{l_sum}'  \n",
    "    all_results.loc[index, 'group_2_avg'] = f'{w_sum/len(sheets2):.1f}/{t_sum/len(sheets2):.1f}/{l_sum/len(sheets2):.1f}'  \n",
    "  \n",
    "all_results.to_csv('result_3_group_sum_avg.csv', index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_717019/3559737155.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/3559737155.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/3559737155.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/3559737155.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/3559737155.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/3559737155.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "  \n",
    "def process_sheet(file_path, sheet_name):  \n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)  \n",
    "    df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)  \n",
    "    result = {}  \n",
    "  \n",
    "    for column in df.columns[1:]:  \n",
    "        counts = df[column].value_counts().to_dict()  \n",
    "        w_count = counts.get('W', 0)  \n",
    "        t_count = counts.get('T', 0)  \n",
    "        l_count = counts.get('L', 0)  \n",
    "        result[column] = f'{w_count}:{t_count}:{l_count}'  \n",
    "  \n",
    "    return result  \n",
    "  \n",
    "def process_all_sheets(file_path, sheets):  \n",
    "    all_results = pd.DataFrame()  \n",
    "  \n",
    "    for sheet in sheets:  \n",
    "        sheet_result = process_sheet(file_path, sheet)  \n",
    "        sheet_df = pd.DataFrame(list(sheet_result.items()), columns=['Model', sheet])  \n",
    "        if all_results.empty:  \n",
    "            all_results = sheet_df  \n",
    "        else:  \n",
    "            all_results = pd.merge(all_results, sheet_df, on='Model', how='outer')  \n",
    "  \n",
    "    return all_results  \n",
    "  \n",
    "def process_wtl(wtl_str):  \n",
    "    w, t, l = map(int, wtl_str.split(':'))  \n",
    "    return w, t, l  \n",
    "  \n",
    "file_path = 'Label_2.xlsx'  \n",
    "sheets1 = ['Lingjie', 'Shaohanh', 'Label3_8B']  \n",
    "sheets2 = ['Lingjie-70B', 'shaohanh-70B', 'Label3-70B']  \n",
    "  \n",
    "results1 = process_all_sheets(file_path, sheets1)  \n",
    "results2 = process_all_sheets(file_path, sheets2)  \n",
    "  \n",
    "all_results = pd.merge(results1, results2, on='Model', how='outer')  \n",
    "  \n",
    "for index, row in all_results.iterrows():  \n",
    "    w_sum = t_sum = l_sum = 0  \n",
    "    for column in sheets1:  \n",
    "        w, t, l = process_wtl(row[column])  \n",
    "        w_sum += w  \n",
    "        t_sum += t  \n",
    "        l_sum += l  \n",
    "      \n",
    "    total_sum_1 = w_sum + t_sum + l_sum  \n",
    "    w1_avg = w_sum / total_sum_1 * 100 if total_sum_1 != 0 else 0  \n",
    "    t1_avg = t_sum / total_sum_1 * 100 if total_sum_1 != 0 else 0  \n",
    "    l1_avg = l_sum / total_sum_1 * 100 if total_sum_1 != 0 else 0  \n",
    "      \n",
    "    all_results.loc[index, 'group_1_sum'] = f'{w_sum}/{t_sum}/{l_sum}'  \n",
    "    all_results.loc[index, 'group_1_avg'] = f'{w1_avg:.1f}/{t1_avg:.1f}/{l1_avg:.1f}'  \n",
    "  \n",
    "    w_sum = t_sum = l_sum = 0  \n",
    "    for column in sheets2:  \n",
    "        w, t, l = process_wtl(row[column])  \n",
    "        w_sum += w  \n",
    "        t_sum += t  \n",
    "        l_sum += l  \n",
    "      \n",
    "    total_sum_2 = w_sum + t_sum + l_sum  \n",
    "    w2_avg = w_sum / total_sum_2 * 100 if total_sum_2 != 0 else 0  \n",
    "    t2_avg = t_sum / total_sum_2 * 100 if total_sum_2 != 0 else 0  \n",
    "    l2_avg = l_sum / total_sum_2 * 100 if total_sum_2 != 0 else 0  \n",
    "      \n",
    "    all_results.loc[index, 'group_2_sum'] = f'{w_sum}/{t_sum}/{l_sum}'  \n",
    "    all_results.loc[index, 'group_2_avg'] = f'{w2_avg:.1f}/{t2_avg:.1f}/{l2_avg:.1f}'  \n",
    "  \n",
    "all_results.to_csv('result_3_group_sum_avg.csv', index=False)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_717019/2014261800.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/2014261800.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/2014261800.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/2014261800.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/2014261800.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/2014261800.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "  \n",
    "def process_sheet(file_path, sheet_name):  \n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)  \n",
    "    df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)  \n",
    "    result = {}  \n",
    "  \n",
    "    for column in df.columns[1:]:  \n",
    "        counts = df[column].value_counts().to_dict()  \n",
    "        w_count = counts.get('W', 0)  \n",
    "        t_count = counts.get('T', 0)  \n",
    "        l_count = counts.get('L', 0)  \n",
    "        result[column] = f'{w_count}:{t_count}:{l_count}'  \n",
    "  \n",
    "    return result  \n",
    "  \n",
    "def process_all_sheets(file_path, sheets):  \n",
    "    all_results = pd.DataFrame()  \n",
    "  \n",
    "    for sheet in sheets:  \n",
    "        sheet_result = process_sheet(file_path, sheet)  \n",
    "        sheet_df = pd.DataFrame(list(sheet_result.items()), columns=['Model', sheet])  \n",
    "        if all_results.empty:  \n",
    "            all_results = sheet_df  \n",
    "        else:  \n",
    "            all_results = pd.merge(all_results, sheet_df, on='Model', how='outer')  \n",
    "  \n",
    "    return all_results  \n",
    "  \n",
    "def process_wtl(wtl_str):  \n",
    "    w, t, l = map(int, wtl_str.split(':'))  \n",
    "    return w, t, l  \n",
    "  \n",
    "file_path = 'Label_2.xlsx'  \n",
    "sheets1 = ['Lingjie', 'Shaohanh', 'Label3_8B']  \n",
    "sheets2 = ['Lingjie-70B', 'shaohanh-70B', 'Label3-70B']  \n",
    "  \n",
    "results1 = process_all_sheets(file_path, sheets1)  \n",
    "results2 = process_all_sheets(file_path, sheets2)  \n",
    "  \n",
    "all_results = pd.merge(results1, results2, on='Model', how='outer')  \n",
    "  \n",
    "average_results = []  \n",
    "  \n",
    "for index, row in all_results.iterrows():  \n",
    "    w_sum = t_sum = l_sum = 0  \n",
    "    for column in sheets1:  \n",
    "        w, t, l = process_wtl(row[column])  \n",
    "        w_sum += w  \n",
    "        t_sum += t  \n",
    "        l_sum += l  \n",
    "    w1_avg = w_sum / (w_sum + t_sum + l_sum) * 100\n",
    "    t1_avg = t_sum / (w_sum + t_sum + l_sum) * 100\n",
    "    l1_avg = l_sum / (w_sum + t_sum + l_sum) * 100\n",
    "    # w1_avg = w_sum / len(sheets1)  \n",
    "    # t1_avg = t_sum / len(sheets1)  \n",
    "    # l1_avg = l_sum / len(sheets1)  \n",
    "  \n",
    "    w_sum = t_sum = l_sum = 0  \n",
    "    for column in sheets2:  \n",
    "        w, t, l = process_wtl(row[column])  \n",
    "        w_sum += w  \n",
    "        t_sum += t  \n",
    "        l_sum += l  \n",
    "    w2_avg = w_sum / (w_sum + t_sum + l_sum) * 100\n",
    "    t2_avg = t_sum / (w_sum + t_sum + l_sum) * 100\n",
    "    l2_avg = l_sum / (w_sum + t_sum + l_sum) * 100\n",
    "    # w2_avg = w_sum / len(sheets2)  \n",
    "    # t2_avg = t_sum / len(sheets2)  \n",
    "    # l2_avg = l_sum / len(sheets2)  \n",
    "  \n",
    "    average_results.append({  \n",
    "        'Model': row['Model'],  \n",
    "        'w1': f'{w1_avg:.1f}',  \n",
    "        't1': f'{t1_avg:.1f}',  \n",
    "        'l1': f'{l1_avg:.1f}',  \n",
    "        'w2': f'{w2_avg:.1f}',  \n",
    "        't2': f'{t2_avg:.1f}',  \n",
    "        'l2': f'{l2_avg:.1f}'  \n",
    "    })  \n",
    "  \n",
    "average_results_df = pd.DataFrame(average_results)  \n",
    "average_results_df.to_csv('average_results4.csv', index=False)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_717019/3950137794.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/3950137794.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/3950137794.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/3950137794.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/3950137794.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/3950137794.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/3950137794.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/3950137794.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/3950137794.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/3950137794.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "  \n",
    "def process_sheet(file_path, sheet_name):  \n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)  \n",
    "    df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)  \n",
    "    result = {}  \n",
    "  \n",
    "    for column in df.columns[1:]:  \n",
    "        counts = df[column].value_counts().to_dict()  \n",
    "        w_count = counts.get('W', 0)  \n",
    "        t_count = counts.get('T', 0)  \n",
    "        l_count = counts.get('L', 0)  \n",
    "        result[column] = f'{w_count}:{t_count}:{l_count}'  \n",
    "  \n",
    "    return result  \n",
    "  \n",
    "def process_all_sheets(file_path, sheets):  \n",
    "    all_results = pd.DataFrame()  \n",
    "  \n",
    "    for sheet in sheets:  \n",
    "        sheet_result = process_sheet(file_path, sheet)  \n",
    "        sheet_df = pd.DataFrame(list(sheet_result.items()), columns=['Model', sheet])  \n",
    "        if all_results.empty:  \n",
    "            all_results = sheet_df  \n",
    "        else:  \n",
    "            all_results = pd.merge(all_results, sheet_df, on='Model', how='outer')  \n",
    "  \n",
    "    return all_results  \n",
    "  \n",
    "def process_wtl(wtl_str):  \n",
    "    w, t, l = map(int, wtl_str.split(':'))  \n",
    "    return w, t, l  \n",
    "  \n",
    "file_path = 'Label_4.xlsx'  \n",
    "sheets1 = ['Lingjie', 'Shaohanh', 'Label3_8B', \"gpt4_text\", \"gpt4_image\"]  \n",
    "sheets2 = ['Lingjie-70B', 'shaohanh-70B', 'Label3-70B',\"text_70B\", \"image_70B\"]  \n",
    "  \n",
    "results1 = process_all_sheets(file_path, sheets1)  \n",
    "results2 = process_all_sheets(file_path, sheets2)  \n",
    "  \n",
    "all_results = pd.merge(results1, results2, on='Model', how='outer')  \n",
    "  \n",
    "for index, row in all_results.iterrows():  \n",
    "    w_sum = t_sum = l_sum = 0  \n",
    "    for column in sheets1:  \n",
    "        w, t, l = process_wtl(row[column])  \n",
    "        w_sum += w  \n",
    "        t_sum += t  \n",
    "        l_sum += l  \n",
    "      \n",
    "    total_sum_1 = w_sum + t_sum + l_sum  \n",
    "    w1_avg = w_sum / total_sum_1 * 100 if total_sum_1 != 0 else 0  \n",
    "    t1_avg = t_sum / total_sum_1 * 100 if total_sum_1 != 0 else 0  \n",
    "    l1_avg = l_sum / total_sum_1 * 100 if total_sum_1 != 0 else 0  \n",
    "      \n",
    "    all_results.loc[index, 'group_1_sum'] = f'{w_sum}/{t_sum}/{l_sum}'  \n",
    "    all_results.loc[index, 'group_1_avg'] = f'{w1_avg:.1f}/{t1_avg:.1f}/{l1_avg:.1f}'  \n",
    "  \n",
    "    w_sum = t_sum = l_sum = 0  \n",
    "    for column in sheets2:  \n",
    "        w, t, l = process_wtl(row[column])  \n",
    "        w_sum += w  \n",
    "        t_sum += t  \n",
    "        l_sum += l  \n",
    "      \n",
    "    total_sum_2 = w_sum + t_sum + l_sum  \n",
    "    w2_avg = w_sum / total_sum_2 * 100 if total_sum_2 != 0 else 0  \n",
    "    t2_avg = t_sum / total_sum_2 * 100 if total_sum_2 != 0 else 0  \n",
    "    l2_avg = l_sum / total_sum_2 * 100 if total_sum_2 != 0 else 0  \n",
    "      \n",
    "    all_results.loc[index, 'group_2_sum'] = f'{w_sum}/{t_sum}/{l_sum}'  \n",
    "    all_results.loc[index, 'group_2_avg'] = f'{w2_avg:.1f}/{t2_avg:.1f}/{l2_avg:.1f}'  \n",
    "  \n",
    "all_results.to_csv('result_6_group_sum_avg.csv', index=False)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results have been written to agreement_result_5.csv\n",
      "Results have been written to agreement_result_6.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_717019/1212702476.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/1212702476.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/1212702476.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/1212702476.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/1212702476.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/1212702476.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/1212702476.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/1212702476.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/1212702476.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_717019/1212702476.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "  \n",
    "def process_sheet(file_path, sheet_name):    \n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)    \n",
    "    df = df.applymap(lambda x: str(x).upper() if isinstance(x, str) else x)  \n",
    "    return df    \n",
    "  \n",
    "def calculate_agreement(df1, df2):    \n",
    "    df1 = df1.set_index(df1.columns[0])    \n",
    "    df2 = df2.set_index(df2.columns[0])    \n",
    "        \n",
    "    agreements = {}    \n",
    "    for col in df1.columns:    \n",
    "        comparison = df1[col] == df2[col]    \n",
    "        agreements[col] = comparison.mean()  \n",
    "    return agreements    \n",
    "  \n",
    "# 文件路径    \n",
    "file_path = 'Label_4.xlsx'    \n",
    "  \n",
    "# 需要处理的工作表名称和输出文件名  \n",
    "sheets_and_output_files = [  \n",
    "    (['Lingjie', 'Shaohanh', 'Label3_8B', \"gpt4_text\", \"gpt4_image\"], 'agreement_result_5.csv'),  \n",
    "    (['Lingjie-70B', 'shaohanh-70B', 'Label3-70B',\"text_70B\", \"image_70B\"], 'agreement_result_6.csv')  \n",
    "]  \n",
    "  \n",
    "for sheets, output_file in sheets_and_output_files:  \n",
    "    # 读取所有的表    \n",
    "    dfs = {sheet: process_sheet(file_path, sheet) for sheet in sheets}    \n",
    "  \n",
    "    # 计算每对工作表的一致性    \n",
    "    results = {}    \n",
    "    for i, sheet1 in enumerate(sheets):    \n",
    "        for j, sheet2 in enumerate(sheets):    \n",
    "            if i < j:    \n",
    "                agreement = calculate_agreement(dfs[sheet1], dfs[sheet2])    \n",
    "                results[f'{sheet1} vs {sheet2}'] = agreement    \n",
    "  \n",
    "    # 将结果转换为DataFrame    \n",
    "    agreement_df = pd.DataFrame(results).T    \n",
    "  \n",
    "    # 计算每列的平均一致性    \n",
    "    agreement_df['Average'] = agreement_df.mean(axis=1)    \n",
    "  \n",
    "    # 将结果写入CSV文件    \n",
    "    agreement_df.to_csv(output_file)    \n",
    "  \n",
    "    print(f'Results have been written to {output_file}')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Unnamed: 0  Meta-Llama-3.1-8B-Instruct  \\\n",
      "0      Lingjie vs Shaohanh                        0.72   \n",
      "1     Lingjie vs Label3_8B                        0.70   \n",
      "2     Lingjie vs gpt4_text                        0.56   \n",
      "3    Lingjie vs gpt4_image                        0.62   \n",
      "4    Shaohanh vs Label3_8B                        0.74   \n",
      "5    Shaohanh vs gpt4_text                        0.58   \n",
      "6   Shaohanh vs gpt4_image                        0.52   \n",
      "7   Label3_8B vs gpt4_text                        0.64   \n",
      "8  Label3_8B vs gpt4_image                        0.64   \n",
      "9  gpt4_text vs gpt4_image                        0.62   \n",
      "\n",
      "   Meta-Llama-3.1-70B-Instruct  Qwen2-72B-Instruct  tulu-2-dpo-70b  Average  \n",
      "0                         0.66                0.76            0.88   0.7750  \n",
      "1                         0.74                0.84            0.92   0.8075  \n",
      "2                         0.50                0.68            0.80   0.6700  \n",
      "3                         0.70                0.60            0.74   0.6575  \n",
      "4                         0.68                0.76            0.92   0.7825  \n",
      "5                         0.60                0.64            0.84   0.6900  \n",
      "6                         0.58                0.56            0.78   0.6075  \n",
      "7                         0.48                0.82            0.88   0.7000  \n",
      "8                         0.68                0.70            0.78   0.6800  \n",
      "9                         0.56                0.70            0.78   0.6175  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "  \n",
    "# 读取CSV文件  \n",
    "file1 = 'agreement_result_5.csv'  \n",
    "file2 = 'agreement_result_6.csv'  \n",
    "  \n",
    "df1 = pd.read_csv(file1)  \n",
    "df2 = pd.read_csv(file2)  \n",
    "  \n",
    "# 提取最后一列  \n",
    "last_col1 = df1.iloc[:, -1]  \n",
    "last_col2 = df2.iloc[:, -1]  \n",
    "  \n",
    "# 计算对应行的平均值  \n",
    "average_col = (last_col1 + last_col2) / 2  \n",
    "  \n",
    "# 将结果放在第三列  \n",
    "df1['Average'] = average_col  \n",
    "  \n",
    "# 保存结果到新的CSV文件  \n",
    "df1.to_csv('agreement_result_with_average_3.csv', index=False)  \n",
    "  \n",
    "print(df1)  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
