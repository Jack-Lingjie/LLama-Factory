{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lidong1/miniconda3/envs/llama_factory/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'response'],\n",
       "    num_rows: 61135\n",
       "})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "import pandas as pd\n",
    "ds = load_dataset(\"HuggingFaceH4/ultrafeedback_binarized\", split=\"train_prefs\")\n",
    "def get_instruct_response(item):\n",
    "    # item[\"instruction\"] = item['chosen'][0][\"content\"]\n",
    "    item[\"response\"] = item['chosen'][1][\"content\"]\n",
    "    return item\n",
    "ds = ds.map(get_instruct_response, batch_size=1024, num_proc=8)\n",
    "export_data = ds.select_columns([\"prompt\", \"response\"])\n",
    "export_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_1 = export_data['response'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver  \n",
    "from selenium.webdriver.chrome.service import Service  \n",
    "from selenium.webdriver.chrome.options import Options  \n",
    "from PIL import Image  \n",
    "import os  \n",
    "import markdown  \n",
    "import logging  \n",
    "import time\n",
    "from io import BytesIO  \n",
    "\n",
    "# 配置日志  \n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')  \n",
    "  \n",
    "def markdown_to_html(markdown_text):  \n",
    "    \"\"\"Convert Markdown text to HTML\"\"\"  \n",
    "    html = markdown.markdown(markdown_text)  \n",
    "    return html  \n",
    "  \n",
    "def save_html_to_file(html_content, file_path):  \n",
    "    \"\"\"Save HTML content to a file\"\"\"  \n",
    "    with open(file_path, 'w', encoding='utf-8') as file:  \n",
    "        file.write(html_content)  \n",
    "\n",
    "def html_to_image(html_file, output_image):  \n",
    "    # Set Chrome options  \n",
    "    chrome_options = Options()  \n",
    "    chrome_options.add_argument(\"--headless\")  # Headless mode  \n",
    "    chrome_options.add_argument(\"--disable-gpu\")  \n",
    "    chrome_options.add_argument(\"--no-sandbox\")  \n",
    "      \n",
    "    # Set ChromeDriver service  \n",
    "    service = Service('/usr/local/bin/chromedriver')  # Path to ChromeDriver  \n",
    "      \n",
    "    # Start Chrome browser  \n",
    "    driver = webdriver.Chrome(service=service, options=chrome_options)  \n",
    "      \n",
    "    # Open HTML file  \n",
    "    file_url = f\"file://{os.path.abspath(html_file)}\"  \n",
    "    driver.get(file_url)  \n",
    "    time.sleep(2)  \n",
    "      \n",
    "    # Get the dimensions of the page  \n",
    "    total_width = driver.execute_script(\"return document.body.scrollWidth\")  \n",
    "    total_height = driver.execute_script(\"return document.body.scrollHeight\")  \n",
    "    viewport_height = driver.execute_script(\"return window.innerHeight\")  \n",
    "      \n",
    "    rectangles = []  \n",
    "      \n",
    "    # Split the screen in multiple parts  \n",
    "    for i in range(0, total_height, viewport_height):  \n",
    "        driver.execute_script(f\"window.scrollTo(0, {i});\")  \n",
    "        time.sleep(0.5)  \n",
    "        screenshot = driver.get_screenshot_as_png()  \n",
    "        screenshot = Image.open(BytesIO(screenshot))  \n",
    "        rectangles.append(screenshot)  \n",
    "      \n",
    "    # Combine images  \n",
    "    combined_image = Image.new('RGB', (total_width, total_height))  \n",
    "    for i, image in enumerate(rectangles):  \n",
    "        combined_image.paste(image, (0, i * viewport_height))  \n",
    "      \n",
    "    # Save the final image  \n",
    "    combined_image.save(output_image)  \n",
    "      \n",
    "    # Close browser  \n",
    "    driver.quit()  \n",
    "\n",
    "# def html_to_image(html_file, output_image):  \n",
    "#     # Set Chrome options  \n",
    "#     chrome_options = Options()  \n",
    "#     chrome_options.add_argument(\"--headless\")  # Headless mode  \n",
    "#     chrome_options.add_argument(\"--disable-gpu\")  \n",
    "#     chrome_options.add_argument(\"--no-sandbox\")  \n",
    "      \n",
    "#     # Set ChromeDriver service  \n",
    "#     service = Service('/usr/local/bin/chromedriver')  # Path to ChromeDriver  \n",
    "      \n",
    "#     # Start Chrome browser  \n",
    "#     driver = webdriver.Chrome(service=service, options=chrome_options)  \n",
    "      \n",
    "#     # Open HTML file  \n",
    "#     file_url = f\"file://{os.path.abspath(html_file)}\"  \n",
    "#     driver.get(file_url)  \n",
    "#     time.sleep(2)  \n",
    "      \n",
    "#     # Get the dimensions of the page  \n",
    "#     total_width = driver.execute_script(\"return document.body.scrollWidth\")  \n",
    "#     total_height = driver.execute_script(\"return document.body.scrollHeight\")  \n",
    "      \n",
    "#     # Set the window size to the dimensions of the page  \n",
    "#     driver.set_window_size(total_width, total_height)  \n",
    "#     time.sleep(2)  \n",
    "      \n",
    "#     # Take screenshot  \n",
    "#     screenshot = driver.get_screenshot_as_png()  \n",
    "      \n",
    "#     # Save image  \n",
    "#     with open(output_image, 'wb') as file:  \n",
    "#         file.write(screenshot)  \n",
    "      \n",
    "#     # Close browser  \n",
    "#     driver.quit()  \n",
    "      \n",
    "#     # Use PIL to adjust image size  \n",
    "#     with Image.open(output_image) as img:  \n",
    "#         img = img.crop(img.getbbox())  # Crop blank areas  \n",
    "#         img.save(output_image)  \n",
    "  \n",
    "  \n",
    "  \n",
    "def text_to_image(text, output_image):  \n",
    "    \"\"\"Convert text to image and log the process\"\"\"  \n",
    "    logging.info(\"Starting the conversion process.\")  \n",
    "      \n",
    "    # Convert text to Markdown (assume the text is in Markdown format)  \n",
    "    html_content = markdown_to_html(text)  \n",
    "      \n",
    "    # Wrap HTML header and style  \n",
    "    html_content = f\"\"\"  \n",
    "    <!DOCTYPE html>  \n",
    "    <html lang=\"en\">  \n",
    "    <head>  \n",
    "        <meta charset=\"UTF-8\">  \n",
    "        <title>Markdown to HTML Example</title>  \n",
    "        <style>  \n",
    "            body {{  \n",
    "                font-family: 'Arial', sans-serif;  \n",
    "            }}  \n",
    "        </style>  \n",
    "    </head>  \n",
    "    <body>  \n",
    "        {html_content}  \n",
    "    </body>  \n",
    "    </html>  \n",
    "    \"\"\"  \n",
    "      \n",
    "    # Get the directory of the current script  \n",
    "    # script_dir = os.path.dirname(os.path.abspath(__file__))  \n",
    "    script_dir = './'\n",
    "    # Save HTML to file  \n",
    "    html_file = os.path.join(script_dir, 'example.html')  \n",
    "    save_html_to_file(html_content, html_file)  \n",
    "    logging.info(f\"HTML content saved to {html_file}.\")  \n",
    "      \n",
    "    # Convert HTML to image  \n",
    "    output_image_path = os.path.join(script_dir, output_image)  \n",
    "    html_to_image(html_file, output_image_path)  \n",
    "    logging.info(f\"Image saved to {output_image_path}.\")  \n",
    "      \n",
    "    # Delete HTML file  \n",
    "    os.remove(html_file)  \n",
    "    logging.info(f\"Temporary HTML file {html_file} deleted.\")  \n",
    "      \n",
    "    logging.info(\"Conversion process completed successfully.\")  \n",
    "  \n",
    "markdown_text = \"\"\"  \n",
    "# Hello, World!  \n",
    "\n",
    "This is an example document written using **Markdown**.  \n",
    "\n",
    "- Item 1  \n",
    "- Item 2  \n",
    "- Item 3  \n",
    "\n",
    "[Click here](http://example.com) to visit the example website.  \n",
    "\"\"\" \n",
    "# if __name__ == \"__main__\":\n",
    "#     # 示例Markdown文本  \n",
    "  \n",
    "    \n",
    "#     # 调用函数并输出日志  \n",
    "#     output_image = 'output.png'  \n",
    "#     text_to_image(markdown_text, output_image)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0823/004648.007068:WARNING:sandbox_linux.cc(430)] InitializeSandbox() called with multiple threads in process gpu-process.\n",
      "[0823/004648.012217:WARNING:bluez_dbus_manager.cc(248)] Floss manager not present, cannot set Floss enable/disable.\n",
      "173264 bytes written to file /home/lidong1/jianglingjie/LLama-Factory/data_process/python_org.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/home/lidong1/jianglingjie/LLama-Factory/data_process/python_org.png']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from html2image import Html2Image\n",
    "hti = Html2Image(temp_path=\"/home/lidong1/jianglingjie/temp\")\n",
    "hti.screenshot(url='https://www.python.org', save_as='python_org.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0823/004655.789946:WARNING:bluez_dbus_manager.cc(248)] Floss manager not present, cannot set Floss enable/disable.\n",
      "[0823/004655.791542:WARNING:sandbox_linux.cc(430)] InitializeSandbox() called with multiple threads in process gpu-process.\n",
      "13187 bytes written to file /home/lidong1/jianglingjie/LLama-Factory/data_process/red_page.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/home/lidong1/jianglingjie/LLama-Factory/data_process/red_page.png']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = \"\"\"<h1> An interesting title </h1> This page will be red\"\"\"\n",
    "css = \"body {background: red;}\"\n",
    "\n",
    "hti.screenshot(html_str=html, css_str=css, save_as='red_page.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"response.txt\", 'w') as f:\n",
    "    f.write(response_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-23 00:15:53,993 - INFO - Starting the conversion process.\n",
      "2024-08-23 00:15:53,998 - INFO - HTML content saved to /home/lidong1/jianglingjie/LLama-Factory/data_process/example.html.\n",
      "2024-08-23 00:15:56,561 - INFO - Image saved to /home/lidong1/jianglingjie/LLama-Factory/data_process/text_images/output.png.\n",
      "2024-08-23 00:15:56,562 - INFO - Temporary HTML file /home/lidong1/jianglingjie/LLama-Factory/data_process/example.html deleted.\n",
      "2024-08-23 00:15:56,563 - INFO - Conversion process completed successfully.\n"
     ]
    }
   ],
   "source": [
    "from text2img import text_to_image\n",
    "output_path = \"text_images/output.png\"\n",
    "text = response_1\n",
    "text_to_image(text, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    ds = load_dataset(\"HuggingFaceH4/ultrafeedback_binarized\", split=\"train_prefs\")\n",
    "    def get_instruct_response(item):\n",
    "        # item[\"instruction\"] = item['chosen'][0][\"content\"]\n",
    "        item[\"response\"] = item['chosen'][1][\"content\"]\n",
    "        return item\n",
    "    ds = ds.map(get_instruct_response, batch_size=1024, num_proc=8)\n",
    "    export_data = ds.select_columns([\"prompt\", \"response\"])\n",
    "    return export_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = export_data['response'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'FreeTypeFont' object has no attribute 'getsize'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 35\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m textwrap\u001b[38;5;241m.\u001b[39mwrap(generated_text, width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m70\u001b[39m):  \n\u001b[1;32m     34\u001b[0m     draw\u001b[38;5;241m.\u001b[39mtext((margin, offset), line, font\u001b[38;5;241m=\u001b[39mfont, fill\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m))  \n\u001b[0;32m---> 35\u001b[0m     offset \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mfont\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetsize\u001b[49m(line)[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m5\u001b[39m  \n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# 保存图片  \u001b[39;00m\n\u001b[1;32m     38\u001b[0m image\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerated_text_image.png\u001b[39m\u001b[38;5;124m'\u001b[39m)  \n",
      "\u001b[0;31mAttributeError\u001b[0m: 'FreeTypeFont' object has no attribute 'getsize'"
     ]
    }
   ],
   "source": [
    "# # import openai  \n",
    "# from PIL import Image, ImageDraw, ImageFont  \n",
    "# import textwrap  \n",
    "  \n",
    "# # 设置OpenAI API密钥  \n",
    "# # openai.api_key = 'your_openai_api_key'  \n",
    "  \n",
    "# # # 调用GPT接口生成文本  \n",
    "# # response = openai.Completion.create(  \n",
    "# #     engine=\"text-davinci-003\",  \n",
    "# #     prompt=\"写一段关于人工智能的短文。\",  \n",
    "# #     max_tokens=150  \n",
    "# # )  \n",
    "# response = export_data['response'][0]\n",
    "# generated_text = response\n",
    "  \n",
    "# # 创建一个空白图片  \n",
    "# width, height = 800, 600  \n",
    "# image = Image.new('RGB', (width, height), color=(255, 255, 255))  \n",
    "  \n",
    "# # 设置字体和大小  \n",
    "# try:  \n",
    "#     font = ImageFont.truetype(\"arial.ttf\", 20)  \n",
    "# except IOError:  \n",
    "#     font = ImageFont.load_default()  \n",
    "  \n",
    "# # 创建绘图对象  \n",
    "# draw = ImageDraw.Draw(image)  \n",
    "  \n",
    "# # 设置文本换行  \n",
    "# margin = 40  \n",
    "# offset = 40  \n",
    "# for line in textwrap.wrap(generated_text, width=70):  \n",
    "#     draw.text((margin, offset), line, font=font, fill=(0, 0, 0))  \n",
    "#     offset += font.getsize(line)[1] + 5  \n",
    "  \n",
    "# # 保存图片  \n",
    "# image.save('generated_text_image.png')  \n",
    "# print(\"图片已保存为 'generated_text_image.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>这是一个标题</h1>\n",
      "<p>这是一些文本。  </p>\n",
      "<ul>\n",
      "<li>列表项 1  </li>\n",
      "<li>列表项 2  </li>\n",
      "<li>列表项 3  </li>\n",
      "</ul>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0822/201007.264298:WARNING:bluez_dbus_manager.cc(248)] Floss manager not present, cannot set Floss enable/disable.\n",
      "[0822/201007.268170:WARNING:sandbox_linux.cc(430)] InitializeSandbox() called with multiple threads in process gpu-process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "图片已生成并保存为 output.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8143 bytes written to file /home/lidong1/jianglingjie/LLama-Factory/data_process/output.png\n"
     ]
    }
   ],
   "source": [
    "import markdown  \n",
    "from html2image import Html2Image  \n",
    "  \n",
    "# Markdown 文本  \n",
    "markdown_text = \"\"\"  \n",
    "# 这是一个标题  \n",
    "  \n",
    "这是一些文本。  \n",
    "  \n",
    "- 列表项 1  \n",
    "- 列表项 2  \n",
    "- 列表项 3  \n",
    "\"\"\"  \n",
    "  \n",
    "# 将 Markdown 转换为 HTML  \n",
    "html = markdown.markdown(markdown_text)  \n",
    "print(html)\n",
    "# 创建 Html2Image 对象  \n",
    "hti = Html2Image()  \n",
    "  \n",
    "# 将 HTML 转换为图片  \n",
    "hti.screenshot(html_str=html, save_as='output.png')  \n",
    "  \n",
    "print(\"图片已生成并保存为 output.png\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import imgkit  \n",
    "# Markdown 文本  \n",
    "markdown_text = \"\"\"  \n",
    "# 这是一个标题  \n",
    "  \n",
    "这是一些文本。  \n",
    "  \n",
    "- 列表项 1  \n",
    "- 列表项 2  \n",
    "- 列表项 3  \n",
    "\"\"\"  \n",
    "  \n",
    "# 将 Markdown 转换为 HTML  \n",
    "html_string = markdown.markdown(markdown_text)    \n",
    "# html_string = '<html><body><h1>Hello World</h1></body></html>'  \n",
    "with open(\"temp.html\", 'w', encoding='utf-8') as f:\n",
    "    f.write(html_string)\n",
    "    \n",
    "output_image = 'output_from_string.png'  \n",
    "options = {  \n",
    "    'encoding': \"UTF-8\",  \n",
    "    'custom-header': [  \n",
    "        ('Accept-Encoding', 'gzip')  \n",
    "    ],  \n",
    "    'quiet': ''  \n",
    "}  \n",
    "imgkit.from_file(\"temp.html\", output_image, options=options)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import markdown  \n",
    "import imgkit  \n",
    "  \n",
    "def markdown_to_html(markdown_text):  \n",
    "    \"\"\"将Markdown文本转换为HTML\"\"\"  \n",
    "    html = markdown.markdown(markdown_text)  \n",
    "    return html  \n",
    "  \n",
    "def save_html_to_file(html_content, file_path):  \n",
    "    \"\"\"将HTML内容保存到文件\"\"\"  \n",
    "    with open(file_path, 'w', encoding='utf-8') as file:  \n",
    "        file.write(html_content)  \n",
    "  \n",
    "def html_to_image(html_file, output_image):  \n",
    "    \"\"\"将HTML文件转换为图片\"\"\"  \n",
    "    options = {  \n",
    "        'encoding': 'UTF-8',  \n",
    "        'custom-header': [  \n",
    "            ('Accept-Encoding', 'gzip')  \n",
    "        ],  \n",
    "        'quiet': ''  \n",
    "    }  \n",
    "    imgkit.from_file(html_file, output_image, options=options)  \n",
    "  \n",
    "# 示例Markdown文本  \n",
    "markdown_text = \"\"\"  \n",
    "# 你好，世界！  \n",
    "  \n",
    "这是一个使用 **Markdown** 编写的示例文档。  \n",
    "  \n",
    "- 项目1  \n",
    "- 项目2  \n",
    "- 项目3  \n",
    "  \n",
    "[点击这里](http://example.com) 访问示例网站。  \n",
    "\"\"\"  \n",
    "  \n",
    "# 将Markdown转换为HTML  \n",
    "html_content = markdown_to_html(markdown_text)  \n",
    "  \n",
    "# 包装HTML头部和样式  \n",
    "html_content = f\"\"\"  \n",
    "<!DOCTYPE html>  \n",
    "<html lang=\"zh-CN\">  \n",
    "<head>  \n",
    "    <meta charset=\"UTF-8\">  \n",
    "    <title>Markdown 转 HTML 示例</title>  \n",
    "    <style>  \n",
    "        body {{  \n",
    "            font-family: 'WenQuanYi Zen Hei', 'Arial', sans-serif;  \n",
    "        }}  \n",
    "    </style>  \n",
    "</head>  \n",
    "<body>  \n",
    "    {html_content}  \n",
    "</body>  \n",
    "</html>  \n",
    "\"\"\"  \n",
    "  \n",
    "# 保存HTML到文件  \n",
    "html_file = 'example.html'  \n",
    "save_html_to_file(html_content, html_file)  \n",
    "  \n",
    "# 将HTML转换为图片  \n",
    "output_image = 'output.png'  \n",
    "html_to_image(html_file, output_image)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver  \n",
    "from selenium.webdriver.chrome.service import Service  \n",
    "from selenium.webdriver.chrome.options import Options  \n",
    "from PIL import Image  \n",
    "import markdown  \n",
    "import os  \n",
    "\n",
    "def markdown_to_html(markdown_text):  \n",
    "    \"\"\"将Markdown文本转换为HTML\"\"\"  \n",
    "    html = markdown.markdown(markdown_text)  \n",
    "    return html  \n",
    "  \n",
    "def save_html_to_file(html_content, file_path):  \n",
    "    \"\"\"将HTML内容保存到文件\"\"\"  \n",
    "    with open(file_path, 'w', encoding='utf-8') as file:  \n",
    "        file.write(html_content)  \n",
    "\n",
    "def html_to_image(html_file, output_image):  \n",
    "    # 设置Chrome选项  \n",
    "    chrome_options = Options()  \n",
    "    chrome_options.add_argument(\"--headless\")  # 无头模式  \n",
    "    chrome_options.add_argument(\"--disable-gpu\")  \n",
    "    chrome_options.add_argument(\"--window-size=1920x1080\")  \n",
    "    chrome_options.add_argument(\"--no-sandbox\")  \n",
    "      \n",
    "    # 设置ChromeDriver服务  \n",
    "    service = Service('/usr/local/bin/chromedriver')  # ChromeDriver的路径  \n",
    "      \n",
    "    # 启动Chrome浏览器  \n",
    "    driver = webdriver.Chrome(service=service, options=chrome_options)  \n",
    "      \n",
    "    # 打开HTML文件  \n",
    "    file_url = f\"file://{os.path.abspath(html_file)}\"  \n",
    "    driver.get(file_url)  \n",
    "      \n",
    "    # 截图  \n",
    "    screenshot = driver.get_screenshot_as_png()  \n",
    "      \n",
    "    # 保存图片  \n",
    "    with open(output_image, 'wb') as file:  \n",
    "        file.write(screenshot)  \n",
    "      \n",
    "    # 关闭浏览器  \n",
    "    driver.quit()  \n",
    "  \n",
    "    # 使用PIL调整图片大小  \n",
    "    with Image.open(output_image) as img:  \n",
    "        img = img.crop(img.getbbox())  # 剪裁空白区域  \n",
    "        img.save(output_image)  \n",
    "\n",
    "# 示例Markdown文本  \n",
    "markdown_text = \"\"\"  \n",
    "# 你好，世界！  \n",
    "  \n",
    "这是一个使用 **Markdown** 编写的示例文档。  \n",
    "  \n",
    "- 项目1  \n",
    "- 项目2  \n",
    "- 项目3  \n",
    "  \n",
    "[点击这里](http://example.com) 访问示例网站。  \n",
    "\"\"\"  \n",
    "  \n",
    "# 将Markdown转换为HTML  \n",
    "html_content = markdown_to_html(markdown_text)  \n",
    "  \n",
    "# 包装HTML头部和样式  \n",
    "html_content = f\"\"\"  \n",
    "<!DOCTYPE html>  \n",
    "<html lang=\"zh-CN\">  \n",
    "<head>  \n",
    "    <meta charset=\"UTF-8\">  \n",
    "    <title>Markdown 转 HTML 示例</title>  \n",
    "    <style>  \n",
    "        body {{  \n",
    "            font-family: 'WenQuanYi Zen Hei', 'Arial', sans-serif;  \n",
    "        }}  \n",
    "    </style>  \n",
    "</head>  \n",
    "<body>  \n",
    "    {html_content}  \n",
    "</body>  \n",
    "</html>  \n",
    "\"\"\"  \n",
    "  \n",
    "# 保存HTML到文件  \n",
    "html_file = 'example.html'  \n",
    "save_html_to_file(html_content, html_file)  \n",
    "  \n",
    "# 将HTML转换为图片  \n",
    "output_image = 'output.png'  \n",
    "html_to_image(html_file, output_image)    \n",
    "\n",
    "# # 使用示例  \n",
    "# html_file = 'example.html'  \n",
    "# output_image = 'output.png'  \n",
    "html_to_image(html_file, output_image)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'markdown' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 64\u001b[0m\n\u001b[1;32m     51\u001b[0m markdown_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124m  \u001b[39m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;124m# 你好，世界！  \u001b[39m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;124m  \u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;124m[点击这里](http://example.com) 访问示例网站。  \u001b[39m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m  \n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# 将Markdown转换为HTML  \u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m html_content \u001b[38;5;241m=\u001b[39m \u001b[43mmarkdown_to_html\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmarkdown_text\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# 包装HTML头部和样式  \u001b[39;00m\n\u001b[1;32m     67\u001b[0m html_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124m  \u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;124m<!DOCTYPE html>  \u001b[39m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;124m<html lang=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzh-CN\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m>  \u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;124m</html>  \u001b[39m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m  \n",
      "Cell \u001b[0;32mIn[1], line 9\u001b[0m, in \u001b[0;36mmarkdown_to_html\u001b[0;34m(markdown_text)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmarkdown_to_html\u001b[39m(markdown_text):  \n\u001b[1;32m      8\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"将Markdown文本转换为HTML\"\"\"\u001b[39;00m  \n\u001b[0;32m----> 9\u001b[0m     html \u001b[38;5;241m=\u001b[39m \u001b[43mmarkdown\u001b[49m\u001b[38;5;241m.\u001b[39mmarkdown(markdown_text)  \n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m html\n",
      "\u001b[0;31mNameError\u001b[0m: name 'markdown' is not defined"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver  \n",
    "from selenium.webdriver.chrome.service import Service  \n",
    "from selenium.webdriver.chrome.options import Options  \n",
    "from PIL import Image  \n",
    "\n",
    "import os  \n",
    "\n",
    "def markdown_to_html(markdown_text):  \n",
    "    \"\"\"将Markdown文本转换为HTML\"\"\"  \n",
    "    html = markdown.markdown(markdown_text)  \n",
    "    return html  \n",
    "  \n",
    "def save_html_to_file(html_content, file_path):  \n",
    "    \"\"\"将HTML内容保存到文件\"\"\"  \n",
    "    with open(file_path, 'w', encoding='utf-8') as file:  \n",
    "        file.write(html_content)  \n",
    "\n",
    "def html_to_image(html_file, output_image):  \n",
    "    # 设置Chrome选项  \n",
    "    chrome_options = Options()  \n",
    "    chrome_options.add_argument(\"--headless\")  # 无头模式  \n",
    "    chrome_options.add_argument(\"--disable-gpu\")  \n",
    "    chrome_options.add_argument(\"--window-size=1920x1080\")  \n",
    "    chrome_options.add_argument(\"--no-sandbox\")  \n",
    "      \n",
    "    # 设置ChromeDriver服务  \n",
    "    service = Service('/usr/local/bin/chromedriver')  # ChromeDriver的路径  \n",
    "      \n",
    "    # 启动Chrome浏览器  \n",
    "    driver = webdriver.Chrome(service=service, options=chrome_options)  \n",
    "      \n",
    "    # 打开HTML文件  \n",
    "    file_url = f\"file://{os.path.abspath(html_file)}\"  \n",
    "    driver.get(file_url)  \n",
    "      \n",
    "    # 截图  \n",
    "    screenshot = driver.get_screenshot_as_png()  \n",
    "      \n",
    "    # 保存图片  \n",
    "    with open(output_image, 'wb') as file:  \n",
    "        file.write(screenshot)  \n",
    "      \n",
    "    # 关闭浏览器  \n",
    "    driver.quit()  \n",
    "  \n",
    "    # 使用PIL调整图片大小  \n",
    "    with Image.open(output_image) as img:  \n",
    "        img = img.crop(img.getbbox())  # 剪裁空白区域  \n",
    "        img.save(output_image)  \n",
    "\n",
    "# 示例Markdown文本  \n",
    "markdown_text = \"\"\"  \n",
    "# 你好，世界！  \n",
    "  \n",
    "这是一个使用 **Markdown** 编写的示例文档。  \n",
    "  \n",
    "- 项目1  \n",
    "- 项目2  \n",
    "- 项目3  \n",
    "  \n",
    "[点击这里](http://example.com) 访问示例网站。  \n",
    "\"\"\"  \n",
    "  \n",
    "# 将Markdown转换为HTML  \n",
    "html_content = markdown_to_html(markdown_text)  \n",
    "  \n",
    "# 包装HTML头部和样式  \n",
    "html_content = f\"\"\"  \n",
    "<!DOCTYPE html>  \n",
    "<html lang=\"zh-CN\">  \n",
    "<head>  \n",
    "    <meta charset=\"UTF-8\">  \n",
    "    <title>Markdown 转 HTML 示例</title>  \n",
    "    <style>  \n",
    "        body {{  \n",
    "            font-family: 'WenQuanYi Zen Hei', 'Arial', sans-serif;  \n",
    "        }}  \n",
    "    </style>  \n",
    "</head>  \n",
    "<body>  \n",
    "    {html_content}  \n",
    "</body>  \n",
    "</html>  \n",
    "\"\"\"  \n",
    "  \n",
    "# 保存HTML到文件  \n",
    "html_file = 'example.html'  \n",
    "save_html_to_file(html_content, html_file)  \n",
    "  \n",
    "# 将HTML转换为图片  \n",
    "output_image = 'output.png'  \n",
    "html_to_image(html_file, output_image)    \n",
    "\n",
    "# # 使用示例  \n",
    "# html_file = 'example.html'  \n",
    "# output_image = 'output.png'  \n",
    "html_to_image(html_file, output_image)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-22 21:55:36,539 - INFO - Starting the conversion process.\n",
      "2024-08-22 21:55:37,117 - INFO - Image saved to output.png.\n",
      "2024-08-22 21:55:37,118 - INFO - Conversion process completed successfully.\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver  \n",
    "from selenium.webdriver.chrome.service import Service  \n",
    "from selenium.webdriver.chrome.options import Options  \n",
    "from PIL import Image  \n",
    "import os  \n",
    "import markdown  \n",
    "import logging  \n",
    "  \n",
    "# 配置日志  \n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')  \n",
    "  \n",
    "def markdown_to_html(markdown_text):  \n",
    "    \"\"\"Convert Markdown text to HTML\"\"\"  \n",
    "    html = markdown.markdown(markdown_text)  \n",
    "    return html  \n",
    "  \n",
    "def save_html_to_file(html_content, file_path):  \n",
    "    \"\"\"Save HTML content to a file\"\"\"  \n",
    "    with open(file_path, 'w', encoding='utf-8') as file:  \n",
    "        file.write(html_content)  \n",
    "  \n",
    "def html_to_image(html_file, output_image):  \n",
    "    # Set Chrome options  \n",
    "    chrome_options = Options()  \n",
    "    chrome_options.add_argument(\"--headless\")  # Headless mode  \n",
    "    chrome_options.add_argument(\"--disable-gpu\")  \n",
    "    chrome_options.add_argument(\"--window-size=1920x1080\")  \n",
    "    chrome_options.add_argument(\"--no-sandbox\")  \n",
    "      \n",
    "    # Set ChromeDriver service  \n",
    "    service = Service('/usr/local/bin/chromedriver')  # Path to ChromeDriver  \n",
    "      \n",
    "    # Start Chrome browser  \n",
    "    driver = webdriver.Chrome(service=service, options=chrome_options)  \n",
    "      \n",
    "    # Open HTML file  \n",
    "    file_url = f\"file://{os.path.abspath(html_file)}\"  \n",
    "    driver.get(file_url)  \n",
    "      \n",
    "    # Take screenshot  \n",
    "    screenshot = driver.get_screenshot_as_png()  \n",
    "      \n",
    "    # Save image  \n",
    "    with open(output_image, 'wb') as file:  \n",
    "        file.write(screenshot)  \n",
    "      \n",
    "    # Close browser  \n",
    "    driver.quit()  \n",
    "      \n",
    "    # Use PIL to adjust image size  \n",
    "    with Image.open(output_image) as img:  \n",
    "        img = img.crop(img.getbbox())  # Crop blank areas  \n",
    "        img.save(output_image)  \n",
    "  \n",
    "def text_to_image_with_log(text, output_image):  \n",
    "    \"\"\"  \n",
    "    Convert text to image and log the process  \n",
    "    \"\"\"  \n",
    "    logging.info(\"Starting the conversion process.\")  \n",
    "      \n",
    "    # Convert text to Markdown (assume the text is in Markdown format)  \n",
    "    html_content = markdown_to_html(text)  \n",
    "      \n",
    "    # Wrap HTML header and style  \n",
    "    html_content = f\"\"\"  \n",
    "    <!DOCTYPE html>  \n",
    "    <html lang=\"en\">  \n",
    "    <head>  \n",
    "        <meta charset=\"UTF-8\">  \n",
    "        <title>Markdown to HTML Example</title>  \n",
    "        <style>  \n",
    "            body {{  \n",
    "                font-family: 'Arial', sans-serif;  \n",
    "            }}  \n",
    "        </style>  \n",
    "    </head>  \n",
    "    <body>  \n",
    "        {html_content}  \n",
    "    </body>  \n",
    "    </html>  \n",
    "    \"\"\"  \n",
    "      \n",
    "    # Save HTML to file  \n",
    "    html_file = 'example.html'  \n",
    "    save_html_to_file(html_content, html_file)  \n",
    "    # logging.info(f\"HTML content saved to {html_file}.\")  \n",
    "      \n",
    "    # Convert HTML to image  \n",
    "    html_to_image(html_file, output_image)  \n",
    "    logging.info(f\"Image saved to {output_image}.\")  \n",
    "      \n",
    "    # Delete HTML file  \n",
    "    os.remove(html_file)  \n",
    "    # logging.info(f\"Temporary HTML file {html_file} deleted.\")  \n",
    "      \n",
    "    logging.info(\"Conversion process completed successfully.\")  \n",
    "  \n",
    "# 示例Markdown文本  \n",
    "markdown_text = \"\"\"  \n",
    "# Hello, World!  \n",
    "  \n",
    "This is an example document written using **Markdown**.  \n",
    "  \n",
    "- Item 1  \n",
    "- Item 2  \n",
    "- Item 3  \n",
    "  \n",
    "[Click here](http://example.com) to visit the example website.  \n",
    "\"\"\"  \n",
    "  \n",
    "# 调用函数并输出日志  \n",
    "output_image = 'output.png'  \n",
    "text_to_image_with_log(markdown_text, output_image)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-22 21:56:02,605 - INFO - Starting the conversion process.\n",
      "2024-08-22 21:56:02,608 - INFO - HTML content saved to example.html.\n",
      "2024-08-22 21:56:03,165 - INFO - Image saved to output.png.\n",
      "2024-08-22 21:56:03,166 - INFO - Temporary HTML file example.html deleted.\n",
      "2024-08-22 21:56:03,167 - INFO - Conversion process completed successfully.\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver  \n",
    "from selenium.webdriver.chrome.service import Service  \n",
    "from selenium.webdriver.chrome.options import Options  \n",
    "from PIL import Image  \n",
    "import os  \n",
    "import markdown  \n",
    "import logging  \n",
    "  \n",
    "# 配置日志  \n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')  \n",
    "  \n",
    "def markdown_to_html(markdown_text):  \n",
    "    \"\"\"Convert Markdown text to HTML\"\"\"  \n",
    "    html = markdown.markdown(markdown_text)  \n",
    "    return html  \n",
    "  \n",
    "def save_html_to_file(html_content, file_path):  \n",
    "    \"\"\"Save HTML content to a file\"\"\"  \n",
    "    with open(file_path, 'w', encoding='utf-8') as file:  \n",
    "        file.write(html_content)  \n",
    "  \n",
    "def html_to_image(html_file, output_image):  \n",
    "    # Set Chrome options  \n",
    "    chrome_options = Options()  \n",
    "    chrome_options.add_argument(\"--headless\")  # Headless mode  \n",
    "    chrome_options.add_argument(\"--disable-gpu\")  \n",
    "    chrome_options.add_argument(\"--window-size=1920x1080\")  \n",
    "    chrome_options.add_argument(\"--no-sandbox\")  \n",
    "      \n",
    "    # Set ChromeDriver service  \n",
    "    service = Service('/usr/local/bin/chromedriver')  # Path to ChromeDriver  \n",
    "      \n",
    "    # Start Chrome browser  \n",
    "    driver = webdriver.Chrome(service=service, options=chrome_options)  \n",
    "      \n",
    "    # Open HTML file  \n",
    "    file_url = f\"file://{os.path.abspath(html_file)}\"  \n",
    "    driver.get(file_url)  \n",
    "      \n",
    "    # Take screenshot  \n",
    "    screenshot = driver.get_screenshot_as_png()  \n",
    "      \n",
    "    # Save image  \n",
    "    with open(output_image, 'wb') as file:  \n",
    "        file.write(screenshot)  \n",
    "      \n",
    "    # Close browser  \n",
    "    driver.quit()  \n",
    "      \n",
    "    # Use PIL to adjust image size  \n",
    "    with Image.open(output_image) as img:  \n",
    "        img = img.crop(img.getbbox())  # Crop blank areas  \n",
    "        img.save(output_image)  \n",
    "  \n",
    "def text_to_image_with_log(text, output_image):  \n",
    "    \"\"\"  \n",
    "    Convert text to image and log the process  \n",
    "    \"\"\"  \n",
    "    logging.info(\"Starting the conversion process.\")  \n",
    "      \n",
    "    # Convert text to Markdown (assume the text is in Markdown format)  \n",
    "    html_content = markdown_to_html(text)  \n",
    "      \n",
    "    # Wrap HTML header and style  \n",
    "    html_content = f\"\"\"  \n",
    "    <!DOCTYPE html>  \n",
    "    <html lang=\"en\">  \n",
    "    <head>  \n",
    "        <meta charset=\"UTF-8\">  \n",
    "        <title>Markdown to HTML Example</title>  \n",
    "        <style>  \n",
    "            body {{  \n",
    "                font-family: 'Arial', sans-serif;  \n",
    "            }}  \n",
    "        </style>  \n",
    "    </head>  \n",
    "    <body>  \n",
    "        {html_content}  \n",
    "    </body>  \n",
    "    </html>  \n",
    "    \"\"\"  \n",
    "      \n",
    "    # Save HTML to file  \n",
    "    html_file = 'example.html'  \n",
    "    save_html_to_file(html_content, html_file)  \n",
    "    logging.info(f\"HTML content saved to {html_file}.\")  \n",
    "      \n",
    "    # Convert HTML to image  \n",
    "    html_to_image(html_file, output_image)  \n",
    "    logging.info(f\"Image saved to {output_image}.\")  \n",
    "      \n",
    "    # Delete HTML file  \n",
    "    os.remove(html_file)  \n",
    "    logging.info(f\"Temporary HTML file {html_file} deleted.\")  \n",
    "      \n",
    "    logging.info(\"Conversion process completed successfully.\")  \n",
    "  \n",
    "# 示例Markdown文本  \n",
    "markdown_text = \"\"\"  \n",
    "# Hello, World!  \n",
    "  \n",
    "This is an example document written using **Markdown**.  \n",
    "  \n",
    "- Item 1  \n",
    "- Item 2  \n",
    "- Item 3  \n",
    "  \n",
    "[Click here](http://example.com) to visit the example website.  \n",
    "\"\"\"  \n",
    "  \n",
    "# 调用函数并输出日志  \n",
    "output_image = 'output.png'  \n",
    "text_to_image_with_log(markdown_text, output_image)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'response'],\n",
       "    num_rows: 61135\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_instruct_response(item):\n",
    "    # item[\"instruction\"] = item['chosen'][0][\"content\"]\n",
    "    item[\"response\"] = item['chosen'][1][\"content\"]\n",
    "    return item\n",
    "ds = ds.map(get_instruct_response, batch_size=1024, num_proc=8)\n",
    "export_data = ds.select_columns([\"prompt\", \"response\"])\n",
    "export_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是GPT-2.5，一个帮助用户回答问题和提供信息的聊天助手。有什么我可以帮你的吗？\n"
     ]
    }
   ],
   "source": [
    "from gpt4o import Openai, API_INFOS\n",
    "client = Openai(apis=API_INFOS)\n",
    "ans = client.get_response(\"你是gpt几？\", system=\"you are gpt2.5, a helpful chat assisstant\")\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我需要写一个prompt，让gpt帮我将LLM对于给定instruction生成的文本在文本美学方面进行修改的prompt，以下是我写的一个中文的system_template，对于这个template，如何让gpt更好的完成我的任务，给出修改意见和修改后的英语的system_template\n",
    "system_template = \\\n",
    "\"\"\"请扮演一个文本改写者来改写LLM(Large Language Model)生成的文本，使其更具有文本美学。你的任务是对于提供的用户instruction和一个LLM生成的答案，你从文本美学的角度去思考这个答案是否合理，是否需要修改,然后给出修改的文本。\n",
    "*Format*\n",
    "文本美学分析:\n",
    "[文本美学分析]\n",
    "是否需要修改:[Y/N]\n",
    "修改后的文本：\n",
    "[修改后的文本]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我需要写一个prompt，让gpt帮我将LLM对于给定instruction生成的文本在文本美学方面进行修改的prompt,主要从文本的排版和布局上对文本美观程度进行优化，例如段落长短、缩进、标题、列表、markdown形式的加粗、斜体、代码块，这些需要根据文本类型的需要来适当的修改，也可以添加一些其他方面的对文本美学的要求。帮我给出一些在观感上文本美学的构成要素，融入到prompt中。以下是我写的一个system template 和user template，对于这个template，如何让gpt更好的完成我的任务，给出修改意见和修改后的英语的template\n",
    "system_template = \\\n",
    "\"\"\"You are tasked with acting as a text rewriter to enhance the aesthetic quality of text generated by a Large Language Model (LLM). Your job is to evaluate the provided user instruction and the LLM-generated response from an aesthetic perspective, determine whether the text needs modification, and then provide the revised text if necessary.   \n",
    "    \n",
    "*Format*  \n",
    "Textual Aesthetic Analysis: [Your analysis]  \n",
    "Does it need modification: [Y/N]  \n",
    "Revised Text: [Your revised text, if applicable]  \n",
    "\"\"\"  \n",
    "user_template = \\\n",
    "\"\"\"### User Instruction:\n",
    "{instruction}\n",
    "\n",
    "### Answer\n",
    "{completition}\n",
    "\n",
    "Your task is to:  \n",
    "1. Analyze the LLM-generated response from a textual aesthetic perspective.  \n",
    "2. Determine whether the text needs modification.  \n",
    "3. Provide a revised version of the text if necessary.  \n",
    "   \n",
    "*Format*  \n",
    "Textual Aesthetic Analysis: [Your analysis]  \n",
    "Does it need modification: [Y/N]  \n",
    "Revised Text: [Your revised text, if applicable] \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = \\\n",
    "\"\"\"You are tasked with acting as a text rewriter to enhance the aesthetic quality of text generated by a Large Language Model (LLM). Your job is to evaluate the provided user instruction and the LLM-generated response from an aesthetic perspective, determine whether the text needs modification, and then provide the revised text if necessary.   \n",
    "  \n",
    "Consider the following aspects of textual aesthetics:  \n",
    "- **Fluency**: Is the text smooth and easy to read?  \n",
    "- **Vocabulary**: Are the words used varied and appropriate?  \n",
    "- **Sentence Structure**: Are the sentences well-constructed and rhythmically balanced?  \n",
    "- **Imagery and Tone**: Does the text evoke vivid images and maintain a consistent tone?  \n",
    "  \n",
    "*Format*  \n",
    "Textual Aesthetic Analysis: [Your analysis]  \n",
    "Does it need modification: [Y/N]  \n",
    "Revised Text: [Your revised text, if applicable]  \n",
    "\"\"\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_template = \\\n",
    "\"\"\"### User Instruction:\n",
    "{instruction}\n",
    "\n",
    "### Answer\n",
    "{completition}\n",
    "\n",
    "Your task is to:  \n",
    "1. Analyze the LLM-generated response from a textual aesthetic perspective.  \n",
    "2. Determine whether the text needs modification.  \n",
    "3. Provide a revised version of the text if necessary.  \n",
    "  \n",
    "Consider the following aspects of textual aesthetics:  \n",
    "- **Fluency**: Is the text smooth and easy to read?  \n",
    "- **Vocabulary**: Are the words used varied and appropriate?  \n",
    "- **Sentence Structure**: Are the sentences well-constructed and rhythmically balanced?  \n",
    "- **Imagery and Tone**: Does the text evoke vivid images and maintain a consistent tone?  \n",
    "  \n",
    "*Format*  \n",
    "Textual Aesthetic Analysis: [Your analysis]  \n",
    "Does it need modification: [Y/N]  \n",
    "Revised Text: [Your revised text, if applicable] \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template= \\\n",
    "\"\"\"You are tasked with acting as a text rewriter to enhance the aesthetic quality of text generated by a Large Language Model (LLM). Your job is to evaluate the provided user instruction and the LLM-generated response from an aesthetic perspective, determine whether the text needs modification, and then provide the revised text if necessary.  \n",
    "  \n",
    "*Format*   \n",
    "  \n",
    "Textual Aesthetic Analysis:\n",
    "[Your analysis]\n",
    "\n",
    "Does it need modification:\n",
    "[Y/N]\n",
    "\n",
    "Revised Text:\n",
    "[Your revised text, if applicable]   \n",
    "  \n",
    "*Textual Aesthetic Elements to Consider*:  \n",
    "  \n",
    "1. **Paragraph Structure**: Ensure paragraphs are of appropriate length and logically structured.  \n",
    "2. **Indentation**: Apply consistent indentation where necessary.  \n",
    "3. **Headings and Subheadings**: Use headings and subheadings to organize content and improve readability.  \n",
    "4. **Lists and Bullet Points**: Utilize lists and bullet points to break down complex information.  \n",
    "5. **Markdown Formatting**: Apply markdown for bold, italic, and code blocks to highlight important information or distinguish between different types of text.  \n",
    "6. **Line Spacing**: Adjust line spacing to enhance readability.  \n",
    "7. **Consistency**: Maintain a consistent style throughout the document.  \n",
    "8. **Visual Breaks**: Use visual breaks to separate different sections and improve flow.  \n",
    "\"\"\"\n",
    "user_template = \\\n",
    "\"\"\"### User Instruction:  \n",
    "{instruction}  \n",
    "  \n",
    "### Answer:  \n",
    "{completion}  \n",
    "  \n",
    "Your task is to:  \n",
    "  \n",
    "1. Analyze the LLM-generated response from a textual aesthetic perspective.  \n",
    "2. Determine whether the text needs modification.  \n",
    "3. Provide a revised version of the text if necessary.  \n",
    "  \n",
    "*Format*   \n",
    "  \n",
    "Textual Aesthetic Analysis:\n",
    "[Your analysis]\n",
    "\n",
    "Does it need modification:\n",
    "[Y/N]\n",
    "\n",
    "Revised Text:\n",
    "[Your revised text, if applicable]\n",
    "  \n",
    "*Textual Aesthetic Elements to Consider*:  \n",
    "  \n",
    "1. **Paragraph Structure**: Ensure paragraphs are of appropriate length and logically structured.  \n",
    "2. **Indentation**: Apply consistent indentation where necessary.  \n",
    "3. **Headings and Subheadings**: Use headings and subheadings to organize content and improve readability.  \n",
    "4. **Lists and Bullet Points**: Utilize lists and bullet points to break down complex information.  \n",
    "5. **Markdown Formatting**: Apply markdown for bold, italic, and code blocks to highlight important information or distinguish between different types of text.  \n",
    "6. **Line Spacing**: Adjust line spacing to enhance readability.  \n",
    "7. **Consistency**: Maintain a consistent style throughout the document.  \n",
    "8. **Visual Breaks**: Use visual breaks to separate different sections and improve flow.  \n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt4o import Openai, API_INFOS\n",
    "client = Openai(apis=API_INFOS)\n",
    "# ans = client.get_response(\"你是gpt几？\", system=\"you are gpt2.5, a helpful chat assisstant\")\n",
    "# print(ans)\n",
    "def get_revised_text(client, instruction, completion, user_template, system_template, max_tokens=2048):\n",
    "    content = user_template.format(instruction=instruction, completion=completion)\n",
    "    gpt_answer = client.get_response(content=content, system=system_template, max_tokens=max_tokens)\n",
    "    gpt_answer = gpt_answer.strip()\n",
    "    need_modification = \"Y\" if \"Does it need modification: Y\" in gpt_answer else \"N\"  \n",
    "    revised_text_start = gpt_answer.find(\"Revised Text:\") + len(\"Revised Text:\")  \n",
    "    revised_text = gpt_answer[revised_text_start:].strip() \n",
    "    return need_modification, revised_text, gpt_answer  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(ans)\n",
    "def get_revised_text(client, instruction, completion, user_template, system_template, max_tokens=2048):\n",
    "    content = user_template.format(instruction=instruction, completion=completion)\n",
    "    gpt_answer = client.get_response(content=content, system=system_template, max_tokens=max_tokens)\n",
    "    gpt_answer = gpt_answer.strip()\n",
    "    need_modification = \"Y\" if \"Does it need modification: Y\" in gpt_answer else \"N\"  \n",
    "    revised_text_start = gpt_answer.find(\"Revised Text:\") + len(\"Revised Text:\")  \n",
    "    revised_text = gpt_answer[revised_text_start:].strip() \n",
    "    return need_modification, revised_text, gpt_answer  \n",
    "from tqdm import tqdm\n",
    "revised_data = []  \n",
    "sample_data = export_data.select(range(100))\n",
    "for row in tqdm(sample_data):\n",
    "    prompt = row['prompt']  \n",
    "    response = row['response']\n",
    "\n",
    "    need_modification, revised_text, gpt_answer = get_revised_text(client, prompt, response, user_template, system_template, max_tokens=2048) \n",
    "    # 将结果添加到列表  \n",
    "    revised_data.append({  \n",
    "        'prompt': prompt,  \n",
    "        'response': response,  \n",
    "        'does_it_need_modification': need_modification,  \n",
    "        'revised_text': revised_text,\n",
    "        'gpt_answer': gpt_answer \n",
    "    })  \n",
    "# 创建新的Dataset  \n",
    "revised_dataset = Dataset.from_pandas(pd.DataFrame(revised_data))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 13/100 [02:35<17:19, 11.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 14/100 [02:49<18:03, 12.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 38/100 [07:36<08:12,  7.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': True, 'severity': 'medium'}, 'violence': {'filtered': False, 'severity': 'safe'}}}}}\n",
      "Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': True, 'severity': 'medium'}, 'violence': {'filtered': False, 'severity': 'safe'}}}}}\n",
      "Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': True, 'severity': 'medium'}, 'violence': {'filtered': False, 'severity': 'safe'}}}}}\n",
      "Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': True, 'severity': 'medium'}, 'violence': {'filtered': False, 'severity': 'safe'}}}}}\n",
      "Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': True, 'severity': 'medium'}, 'violence': {'filtered': False, 'severity': 'safe'}}}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 39/100 [08:05<14:16, 14.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': True, 'severity': 'medium'}, 'violence': {'filtered': False, 'severity': 'safe'}}}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 95/100 [17:58<01:07, 13.50s/it]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "revised_data = []  \n",
    "sample_data = export_data.select(range(100))\n",
    "for row in tqdm(sample_data):\n",
    "    prompt = row['prompt']  \n",
    "    response = row['response']\n",
    "\n",
    "    need_modification, revised_text, gpt_answer = get_revised_text(client, prompt, response, user_template, system_template, max_tokens=2048) \n",
    "    # 将结果添加到列表  \n",
    "    revised_data.append({  \n",
    "        'prompt': prompt,  \n",
    "        'response': response,  \n",
    "        'does_it_need_modification': need_modification,  \n",
    "        'revised_text': revised_text,\n",
    "        'gpt_answer': gpt_answer \n",
    "    })  \n",
    "# 创建新的Dataset  \n",
    "revised_dataset = Dataset.from_pandas(pd.DataFrame(revised_data))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 56\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# Collect the results as they complete  \u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# for future in tqdm(as_completed(futures), total=len(futures)):  \u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m#     revised_data.append(future.result())  \u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mtqdm\u001b[49m(total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(futures)) \u001b[38;5;28;01mas\u001b[39;00m pbar:  \n\u001b[1;32m     57\u001b[0m     \u001b[38;5;66;03m# Collect the results as they complete  \u001b[39;00m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m as_completed(futures):  \n",
      "\u001b[0;31mNameError\u001b[0m: name 'tqdm' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 73\u001b[0m\n\u001b[1;32m     71\u001b[0m     revised_dataset \u001b[38;5;241m=\u001b[39m Dataset\u001b[38;5;241m.\u001b[39mfrom_pandas(pd\u001b[38;5;241m.\u001b[39mDataFrame(revised_data))  \n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28mprint\u001b[39m(revised_dataset)  \n\u001b[0;32m---> 73\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[11], line 49\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m     os\u001b[38;5;241m.\u001b[39mremove(output_file)  \n\u001b[1;32m     47\u001b[0m revised_data \u001b[38;5;241m=\u001b[39m []  \n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ThreadPoolExecutor(max_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m executor:  \n\u001b[1;32m     50\u001b[0m     \u001b[38;5;66;03m# Create a future for each row in the dataset  \u001b[39;00m\n\u001b[1;32m     51\u001b[0m     futures \u001b[38;5;241m=\u001b[39m [executor\u001b[38;5;241m.\u001b[39msubmit(process_row, i, clients[i \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mlen\u001b[39m(clients)], row, user_template, system_template, max_tokens, output_file) \u001b[38;5;28;01mfor\u001b[39;00m i, row \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(sample_data)]  \n\u001b[1;32m     53\u001b[0m     \u001b[38;5;66;03m# Collect the results as they complete  \u001b[39;00m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;66;03m# for future in tqdm(as_completed(futures), total=len(futures)):  \u001b[39;00m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;66;03m#     revised_data.append(future.result())  \u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/llama_factory/lib/python3.10/concurrent/futures/_base.py:649\u001b[0m, in \u001b[0;36mExecutor.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    648\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_val, exc_tb):\n\u001b[0;32m--> 649\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshutdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    650\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/llama_factory/lib/python3.10/concurrent/futures/thread.py:235\u001b[0m, in \u001b[0;36mThreadPoolExecutor.shutdown\u001b[0;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads:\n\u001b[0;32m--> 235\u001b[0m         \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/llama_factory/lib/python3.10/threading.py:1096\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1095\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1096\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1098\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda3/envs/llama_factory/lib/python3.10/threading.py:1116\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1116\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1117\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m   1118\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'low'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'low'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'low'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'low'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': True, 'severity': 'medium'}, 'violence': {'filtered': False, 'severity': 'safe'}}}}}\n",
      "Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': True, 'severity': 'medium'}, 'violence': {'filtered': False, 'severity': 'safe'}}}}}\n",
      "Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': True, 'severity': 'medium'}, 'violence': {'filtered': False, 'severity': 'safe'}}}}}\n",
      "Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': True, 'severity': 'medium'}, 'violence': {'filtered': False, 'severity': 'safe'}}}}}\n",
      "Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': True, 'severity': 'medium'}, 'violence': {'filtered': False, 'severity': 'safe'}}}}}\n",
      "Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': True, 'severity': 'medium'}, 'violence': {'filtered': False, 'severity': 'safe'}}}}}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed  \n",
    "import os\n",
    "import pandas as pd\n",
    "from gpt4o import Openai, API_INFOS\n",
    "def get_revised_text(client, instruction, completion, user_template, system_template, max_tokens=2048):  \n",
    "    content = user_template.format(instruction=instruction, completion=completion)  \n",
    "    # print(f\"content: {content}\")\n",
    "    gpt_answer = client.get_response(content=content, system=system_template, max_tokens=max_tokens)  \n",
    "    gpt_answer = gpt_answer.strip()  \n",
    "    need_modification = \"Y\" if \"Does it need modification: Y\" in gpt_answer else \"N\"  \n",
    "    revised_text_start = gpt_answer.find(\"Revised Text:\") + len(\"Revised Text:\")  \n",
    "    revised_text = gpt_answer[revised_text_start:].strip()  \n",
    "    return need_modification, revised_text, gpt_answer  \n",
    "  \n",
    "def process_row(index, client, row, user_template, system_template, max_tokens=2048, output_file=\"output.jsonl\"):  \n",
    "    prompt = row['prompt']  \n",
    "    response = row['response']  \n",
    "    need_modification, revised_text, gpt_answer = get_revised_text(client, prompt, response, user_template, system_template, max_tokens=max_tokens)  \n",
    "    # print(f\"index {index}\")\n",
    "    result = {  \n",
    "        'index': index,  \n",
    "        'prompt': prompt,  \n",
    "        'response': response,  \n",
    "        'does_it_need_modification': need_modification,  \n",
    "        'revised_text': revised_text,  \n",
    "        'gpt_answer': gpt_answer  \n",
    "    }  \n",
    "    # Write the result to a JSONL file  \n",
    "    with open(output_file, 'a') as f:  \n",
    "        f.write(json.dumps(result) + \"\\n\")  \n",
    "    return result  \n",
    "def main():  \n",
    "    # Initialize multiple clients  \n",
    "    clients = [Openai(apis=[API_INFOS[i]]) for i in range(6)]  \n",
    "  \n",
    "    sample_data = export_data.select(range(100))\n",
    "    # user_template = \"User: {instruction}\\nCompletion: {completion}\"  \n",
    "    # system_template = \"You are a helpful assistant.\"  \n",
    "    max_tokens = 2048  \n",
    "    output_file = \"./revised_data/output.jsonl\"  \n",
    "  \n",
    "    # Clear the output file before starting  \n",
    "    if os.path.exists(output_file):  \n",
    "        os.remove(output_file)  \n",
    "  \n",
    "    revised_data = []  \n",
    "  \n",
    "    with ThreadPoolExecutor(max_workers=6) as executor:  \n",
    "        # Create a future for each row in the dataset  \n",
    "        futures = [executor.submit(process_row, i, clients[i % len(clients)], row, user_template, system_template, max_tokens, output_file) for i, row in enumerate(sample_data)]  \n",
    "  \n",
    "        # Collect the results as they complete  \n",
    "        # for future in tqdm(as_completed(futures), total=len(futures)):  \n",
    "        #     revised_data.append(future.result())  \n",
    "        with tqdm(total=len(futures)) as pbar:  \n",
    "            # Collect the results as they complete  \n",
    "            for future in as_completed(futures):  \n",
    "                result = future.result()  \n",
    "                revised_data.append(result)  \n",
    "                pbar.update(1)  # Update the progress bar\n",
    "  \n",
    "    # Load results from JSONL file and ensure the order is preserved  \n",
    "    with open(output_file, 'r') as f:  \n",
    "        revised_data = [json.loads(line) for line in f]  \n",
    "  \n",
    "    # Sort by the original index  \n",
    "    revised_dataset = revised_data.sort(key=lambda x: x['index'])  \n",
    "  \n",
    "    # Create a new Dataset  \n",
    "    revised_dataset = Dataset.from_pandas(pd.DataFrame(revised_data))  \n",
    "    revised_dataset.to_json(\"./revised_data/output_sorted.jsonl\") \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 334.07ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'response', 'does_it_need_modification', 'revised_text', 'gpt_answer'],\n",
       "    num_rows: 10\n",
       "})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_length = revised_dataset.shape[0]\n",
    "revised_dataset.to_json(f\"./revised_data/revised_{data_length}.jsonl\")\n",
    "revised_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Textual Aesthetic Analysis: The LLM-generated response is clear but lacks structural elements that could enhance readability and organization. The response could benefit from the use of headings, bullet points, and possibly some markdown formatting to emphasize key points. Additionally, the response could be broken down into more digestible parts.\n",
      "\n",
      "Does it need modification: Y\n",
      "\n",
      "Revised Text:\n",
      "\n",
      "---\n",
      "\n",
      "### Transforming the `getPosition` Method of `antv/g`'s Group in ZRender\n",
      "\n",
      "It is generally not recommended to modify built-in methods as it can lead to unexpected results and potential bugs. Here are some alternative approaches you can consider:\n",
      "\n",
      "1. **Develop a New Method**: \n",
      "   - Instead of modifying the existing method, create a new method that achieves your desired outcome.\n",
      "\n",
      "2. **Explore Other Methods**:\n",
      "   - Look into other methods provided by the library that might offer the functionality you need.\n",
      "\n",
      "3. **Search for Other Libraries or Modules**:\n",
      "   - There might be other libraries or modules that offer similar functionalities. Research and see if they can meet your requirements.\n",
      "\n",
      "4. **Reach Out for Support**:\n",
      "   - Contact the library's support team or community for assistance. They might provide insights or solutions that you haven't considered.\n",
      "\n",
      "By following these steps, you can avoid the risks associated with modifying built-in methods and find a more stable and maintainable solution.\n",
      "\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "print(revised_data[1]['gpt_answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': 'Which animal has two hands, a hyrax or a dog?',\n",
       " 'response': 'Neither a hyrax nor a dog has hands. Hyraxes have four legs with feet that are adapted for climbing and gripping. Similarly, dogs also have four legs with paws. The term \"hands\" is usually reserved for primates, such as humans, which have opposable thumbs and fingers.',\n",
       " 'does_it_need_modification': 'Y',\n",
       " 'revised_text': '---\\n\\n### Which Animal Has Two Hands, a Hyrax or a Dog?\\n\\nNeither a hyrax nor a dog has hands. Here’s a breakdown of their limb structures:\\n\\n#### Hyrax\\n- **Legs**: Four legs\\n- **Feet**: Adapted for climbing and gripping\\n\\n#### Dog\\n- **Legs**: Four legs\\n- **Paws**: Adapted for walking and running\\n\\nThe term \"hands\" is usually reserved for primates, such as humans, which have opposable thumbs and fingers.\\n\\n---\\n\\nThis revised version uses headings and bullet points to organize the information, making it more readable and visually appealing.',\n",
       " 'gpt_answer': 'Textual Aesthetic Analysis: The LLM-generated response is clear and accurate but could benefit from improved structure and formatting to enhance readability. The information can be organized into smaller sections with headings and bullet points to make it more visually appealing and easier to digest.\\n\\nDoes it need modification: Y\\n\\nRevised Text:\\n\\n---\\n\\n### Which Animal Has Two Hands, a Hyrax or a Dog?\\n\\nNeither a hyrax nor a dog has hands. Here’s a breakdown of their limb structures:\\n\\n#### Hyrax\\n- **Legs**: Four legs\\n- **Feet**: Adapted for climbing and gripping\\n\\n#### Dog\\n- **Legs**: Four legs\\n- **Paws**: Adapted for walking and running\\n\\nThe term \"hands\" is usually reserved for primates, such as humans, which have opposable thumbs and fingers.\\n\\n---\\n\\nThis revised version uses headings and bullet points to organize the information, making it more readable and visually appealing.'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revised_data[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Textual Aesthetic Analysis: The LLM-generated response is clear and accurate but could benefit from improved structure and formatting to enhance readability. The information can be organized into smaller sections with headings and bullet points to make it more visually appealing and easier to digest.\n",
      "\n",
      "Does it need modification: Y\n",
      "\n",
      "Revised Text:\n",
      "\n",
      "---\n",
      "\n",
      "### Which Animal Has Two Hands, a Hyrax or a Dog?\n",
      "\n",
      "Neither a hyrax nor a dog has hands. Here’s a breakdown of their limb structures:\n",
      "\n",
      "#### Hyrax\n",
      "- **Legs**: Four legs\n",
      "- **Feet**: Adapted for climbing and gripping\n",
      "\n",
      "#### Dog\n",
      "- **Legs**: Four legs\n",
      "- **Paws**: Adapted for walking and running\n",
      "\n",
      "The term \"hands\" is usually reserved for primates, such as humans, which have opposable thumbs and fingers.\n",
      "\n",
      "---\n",
      "\n",
      "This revised version uses headings and bullet points to organize the information, making it more readable and visually appealing.\n"
     ]
    }
   ],
   "source": [
    "print(revised_data[3]['gpt_answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'response'],\n",
       "    num_rows: 100\n",
       "})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "export_data.select(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 250.24ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "216011"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "export_data.select(range(100)).to_json(\"uf_sample.jsonl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
