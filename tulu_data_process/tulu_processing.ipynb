{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['dataset', 'id', 'messages'],\n",
       "        num_rows: 326154\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"allenai/tulu-v2-sft-mixture\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# judge the prompt or response is empty\n",
    "def flag_empty(e):\n",
    "    e[\"empty\"] = False\n",
    "    for m in e[\"messages\"]:\n",
    "        if m[\"content\"].strip() == \"\" and m[\"role\"] != \"system\":\n",
    "            e[\"empty\"] = True\n",
    "    return e\n",
    "\n",
    "_dataset = dataset.map(flag_empty, num_proc=8)\n",
    "_empty_ds = _dataset.filter(lambda x: x[\"empty\"], num_proc=8)\n",
    "_dataset_notempty = _dataset.filter(lambda x: not x[\"empty\"], num_proc=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['dataset', 'id', 'messages', 'empty'],\n",
       "        num_rows: 270\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_empty_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['dataset', 'id', 'messages'],\n",
       "        num_rows: 325884\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "export_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format:  97%|█████████▋| 317/326 [00:03<00:00, 125.48ba/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|██████████| 326/326 [00:03<00:00, 94.95ba/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1414664165"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# export to json\n",
    "export_dataset = _dataset_notempty.select_columns([\"dataset\", \"id\", \"messages\"])\n",
    "export_dataset[\"train\"].to_json(\"./tulu_v2.json\",num_proc=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'assistant', 'system', 'user'}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# role type\n",
    "def get_role(e):\n",
    "    e['role'] = [x['role'] for x in e['messages']]\n",
    "    return e\n",
    "data_role = dataset.map(get_role, num_proc=8)\n",
    "role_list = data_role['train']['role']\n",
    "roles = [item for sublist in role_list for item in sublist]\n",
    "set(roles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter (num_proc=8):   0%|          | 0/326154 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter (num_proc=8): 100%|██████████| 326154/326154 [00:02<00:00, 123977.67 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['dataset', 'id', 'messages', 'length'],\n",
       "        num_rows: 29683\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset['train'][0]['messages'])\n",
    "def data_length(e):\n",
    "    e['length'] = len(e[\"messages\"])\n",
    "    return e\n",
    "dataset_length = dataset.map(data_length, num_proc=8)\n",
    "dataset_length\n",
    "# mutil turns dataset\n",
    "dataset_mutil_turn = dataset_length.filter(lambda x: x['length'] > 3, num_proc=8)\n",
    "dataset_mutil_turn\n",
    "set(dataset_mutil_turn['train']['dataset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dialogue turns count\n",
    "from collections import Counter  \n",
    "data_length = dataset_length['train']['length']\n",
    "counter = Counter(data_length) \n",
    "# for value, count in counter.items():  \n",
    "#     print(f\"Value: {value}, Count: {count}\")  \n",
    "import pandas as pd\n",
    "data_length_distribution = pd.Series(counter)\n",
    "data_length_distribution.sort_index(inplace=True)\n",
    "data_length_distribution.to_csv(\"./turns_distribution.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_factory",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
